{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a2ebd9c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53b2e82b",
   "metadata": {},
   "source": [
    "## First round of qualitative analysis\n",
    "I use this notebook to look at all the text based answers I have given in the annotated data to be able to collect the data for part 2. This data was collected directly in an excel spreadsheet and uploaded to the repository for more work and access."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "de0704e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "88"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#reading in file\n",
    "df = pd.read_csv('annotations_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8ab8cf93",
   "metadata": {},
   "outputs": [],
   "source": [
    "#filtering down to true articles from 2012 or 2021\n",
    "df_true = df[df['Is the article accurately labelled as classification?'] == 'Yes']\n",
    "df = df_true[df_true['Which year is the article from?'] == 2012]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feb2e95f",
   "metadata": {},
   "source": [
    "## Demographics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b6c4cd84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of articles mentioning demographics:  3\n",
      "117\n",
      "Informed consent was obtained from all subjects, and the\n",
      "experimental protocols were approved by the institutional ethics board. Confirmation\n",
      "of diagnosis for all subjects was made via expert consensus panels. Demographic and\n",
      "clinical information of the participants is provided in Table 1.\n",
      "214 C.-Y. Wee et al.\n",
      "Table 1. Demographic and clinical information of the participants\n",
      "Group MCI Control p-value\n",
      "No. of subjects (Male/Female) 6/6 9/16 -\n",
      "Age (mean ± SD) 75.0 ± 8.0 72.9 ± 7.9 0.3598a\n",
      "Years of education (mean ± SD) 18.0 ± 4.1 15.8 ± 2.4 0.0491a\n",
      "MMSE (mean ± SD) 28.5 ± 1.5b 29.3 ± 1.1 0.1201a\n",
      "---\n",
      "202\n",
      "Table 1 provides a summary of the\n",
      "demographic characteristics of the studied subjects (denoted as mean ± standard\n",
      "deviation). (and shows age and gender as the only demographic information)\n",
      "---\n",
      "235\n",
      "Sex and age(mean and range are reported): \n",
      "\n",
      "Our cohort includes 18 trauma patients admitted to UC Irvine Medical Center between\n",
      "June 2009 and July 2010. The mean patient age was 51±11 yrs (18-86yrs). There were\n",
      "13 men and 5 women. All patients were scanned on a Siemens Sensation 64 scanner.\n",
      "The scanning parameters were: 2mm slice thickness, 120 kvp, no intravenous contrast\n",
      "administration, and convolution kernel B40f (16 patients) or B60f (2 patients). The CT\n",
      "data covered the thoracic and lumbar spines, and included 14 vertebrae on average. An\n",
      "expert radiologist examined the cases and manually marked the fracture sites. Ten\n",
      "patients were positive for vertebral body fractures. The total number of spatially distinct\n",
      "fracture sites was 21, among the 10 patients. The remaining 8 patients had no evidence\n",
      "of vertebral body fracture. The average running time is 5.6 minutes.\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "#column 1: id\n",
    "#column 19: demographics y/n\n",
    "#column 22: quote\n",
    "\n",
    "demo = df[df.iloc[:,19] == 'Yes']\n",
    "demo = demo.iloc[:,[1,20]]\n",
    "demo.reset_index()\n",
    "print('Number of articles mentioning demographics: ', len(demo))\n",
    "\n",
    "\n",
    "for index in range(len(demo)):\n",
    "    print(demo.iloc[index, 0])\n",
    "    print(demo.iloc[index, 1])\n",
    "    print('---')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37acc932",
   "metadata": {},
   "source": [
    "## Dataset collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9c9e0de4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of articles mentioning dataset collection:  14\n",
      "78\n",
      "For this article (though plucked from an existing dataset\n",
      "---\n",
      "82\n",
      "For this article, from existing dataset\n",
      "---\n",
      "124\n",
      "For the purpose of this article\n",
      "---\n",
      "173\n",
      "They expanded their dataset with data specifically for this article: \n",
      "\n",
      "Additionally, we obtained 29 fundus images from patients (11 male, 18 female, all older than 47 years) at the University Eye Hospital with permission of the Institutional Ethics Board. We used these additional images as an independent test set.\n",
      "---\n",
      "258\n",
      "From September 2020 to January 2021, a total of 2,008 images of benign lesions and 1,466 images of malignant lesions from 593 patients were collected as the dataset used in this paper. \n",
      "---\n",
      "278\n",
      "For this article: To this end, we collected a big-data (BD) cohort consisting of $$3\\,790$$ patients, $$312\\,848$$ US images, and $$36\\,602$$ US studies from the PACS of Anonymized\n",
      "---\n",
      "280\n",
      "For this article\n",
      "---\n",
      "284\n",
      "For the article\n",
      "---\n",
      "291\n",
      "For one of the three it was created for this article specifically: \n",
      "The proposed method was extensively evaluated on three imbalanced medical image datasets, Skin7 [5], OCTMNIST [27], and X-ray6 (Table 1). Specially, X-ray6 contains six diseases of X-ray images (Atelectasis, Cardiomegaly, Emphysema, Hernia, Mass, Effusion), where the six classes were selected from the original 14-class dataset ChestX-ray14 [24] by removing those classes of images which may contain multiple or ambiguous diseases in single images. \n",
      "---\n",
      "294\n",
      "I think for this article:\n",
      "We evaluate our method on a dataset of 439 subjects, including 93, 98, and 248 HCC cases of grading LR-3, LR-4, and LR-5, respectively. All data were obtained using either a 1.5 T (Magnetom Aera, Siemens Healthcare, Erlangen, Germany) or a 3.0 T (uMR 770, United Imaging Healthcare, Shanghai, China) MR scanner with Gd-EOB-DTPA as contrast agent in same hospital and labeled by three radiologists with experience over 5 years. \n",
      "---\n",
      "297\n",
      "The final dataset is created for this article, the others no:\n",
      "Xray6 is a subset of ChestXray14 dataset [23], containing six diseases of X-ray images (Atelectasis, Cardiomegaly, Emphysema, Hernia, Mass, Effusion). Based on the smallest class (i.e., Hernia) which has only 110 images, the same number of images were randomly sampled from every other class, forming the small-sample Xray6 dataset. \n",
      "---\n",
      "309\n",
      "For this article\n",
      "---\n",
      "315\n",
      "For this article\n",
      "---\n",
      "316\n",
      "For this article: (generated from other previous datasets)\n",
      "176 patients (see patient selection in Fig. S2) with Gd-T1w and T2w-FLAIR scans from the TCGA-GBM [23] and TCGA-LGG [24] studies were obtained from TCIA [25] and annotated by 7 radiologists to delineate the enhancing lesion and edema region.\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "#column 1: id\n",
    "#column 21: dataset collection y/n\n",
    "#column 22: quote\n",
    "\n",
    "\n",
    "demo = df[df.iloc[:,21] == 'Yes']\n",
    "demo = demo.iloc[:,[1,22]]\n",
    "demo.reset_index()\n",
    "print('Number of articles mentioning dataset collection: ', len(demo))\n",
    "\n",
    "\n",
    "for index in range(len(demo)):\n",
    "    print(demo.iloc[index, 0])\n",
    "    print(demo.iloc[index, 1])\n",
    "    print('---')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c47da679",
   "metadata": {},
   "source": [
    "## Justification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5514e424",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "215\n",
      "e present an algorithm for\n",
      "automated TB detection using images from digital microscopes such as\n",
      "CellScope [2], a novel, portable device capable of brightfield and fluorescence\n",
      "microscopy\n",
      "\n",
      "Automated processing on such platforms could\n",
      "save lives by bringing healthcare to rural areas with limited access to\n",
      "laboratory-based diagnostics\n",
      "---\n",
      "4\n",
      "surgical gesture analysis\n",
      "\n",
      "Most of the prior work on surgical gesture recognition (see, e.g., [4-6]) uses hidden Markov models (HMMs) to analyze kinematic data stored by the robot (…) Overall, our main conclusion is that methods based on video data perform equally well as methods based n kinematic data for a typical surgical training setup.\n",
      "---\n",
      "7\n",
      "We present a superpixel based learning framework based on retinal structure priors for glaucoma diagnosis.\n",
      "\n",
      "It is critical to detect this degeneration of the optic nerve as early as possible in order to stall its progression\n",
      "---\n",
      "9\n",
      "our aim of this study is to develop a computerized method to detect\n",
      "the lung tumors and abnormal lymph nodes from PET-CT thoracic images automatically.\n",
      "\n",
      "In this work, we propose a new and intuitive idea to the detection problem –\n",
      "after attempting to detect all abnormalities, if we can identify the actual lung\n",
      "field (tumors inclusive), then we can differentiate lung tumors and abnormal\n",
      "lymph nodes based on the degree of overlap between the detected abnormality\n",
      "and the lung field.\n",
      "---\n",
      "10\n",
      "Different from most existing methods, we\n",
      "classify MCI-C and MCI-NC with aid from the domain knowledge learned with\n",
      "AD and NC subjects as auxiliary domain to further improve the classification\n",
      "performance.\n",
      "\n",
      "Alzheimer’s disease (AD) is the most common form of dementia in elderly people\n",
      "worldwide. Early diagnosis of AD is very important for possible delay of the disease.\n",
      "Mild cognitive impairment (MCI) is a prodromal stage of AD, which can be further\n",
      "categorized into MCI converters (MCI-C) and MCI non-converters (MCI-NC). The\n",
      "former will convert into AD in follow-up time, while the latter will not convert. Thus,\n",
      "accurate diagnosis of MCI converters is of great importance.\n",
      "---\n",
      "13\n",
      "We\n",
      "utilize a fuzzy multi-class modeling using a stochastic expectation maximization\n",
      "(SEM) algorithm to fit a finite mixture model (FMM) to the\n",
      "PET image. We then propose a direct estimation formula for TLA and\n",
      "SUVmean from this multi-class statistical model.\n",
      "\n",
      "The aforementioned functional markers computed from the PET image are\n",
      "corrupted by partial volume effects and acquisition blur. Nonetheless, we recently\n",
      "proposed a direct statistical estimation method, statistical lesion activity\n",
      "computation (SLAC), in [6] for computing TLA, in the presence of blur.\n",
      "---\n",
      "14\n",
      "A novel gland segmentation and classification scheme applied\n",
      "to an H&E histology image of the prostate tissue is proposed.\n",
      "\n",
      "In detecting prostate cancer on a digitized tissue slide, the pathologist relies\n",
      "on: (i) structural information; glands in a cancer region (cancer glands) appear\n",
      "to have structural properties (e.g. nuclei abundance, lumen size) different from\n",
      "glands in a normal region (normal glands) and (ii) contextual information; cancer\n",
      "glands typically cluster into groups and are of similar shape and size1, while\n",
      "shape and size of normal glands vary widely. These two sources of information\n",
      "can be observed in Fig. 1b. Hence, a reasonable approach to assist a pathologist\n",
      "in finding cancer regions includes segmenting out glandular regions, examining\n",
      "their structural and contextual information and finally classifying them.\n",
      "---\n",
      "16\n",
      "We propose a modeling\n",
      "strategy using supervised feature extraction to optimally combine highdimensional\n",
      "imaging modalities with several other low-dimensional disease\n",
      "risk factors. The motivation is to discover new imaging biomarkers\n",
      "and use them in conjunction with other known biomarkers for prognosis\n",
      "of individuals at high risk of developing AD. Our framework also has the\n",
      "ability to assess the relative importance of imaging modalities for predicting\n",
      "AD conversion.\n",
      "\n",
      "Mild cognitive impairment (MCI) is an intermediate stage between healthy aging\n",
      "and dementia. Patients diagnosed with MCI are at high risk of developing\n",
      "Alzheimer’s disease (AD), but not everyone with MCI will convert. Accurate\n",
      "prognosis for MCI patients is an important prerequisite for providing the optimal\n",
      "treatment and management of the disease.\n",
      "---\n",
      "19\n",
      "A method for automatic analysis and interpretation of histopathology\n",
      "images is presented. The method uses a representation of the image data\n",
      "set based on bag of features histograms built from visual dictionary of Haarbased\n",
      "patches and a novel visual latent semantic strategy for characterizing the\n",
      "visual content of a set of images.\n",
      "\n",
      "This paper presents a new method, ViSAI, for automatic analysis and interpretation of\n",
      "histopathological images.\n",
      "---\n",
      "25\n",
      "3D Polarized Light Imaging (3D-PLI) has been shown to\n",
      "measure the orientation of nerve fibers in post mortem human brains at\n",
      "ultra high resolution. The 3D orientation in each voxel is obtained as a\n",
      "pair of angles, the direction angle and the inclination angle with unknown\n",
      "sign. The sign ambiguity is a major problem for the correct interpretation\n",
      "of fiber orientation. Measurements from a tiltable specimen stage, that\n",
      "are highly sensitive to noise, extract information, which allows drawing\n",
      "conclusions about the true inclination sign. In order to reduce noise, we\n",
      "propose a global classification of the inclination sign, which combines\n",
      "measurements with spatial coherence constraints.\n",
      "\n",
      "Fiber tracts are composed of axons, which connect nerve cells between each\n",
      "other, and thus transmit information between brain areas. The exact courses\n",
      "of fiber tracts are still far from being fully understood.\n",
      "---\n",
      "36\n",
      "This paper presents\n",
      "a novel approach for streak detection and visualization on dermoscopic images.\n",
      "\n",
      "Melanoma is the most deadly form of skin cancer, yet treatable via excision if detected\n",
      "early. There is, therefore, a demand to develop computer-aided diagnostic systems to facilitate\n",
      "the early detection of melanoma.\n",
      "---\n",
      "37\n",
      "We develop an automated method to determine the foveola\n",
      "location in macular 3D-OCT images in either healthy or pathological\n",
      "conditions.\n",
      "\n",
      "The foveola is an important anatomical landmark for retinal image analysis [1]. It\n",
      "is located in the center of the macula, responsible for sharp central vision. Several\n",
      "clinically-relevant indices are measured with respect to the foveola location, such\n",
      "as the retina’s average thickness, or drusen size within concentric circles around\n",
      "the foveola [1, 2]. In addition, many macular diseases are best observed around\n",
      "the foveola, such as macular hole, and age-related macular degeneration [3].\n",
      "Therefore, the localization of the foveola in retinal images is an important first\n",
      "step for diagnosis and longitudinal data analysis.\n",
      "---\n",
      "38\n",
      "In this paper we propose a new log-chromaticity 2-D colour space,\n",
      "an extension of previous approaches, which succeeds in removing confounding\n",
      "factors from dermoscopic images: (i) the effects of the particular camera characteristics\n",
      "for the camera system used in forming RGB images; (ii) the colour\n",
      "of the light used in the dermoscope; (iii) shading induced by imaging non-flat\n",
      "skin surfaces; (iv) and light intensity, removing the effect of light-intensity falloff\n",
      "toward the edges of the dermoscopic image. In the context of a blind source separation\n",
      "of the underlying colour, we arrive at intrinsic melanin and hemoglobin\n",
      "images, whose properties are then used in supervised learning to achieve excellent\n",
      "malignant vs. benign skin lesion classification.\n",
      "\n",
      "The three most common malignant skin cancers are basal cell carcinoma (BCC), squamous\n",
      "cell carcinoma (SCC), and melanoma, among which melanoma is the most deadly\n",
      "with a high increasing rate in most parts of the world. Melanoma is often treatable if\n",
      "detected in the early stage, particularly before the metastasis phase. Therefore, there is\n",
      "an increasing demand for computer-aided diagnostic systems to catch early melanomas.\n",
      "Colour has played a crucial role in the diagnosis of skin lesions by experts in most\n",
      "clinical methods (see e.g. [1]). For instance, the presence of multiple colours with an\n",
      "irregular distribution can signal malignancy.\n",
      "Few studies have investigated the use of colour features representing biological properties\n",
      "of skin lesions.\n",
      "---\n",
      "40\n",
      "we present an image analysis method to\n",
      "detect apoptosis in time-lapse phase-contrast microscopy, which is nondestructive\n",
      "imaging.\n",
      "\n",
      "There have been little-to-no reports of apoptosis detection in phase-contrast\n",
      "microscopy. To the best of our knowledge, cell death event detection has only\n",
      "been implicitly performed as a byproduct of cell tracking; i.e., if the trajectory of\n",
      "a cell terminates during cell tracking, the cell is considered dead. However, this\n",
      "simple heuristic often yields poor results because many cell traject\n",
      "---\n",
      "41\n",
      "In this paper we propose a dynamic framework for quantitative analysis of\n",
      "lymphocyte morphological changes in 2D+t image sequences\n",
      "\n",
      "Morphological analysis of cells features prominently in a wide range of applications\n",
      "including digital pathology and is essential for improving our understanding\n",
      "of the basic physiological processes of organisms.\n",
      "---\n",
      "42\n",
      "In this paper we propose a learning-based method that is general enough\n",
      "to perform well across different microscopy modalities. Rather than invoking\n",
      "computationally-intensive segmentation frameworks [1,9], or classifying all image\n",
      "patches in a sliding-window manner [15], it uses a highly-efficient MSER region\n",
      "detector [8] to find a broad number of candidate regions to be scored with a\n",
      "learning-based measure. The non-overlaping subset of those regions with high\n",
      "similarity to the class of interest can then be selected via dynamic programming,\n",
      "while the learning can be done within the structured output framework [12].\n",
      "\n",
      "Automatic cell detection is a subject of interest in a wide range of cell-based\n",
      "studies, as it is the basis of many automatic methods for cell counting, segmentation\n",
      "and tracking. The broad diversity of cell lines and microscopy imaging\n",
      "techniques require that cell detection algorithms adapt well to different scenarios.\n",
      "The difficulty of the problem also increases when the cell density of the\n",
      "sample is high, as in this case the cell size can vary and cell clumping is usual.\n",
      "Moreover, in some applications different cell types or other similar structures\n",
      "can be present in the same image, and in this case the algorithm is required to\n",
      "detect only the cells of interest, posing a barrier hard to overcome with classical\n",
      "image processing techniques.\n",
      "---\n",
      "53\n",
      "We therefore propose a method for 3D breast decompression\n",
      "and associated lesion mapping from 3D DBT data.\n",
      "\n",
      "According to theWorld Cancer Report 2008 (globocan.iarc.fr, 2012/01/23) breast\n",
      "cancer is the most frequent cancer diagnosis in women among all specifiable\n",
      "kinds of cancer. Early detection is assumed to significantly improve outcomes.\n",
      "---\n",
      "62\n",
      "We present a novel method of Hierarchical Manifold Learning\n",
      "which aims to automatically discover regional variations within images.\n",
      "\n",
      "We present a novel method of Hierarchical Manifold Learning\n",
      "which aims to automatically discover regional variations within images.\n",
      "---\n",
      "88\n",
      "we show that null distributions ordinarily obtained\n",
      "by permutation tests using SVMs can be analytically approximated from\n",
      "the data. The analytical computation takes a small fraction of the time\n",
      "it takes to do an actual permutation test, thereby rendering it possible\n",
      "to quickly create statistical significance maps derived from SVMs. Such\n",
      "maps are critical for understanding imaging patterns of group differences\n",
      "and interpreting which anatomical regions are important in determining\n",
      "the classifier’s decision.\n",
      "\n",
      "The dominant approach\n",
      "addressing this problem involves performing independent statistical testing either\n",
      "pixel/voxel-wise [1] or regions of interest (ROI-wise) in the image. It has\n",
      "been argued that such univariate analysis might miss group difference patterns\n",
      "that span multiple voxels or regions [2]. Hence, replacing univariate methods by\n",
      "multivariate methods such as SVMs [3] [4][5] has been discussed in literature.\n",
      "However, unlike univariate methods [1], SVMs do not naturally provide statistical\n",
      "tests (and corresponding p-values) associated with every voxel/region of\n",
      "an image. Permutation testing has been suggested for interpreting SVM output\n",
      "for such high dimensional data [6]. However, performing these tests is time\n",
      "consuming and computationally costly\n",
      "---\n",
      "97\n",
      "we adapt spectral signatures for capturing morphological\n",
      "changes over time. Advanced techniques for capturing temporal shape changes\n",
      "frequently rely on first registering the sequence of shapes and then analyzing the\n",
      "corresponding set of high dimensional deformation maps. Instead, we propose a\n",
      "simple encoding motivated by the observation that small shape deformations lead\n",
      "to minor refinements in the spectral signature composed of the eigenvalues of\n",
      "the Laplace operator. The proposed encoding does not require registration, since\n",
      "spectral signatures are invariant to pose changes. We apply our representation to\n",
      "the shapes of the ventricles extracted from 22 cine MR scans of healthy controls\n",
      "and Tetralogy of Fallot patients. We then measure the accuracy score of our encoding\n",
      "by training a linear classifier, which outperforms the same classifier based\n",
      "on volumetric measurements.\n",
      "\n",
      "Capturing the shape and function of anatomy through volumetric measurements extracted\n",
      "from 4D medical scans has become of central importance in diagnosing diseases.\n",
      "For example, cardiologists rely on ejection fraction extracted from ultrasound\n",
      "or cine MR scans to assess patients. These volumetric measurements, however, are not\n",
      "sensitive enough to aid the diagnosis of many focal or diffuse cardiac diseases. In this\n",
      "paper, we introduce a new encoding of the shape and its temporal changes based on\n",
      "the spectral signature and show that this encoding is more sensitive for comparing two\n",
      "shapes and their temporal dynamics than volumetric measurements.\n",
      "---\n",
      "117\n",
      "we consider a constrained sparse linear regression model associated\n",
      "with the least absolute shrinkage and selection operator (LASSO). Specifically,\n",
      "we introduced sparsity into brain connectivity via l1-norm penalization, and ensured\n",
      "consistent non-zero connections across subjects via l2-norm penalization.\n",
      "Our results demonstrate that the constrained sparse network gives better classification\n",
      "performance than the conventional correlation-based network, indicating\n",
      "its greater sensitivity to early stage brain pathologies.\n",
      "\n",
      "Mild cognitive impairment (MCI) is difficult to diagnose due to its\n",
      "subtlety. Recent emergence of advanced network analysis techniques utilizing\n",
      "resting-state functional Magnetic Resonance Imaging (rs-fMRI) has made the\n",
      "understanding of neurological disorders more comprehensively at a whole-brain\n",
      "connectivity level. However, inferring effective brain connectivity from fMRI\n",
      "data is a challenging task, particularly when the ultimate goal is to obtain good\n",
      "control-patient classification performance. Incorporating sparsity into connectivity\n",
      "modeling can potentially produce results that are biologically more meaningful\n",
      "since most biologically networks are formed by a relatively few number\n",
      "of connections. However, this constraint, when applied at an individual level, will\n",
      "degrade classification performance due to inter-subject variability. To address this\n",
      "problem,\n",
      "---\n",
      "122\n",
      "This paper presents a method for unsupervised cluster analysis using\n",
      "multi-edge similarity graphs that combine information from different\n",
      "modalities. The method alleviates the issues with traditional supervised\n",
      "classification methods that use diagnostic labels and are therefore unable\n",
      "to exploit or elucidate the underlying heterogeneity of the dataset under\n",
      "analysis.\n",
      "\n",
      "Classifying subjects based on their underlying pathology, brain structure, behavior\n",
      "and cognition is an important step towards creating biomarkers. However,\n",
      "pathologies like ASD and other neuropsychiatric disorders are defined over a\n",
      "spectrum and the severity of the disease may vary within a population thus\n",
      "making the data highly heterogeneous. Different modalities, like imaging, neurocognitive\n",
      "scores etc., may characterize different aspects of this heterogeneity\n",
      "to different degrees. This paper presents a method for unsupervised cluster analysis\n",
      "of populations using multi-edge similarity graphs that combine information\n",
      "of population heterogeneity from different modalities, producing classes that are\n",
      "more representative of population variability.\n",
      "Traditional superivised classification methods, utilize predefined diagnostic\n",
      "labels for the subjects for training [1], [2], and hence new subjects can only be\n",
      "classified into one of these diagnostic categories, thereby overlooking the underlying\n",
      "heterogeneity of the pathology.\n",
      "---\n",
      "137\n",
      "we present an automatic, probabilistic Hierarchical\n",
      "Conditional Random Field (HCRF) framework for detection of gadenhancing\n",
      "lesions in brain images of patients with MS.\n",
      "\n",
      "The detection of gad-enhancing lesions in brain MRI of Multiple\n",
      "Sclerosis (MS) patients is of great interest since they are important\n",
      "markers of disease activity. However, many of the enhancing voxels are\n",
      "associated with normal structures (i.e. blood vessels) or noise in the\n",
      "MRI, making the detection of gad-enhancing lesions a challenging task.\n",
      "---\n",
      "152\n",
      "By exploiting the recent developments in Multirow-Detector\n",
      "Computed Tomography (MDCT) scanner technology, the complex endocardial\n",
      "surface morphology of the left ventricle is studied and the cardiac segments\n",
      "affected by coronary arterial stenosis localized via analysis of Computed\n",
      "Tomography (CT) image data obtained from a 320-MDCT scanner. The nonrigid\n",
      "endocardial surface data is analyzed using an isometry-invariant Bag-of-\n",
      "Words (BOW) feature-based approach. The clinical significance of the analysis\n",
      "in identifying, localizing and quantifying the incidence and extent of coronary\n",
      "artery disease is investigated. Specifically, the association between the\n",
      "incidence and extent of coronary artery disease and the alterations in the\n",
      "endocardial surface morphology is studied. The results of the proposed\n",
      "approach on 15 normal data sets, and 12 abnormal data sets exhibiting coronary\n",
      "artery disease with varying levels of severity are presented. Based on the\n",
      "characterization of the endocardial surface morphology using the Bag-of-Words\n",
      "features, a neural network-based classifier is implemented to test the\n",
      "effectiveness of the proposed morphological analysis approach.\n",
      "\n",
      "The complex morphological structure of the left ventricular\n",
      "endocardial surface and its relation to the severity of arterial stenosis has not yet\n",
      "been thoroughly investigated due to the limitations of conventional imaging\n",
      "techniques.\n",
      "\n",
      "\n",
      "Since CAD is a leading cause of morbidity and\n",
      "mortality worldwide, techniques that improve diagnostic and prognostic effectiveness\n",
      "have a potentially significant clinical impact.\n",
      "---\n",
      "163\n",
      "we describe a tracking system which\n",
      "learns visual feature descriptors as class-specific landmarks on an articulated tool.\n",
      "\n",
      "Tool tracking is an accepted capability for computer-aided surgical intervention\n",
      "which has numerous applications, both in robotic and manual\n",
      "minimally-invasive procedures.\n",
      "---\n",
      "194\n",
      "We propose a\n",
      "realistic head model creation with all useful head structures and brain tissues\n",
      "including the neonate fontanel for more accurate results from NIRS signals\n",
      "modeling. We also design a 3D imaging tool for dynamic mapping and analysis\n",
      "of brain activation onto the cortex surface. Results show significant differences\n",
      "in oxy-hemoglobin between healthy neonates and subjects with IVH.\n",
      "\n",
      "Low arterial blood oxygenation and abnormal cerebral\n",
      "blood flow is believed to influence the function of the neonatal brain [1]. Preterm\n",
      "neonates are at high-risk of IVH because of their lack of ability to regulate cerebral blood\n",
      "flow and pressure [2].\n",
      "---\n",
      "202\n",
      "we\n",
      "investigate a tree-guided sparse coding method to identify grouped imaging\n",
      "features in the brain regions for guiding disease classification and interpretation.\n",
      "\n",
      "Neuroimage analysis based on machine learning technologies has\n",
      "been widely employed to assist the diagnosis of brain diseases such as\n",
      "Alzheimer's disease and its prodromal stage - mild cognitive impairment. One\n",
      "of the major problems in brain image analysis involves learning the most\n",
      "relevant features from a huge set of raw imaging features, which are far more\n",
      "numerous than the training samples. This makes the tasks of both disease\n",
      "classification and interpretation extremely challenging. Sparse coding via L1\n",
      "regularization, such as Lasso, can provide an effective way to select the most\n",
      "relevant features for alleviating the curse of dimensionality and achieving more\n",
      "accurate classification. However, the selected features may distribute randomly\n",
      "throughout the whole brain, although in reality disease-induced abnormal\n",
      "changes often happen in a few contiguous regions.\n",
      "---\n",
      "203\n",
      "we propose to use a database\n",
      "of images, rather than coordinates, and frame the problem as transfer\n",
      "learning: learning a discriminant model on a reference task to apply it\n",
      "to a different but related new task. To facilitate statistical analysis of\n",
      "small cohorts, we use a sparse discriminant model that selects predictive\n",
      "voxels on the reference task and thus provides a principled procedure to\n",
      "define ROIs.\n",
      "\n",
      "Typical cohorts in brain imaging studies are not large enough\n",
      "for systematic testing of all the information contained in the images. To\n",
      "build testable working hypotheses, investigators thus rely on analysis\n",
      "of previous work, sometimes formalized in a so-called meta-analysis. In\n",
      "brain imaging, this approach underlies the specification of regions of interest\n",
      "(ROIs) that are usually selected on the basis of the coordinates of\n",
      "previously detected effects. In this paper, we propose to use a database\n",
      "of images, rather than coordinates, and frame the problem as transfer\n",
      "learning:\n",
      "---\n",
      "206\n",
      "We applied the feature analysis method\n",
      "to a large TCS dataset that is relevant for clinical practice and includes\n",
      "the variability that is present under real conditions. In order to decrease\n",
      "the influence to the image properties from the different settings of ultrasound\n",
      "machine, we propose a local image analysis method using an\n",
      "invariant scale blob detection for the hyperechogenicity estimation. The\n",
      "local features are extracted from the detected blobs and the watershed\n",
      "regions in half of mesencephalon area. The performance of these features\n",
      "is evaluated by a feature-selection method. The cross validation results\n",
      "show that the local features could be used for PD detection.\n",
      "\n",
      "Transcranial sonography (TCS) is a new tool for the diagnosis\n",
      "of Parkinson’s disease (PD) according to a distinct hyperechogenic\n",
      "pattern in the substantia nigra (SN) region. However a procedure including\n",
      "rating scale of SN hyperechogenicity was required for a standard clinical\n",
      "setting with increased use.\n",
      "---\n",
      "213\n",
      "We propose a novel approach to detect fusion\n",
      "and undocking events by first searching for docked vesicles that ‘disappear’ from\n",
      "the field of view, and then using a diffusion model to classify them as either fusion\n",
      "or undocking events.\n",
      "\n",
      "Fluorescently-tagged proteins located on vesicles can fuse with the\n",
      "surface membrane (visualised as a ‘puff’) or undock and return back into the bulk\n",
      "of the cell. Detection and quantitative measurement of these events from timelapse\n",
      "videos has proven difficult.\n",
      "---\n",
      "227\n",
      "In this work, for the first time, we propose\n",
      "an automatic 3D SNE detection approach based on random forests,\n",
      "with a novel formulation of SNE probability that relies on visual context\n",
      "and anatomical priors. On a 3D-TCUS dataset of 11 PD patients and 11\n",
      "healthy controls, we demonstrate that our SNE detection approach yields\n",
      "promising results with a sensitivity and specificity of around 83%.\n",
      "\n",
      "Parkinson’s disease (PD) is a neurodegenerative movement\n",
      "disorder caused by decay of dopaminergic cells in the substantia nigra\n",
      "(SN), which are basal ganglia residing within the midbrain area. In the\n",
      "past two decades, transcranial B-mode sonography (TCUS) has emerged\n",
      "as a viable tool in differential diagnosis of PD and recently has been shown\n",
      "to have promising potential as a screening technique for early detection of\n",
      "PD, even before onset of motor symptoms. In TCUS imaging, the degeneration\n",
      "of SN cells becomes visible as bright and hyper-echogenic speckle\n",
      "patches (SNE) in the midbrain. Recent research proposes the usage of 3D\n",
      "ultrasound imaging in order to make the application of the TCUS technique\n",
      "easier and more objective.\n",
      "---\n",
      "230\n",
      "The paper presents a method for learning multimodal classifiers\n",
      "from datasets in which not all subjects have data from all modalities.\n",
      "\n",
      "Pattern classification techniques are generating increasing interest in the neuroimaging\n",
      "community as they are powerful in learning the patterns of pathology from a population, assign a probabilistic score to each subject which characterizes\n",
      "pathology on an individual basis and aid in assessing treatment in conjunction\n",
      "with other clinical scores\n",
      "---\n",
      "234\n",
      "we show how\n",
      "these visual features can be automatically extracted from coronary artery\n",
      "images and used for finding similar coronary angiograms from a database.\n",
      "\n",
      "X-ray Coronary angiography is a commonly used technique to assess the state\n",
      "of coronary artery disease (CAD). During assessment, clinicians look for characteristic\n",
      "visual features, taking into account the overall disease burden, the\n",
      "complexity of individual lesions, and placing more weight on proximal stenoses\n",
      "of the coronary arteries. Even though there are quantitative assessment scores\n",
      "such as the Syntax Score[12], they require manual input of angiographic information.\n",
      "Thus the clinicians still characterize the disease by ’eyeballing’ on salient\n",
      "visual features such as lumen variation or the relative thickness of arteries (see\n",
      "Fig. 1a-c)[5], the distance of the junctions from the root, the number of trifurcations,\n",
      "etc.\n",
      "---\n",
      "235\n",
      "We propose a\n",
      "fully automated method to detect acute vertebral body fractures on trauma CT\n",
      "studies.\n",
      "\n",
      "Assessment of trauma patients with multiple injuries, particularly in the setting of\n",
      "multiple trauma patients presenting to the hospital concurrently, can be one of the\n",
      "most clinically challenging situations dealt with by the radiologist. Traumatic injury\n",
      "of the spine is a subset of the spectrum of blunt trauma pathology, and is common and\n",
      "potentially devastating. Previous reports estimate the number of vertebral fractures\n",
      "each year in the United States at more than 140,000, with 19%-50% of fractures of the\n",
      "thoracolumbar spine associated with neurological injury [1]. Rapid and accurate\n",
      "assessment is essential for determination of an acceptable management algorithm, and\n",
      "delay in detection and management of\n",
      "---\n",
      "236\n",
      "Abstract. Texture–based computerized analysis of high–resolution\n",
      "computed tomography images from patients with interstitial lung diseases\n",
      "is introduced to assist radiologists in image interpretation. The\n",
      "cornerstone of our approach is to learn lung texture signatures using\n",
      "a linear combination of N–th order Riesz templates at multiple scales.\n",
      "The weights of the linear combination are derived from one–versus–all\n",
      "support vector machines. Steerability and multiscale properties of Riesz\n",
      "wavelets allow for scale and rotation covariance of the texture descriptors\n",
      "with infinitesimal precision. Orientations are normalized among texture\n",
      "instances by locally aligning the Riesz templates, which is carried out\n",
      "analytically. The proposed approach is compared with state–of–the–art\n",
      "texture attributes and shows significant improvement in classification\n",
      "performance with an average area under receiver operating characteristic\n",
      "curves of 0.94 for five lung tissue classes. The derived lung texture\n",
      "signatures illustrate optimal class–wise discriminative properties.\n",
      "\n",
      "Abstract. Texture–based computerized analysis of high–resolution\n",
      "computed tomography images from patients with interstitial lung diseases\n",
      "is introduced to assist radiologists in image interpretation. \n",
      "---\n",
      "240\n",
      "In this study, we propose a computational diagnosis system\n",
      "for detecting the colorectal cancer from histopathological slices.The computational\n",
      "analysis was usually performed on patch level where only\n",
      "a small part of the slice is covered. However, slice-based classification\n",
      "is more realistic for histopathological diagnosis.\n",
      "\n",
      "Colorectal cancer is the third most common cancer in both men and women\n",
      "world-wide and is the third leading cause of cancer-related deaths in the Western\n",
      "world [1]. For 2012, 103,000 colon cancer cases and 51,000 colon cancer\n",
      "related deaths are predicted for the United States. Like for many other types\n",
      "of cancer, histopathological analysis is accepted as the gold standard for malignancy\n",
      "diagnosis [2]. The analysis of these data, however, is performed visually\n",
      "and the detection and grading of the suspect tissue may show variability depending\n",
      "on the experience and awareness of the experts. Therefore, various studies\n",
      "have been performed into the development of computer-aided diagnosis systems\n",
      "(CAD) to improve the ability of pathologists at discriminating between malignant\n",
      "and benign tissue.\n",
      "---\n",
      "242\n",
      "Distortion correction is applied to endoscopic duodenal imagery to\n",
      "improve automated classification of celiac disease affected mucosa patches.\n",
      "\n",
      "Computer-aided decision support systems relying on automated analysis of endoscopic\n",
      "imagery receive increasing attention [1].\n",
      "A specific type of degradation, present in all endoscopic images, is a barrel-type\n",
      "distortion. This type of degradation is caused by the wide-angle (fish eye) nature of the\n",
      "optics used in endoscopes.\n",
      "The aim of correcting this distortion in endoscopy is manifold\n",
      "---\n",
      "248\n",
      "the\n",
      "authors analyze the image formation process of phase contrast images\n",
      "and propose an image restoration method based on the dictionary representation\n",
      "of diffraction patterns.\n",
      "\n",
      "Computer-aided image analysis of phase contrast microscopy [1] has attracted\n",
      "increasing attention since it enables long-term monitoring of the proliferation\n",
      "and migration processes of live cells.\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "#column 1: id\n",
    "#column 6: task\n",
    "#column 7: justification\n",
    "\n",
    "demo = df.iloc[:,[1,6,7]]\n",
    "demo.reset_index()\n",
    "\n",
    "\n",
    "for index in range(len(demo)):\n",
    "    print(demo.iloc[index, 0])\n",
    "    print(demo.iloc[index, 1])\n",
    "    print()\n",
    "    print(demo.iloc[index, 2])\n",
    "    print('---')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7682da28",
   "metadata": {},
   "source": [
    "## Affiliations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9509a68a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of articles who acknowledge funding etc:  58\n",
      "69\n",
      "Shanghai Jiao Tong University, Shanghai, China\n",
      "(2)\n",
      "MoE Key Lab of Artificial Intelligence, AI Institute, Shanghai Jiao Tong University, Shanghai, China\n",
      "\n",
      "This work was supported in part by Shanghai Municipal Science and Technology Major Project (2021SHZDZX0102), 111 project (BP0719010), Shanghai Science and Technology Committee (18DZ2270700) and Shanghai Jiao Tong University Science and Technology Innovation Special Fund (ZH2018ZDA17).\n",
      "---\n",
      "72\n",
      "Department of Computer Science, Technical University of Munich, Munich, Germany\n",
      "(2)\n",
      "Department of Quantitative Biomedicine, University of Zurich, Zürich, Switzerland\n",
      "(3)\n",
      "ETH Zurich, Zürich, Switzerland\n",
      "(4)\n",
      "Department of Computer Science and Engineering, Southern University of Science and Technology, Shenzhen, China\n",
      "(5)\n",
      "Faculty of Information Technology, Macau University of Science and Technology, Macao, China\n",
      "(6)\n",
      "Klinikum rechts der Isar, Technical University of Munich, Munich, Germany \n",
      "\n",
      "This work was supported by Helmut Horten Foundation. I. E. was supported by the TRABIT network under the EU Marie Sklodowska-Curie program (Grant ID: 765148). S. L. was supported by the Faculty Research Grant (NO. FRG-18-020-FI) at Macau University of Science and Technology. B. W. and B. M. were supported through the DFG, SFB-824, subproject B12. K. C. was supported by Clinical Research Priority Program (CRPP) Grant on Artificial Intelligence in Oncological Imaging Network, University of Zurich.\n",
      "---\n",
      "73\n",
      "\n",
      "Ministry of Education Key Laboratory of Bioinformatics, Bioinformatics Division, Beijing National Research Center for Information Science and Technology, Department of Automation, Tsinghua University, Beijing, 100084, China\n",
      "(2)\n",
      "Department of Computer Science and Technology, Tsinghua University, Beijing, 100084, China\n",
      "(3)\n",
      "Department of Hepatobiliary and Pancreatic Surgery, The Affiliated Hospital of Qingdao University, Qingdao, 266000, Shandong, China\n",
      "\n",
      "This work was partially supported by the National Key Research and Development Program of China (No. 2018YFC0910404), the National Natural Science Foundation of China (Nos. 61873141, 61721003), the Shanghai Municipal Science and Technology Major Project (No. 2017SHZDZX01), the Tsinghua-Fuzhou Institute for Data Technology, the Taishan Scholars Program of Shandong Province (No. 2019010668), and the Shandong Higher Education Young Science and Technology Support Program (No. 2020KJL005).\n",
      "---\n",
      "74\n",
      "(1)\n",
      "NeuroSpin, CEA Saclay, Université Paris-Saclay, Gif-sur-Yvette, France\n",
      "(2)\n",
      "LTCI, Télécom Paris, IPParis, Paris, France\n",
      "(3)\n",
      "Department of Neuropsychology, Johannes-Gutenberg University of Mainz, Mainz, Germany\n",
      "(4)\n",
      "Department of Neurosciences, Fondazione IRCCS, University of Milan, Milan, Italy\n",
      "(5)\n",
      "Université Grenoble Alpes, Inserm U1216, CHU Grenoble Alpe, Grenoble, France\n",
      "(6)\n",
      "Centre for Neuroimaging and Cognitive Genomics (NICOG), Galway, Ireland\n",
      "(7)\n",
      "Department of Neuroscience, University of Geneva, Geneva, Switzerland\n",
      "(8)\n",
      "Department of Psychiatry, Western Psychiatric Institute, University of Pittsburgh, Pittsburgh, USA\n",
      "(9)\n",
      "Department of Psychiatry, UC San Diego, San Diego, CA, USA\n",
      "\n",
      "This work was granted access to the HPC resources of IDRIS under the allocation 2020-AD011011854 made by GENCI.\n",
      "---\n",
      "78\n",
      "\n",
      "\n",
      "Vanderbilt University, Nashville, TN 37215, USA\n",
      "(2)\n",
      "Vanderbilt University Medical Center, Nashville, TN 37215, USA\n",
      "\n",
      "Dr. Wheless is funded by grants from the Skin Cancer Foundation and the Dermatology Foundation.\n",
      "---\n",
      "92\n",
      "LIST, Key Laboratory of Computer Network and Information Integration (Southeast University), Ministry of Education, Nanjing, China\n",
      "(2)\n",
      "Centre de Recherche en Information Biomédicale Sino-Français (CRIBs), Rennes, France\n",
      "\n",
      "This research was supported by National Natural Science Foundation under grants (31571001, 61828101). We thank the Big Data Center of Southeast University for providing the GPUs to support the numerical calculations in this paper.\n",
      "---\n",
      "94\n",
      "(1)\n",
      "CSAIL, Massachusetts Institute of Technology, Cambridge, MA, USA\n",
      "(2)\n",
      "MIT Lincoln Laboratory, Lexington, MA, USA\n",
      "(3)\n",
      "Beth Israel Deaconess Medical Center, Harvard Medical School, Boston, MA, USA\n",
      "(4)\n",
      "Brigham and Women’s Hospital, Harvard Medical School, Boston, MA, USA\n",
      "\n",
      "This work was supported in part by NIH NIBIB NAC P41EB015902, Wistron, IBM Watson, MIT Deshpande Center, MIT J-Clinic, MIT Lincoln Lab, and US Air Force.\n",
      "---\n",
      "102\n",
      "University of Texas at Arlington, Arlington, USA\n",
      "(2)\n",
      "Lawrence Berkeley National Laboratory, Berkeley, USA\n",
      "(3)\n",
      "Pohang University of Science and Technology, Pohang, South Korea\n",
      "(4)\n",
      "University of North Carolina, Chapel Hill, Chapel Hill, USA\n",
      "\n",
      "This work was supported by GAANN Doctoral Fellowships in Computer Science and Engineering at UTA sponsored by the U.S. Department of Education, NSF IIS CRII 1948510, NIH RF1 AG059312, NIH R03 AG070701, and IITP-2019-0-01906 funded by MSIT (AI Graduate School Program at POSTECH).\n",
      "---\n",
      "106\n",
      "\n",
      "Section for Image Computing, Technical University of Denmark, Kgs. Lyngby, Denmark\n",
      "(2)\n",
      "Physense, Department of Information and Communication Technologies, Universitat Pompeu Fabra, Barcelona, Spain\n",
      "(3)\n",
      "Department of Cardiology, Rigshospitalet, University of Copenhagen, Copenhagen, Denmark\n",
      "\n",
      "This work was supported by a PhD grant from the Technical University of Denmark - Department of Applied Mathematics and Computer Science (DTU Compute) and the Spanish Ministry of Science, Innovation and Universities under the Retos I+D Programme (RTI2018-101193-B-I00).\n",
      "---\n",
      "112\n",
      "\n",
      "Kyushu University, Fukuoka City, Japan\n",
      "(2)\n",
      "National Institute of Informatics, Tokyo, Japan\n",
      "(3)\n",
      "Kyoto Second Red Cross Hospital, Kyoto, Japan\n",
      "\n",
      "This work was supported by JSPS KAKENHI Grant Number JP20H04211 and AMED Grant Number JP20lk1010036h0002.\n",
      "---\n",
      "118\n",
      "Department of Computer Science and Engineering, The Chinese University of Hong Kong, Hong Kong, China\n",
      "(2)\n",
      "Department of Computer Science and Engineering, The Hong Kong University of Science and Technology, Hong Kong, China\n",
      "(3)\n",
      "Imsight AI Research Lab, Shenzhen, China\n",
      "(4)\n",
      "Guangdong-Hong Kong-Macao Joint Laboratory of Human-Machine Intelligence-Synergy Systems, Shenzhen Institutes of Advanced Technology, Chinese Academy of Sciences, Beijing, China\n",
      "\n",
      "This work was supported by Key-Area Research and Development Program of Guangdong Province, China (2020B010165004), Hong Kong Innovation and Technology Fund (Project No. ITS/311/18FP and Project No. ITS/426/17FP.), and National Natural Science Foundation of China with Project No. U1813204.\n",
      "---\n",
      "122\n",
      "Image and Video Processing Laboratory, Department of Electrical and Computer Engineering, Northwestern University, Evanston, IL 60208, USA\n",
      "(2)\n",
      "Depto. Ciencias de la Computacion e I.A., Universidad de Granada, 18071 Granada, Spain\n",
      "\n",
      "This work has received funding from the European Union’s Horizon 2020 research and innovation programme under the Marie Skłodowska Curie grant agreement No 860627 (CLARIFY Project) and also from the Spanish Ministry of Science and Innovation under project PID2019-105142RB-C22.\n",
      "---\n",
      "138\n",
      "\n",
      "Data Science Group, Faculty of Science, Radboud University, Nijmegen, The Netherlands\n",
      "\n",
      "The research leading to these results is part of the project “MARBLE”, funded from the EFRO/OP-Oost under grant number PROJ-00887. Some of the experiments were carried out on the Dutch national e-infrastructure with the support of SURF Cooperative.\n",
      "---\n",
      "139\n",
      "aetherAI, Taipei, Taiwan\n",
      "(2)\n",
      "National Yang Ming Chiao Tung University, Hsinchu, Taiwan\n",
      "\n",
      "We thank Wen-Chien Chou M.D.(National Taiwan University Hospital), Ta-Chuan Yu M.D.(National Taiwan University Hospital Yunlin Branch) and Poshing Lee M.D.(Department of Hematopathology, BioReference) for Hema dataset construction. This paper was supported in part by the Ministry of Science and Technology, Taiwan, under Grants MOST 110-2634-F-007-015 and MOST 109-2221-E-009-113-MY3.\n",
      "---\n",
      "145\n",
      "Department of Electrical and Systems Engineering, University of Pennsylvania, Philadelphia, USA\n",
      "(2)\n",
      "Center for Biomedical Image Computing and Analytics (CBICA), Philadelphia, USA\n",
      "(3)\n",
      "General Robotics, Automation, Sensing and Perception Laboratory (GRASP), Philadelphia, USA\n",
      "(4)\n",
      "Department of Radiology, Perelman School of Medicine, University of Pennsylvania, Philadelphia, USA\n",
      "\n",
      "We thank Ben Glocker, Nick Pawlowski and Daniel C. Castro for suggestions. This work was supported by the National Institute on Aging (grant numbers RF1AG054409 and U01AG068057) and the National Institute of Mental Health (grant number R01MH112070). Pratik Chaudhari would like to acknowledge the support of the Amazon Web Services Machine Learning Research Award.\n",
      "---\n",
      "159\n",
      "Department of Computer Science and Engineering, The Chinese University of Hong Kong, Kowloon, Hong Kong SAR, China\n",
      "(2)\n",
      "Department of Computer Science and Engineering, Beihang University, Beijing, China\n",
      "(3)\n",
      "Shenzhen Key Laboratory of Virtual Reality and Human Interaction Technology, Shenzhen Institutes of Advanced Technology, Chinese Academy of Sciences, Shenzhen, China\n",
      "\n",
      "The work described in this paper was supported in parts by the following grants: Key-Area Research and Development Program of Guangdong Province, China (2020B010165004), Hong Kong Innovation and Technology Fund (Project No. GHP/110/19SZ), Foundation of China with Project No. U1813204 and Shenzhen-HK Collaborative Development Zone.\n",
      "---\n",
      "160\n",
      "Computer Aided Medical Procedures, Technical University of Munich, Munich, Germany\n",
      "(2)\n",
      "Helmholtz AI, Helmholtz Zentrum München, Neuherberg, Germany\n",
      "(3)\n",
      "The Whiting School of Engineering, Johns Hopkins University, Baltimore, USA\n",
      "\n",
      "T.B. is financially supported by the German Academic Exchange Service (DAAD).\n",
      "---\n",
      "161\n",
      "Department of Electrical Engineering, City University of Hong Kong, Kowloon, Hong Kong, China\n",
      "\n",
      "This work is supported by Shenzhen-Hong Kong Innovation Circle Category D Project SGDX2019081623300177 (CityU 9240008) and CityU SRG 7005229.\n",
      "---\n",
      "164\n",
      "Department of Computer Science, University of Oxford, Oxford, UK\n",
      "\n",
      "We would like to thank Huawei Technologies Co., Ltd. for providing GPU computing service for this study.\n",
      "---\n",
      "170\n",
      "Case Western Reserve University, Cleveland, OH 44106, USA\n",
      "(2)\n",
      "Louis Stokes Cleveland VA Medical Center, Cleveland, OH 44106, USA\n",
      "\n",
      "Research supported by NCI (1U24CA199374-01, 1R01CA249992-01A1, 1R01CA202752-01A1, 1R01CA208236-01A1, 1R01CA216579-01A1, 1R01CA220581-01A1, 1R01CA257612-01A1, 1U01CA239055-01, 1U01CA248226-01, 1U54CA254566-01, 1F31CA216935-01A1), NHLBI (R01HL15127701A1), NIBIB (1R43EB028736-01), NCRR (1C06RR12463-01), DOD/CDMRP (W81XWH-19-1-0668, W81XWH-15-1-0558, W81XWH-20-1-0851, W81XWH-18-1-0440, W81XWH-20-1-0595, W81XWH-18-1-0404, CA200789), VA (IBX004121A Merit Review Award), the KPMP Glue Grant, the Ohio Third Frontier Technology Validation Fund, the CTSC of Cleveland (UL1TR0002548), the Wallace H. Coulter Foundation Program in the Department of Biomedical Engineering at Case Western Reserve University, as well as sponsored research agreements from Bristol Myers-Squibb, Boehringer-Ingelheim, and Astrazeneca. Content solely responsibility of the authors and does not necessarily represent the official views of the NIH, USDVA, DOD, or the United States Government.\n",
      "---\n",
      "172\n",
      "Department of Computer Science, University of Freiburg, Freiburg im Breisgau, Germany\n",
      "(2)\n",
      "CIBSS – Centre for Integrative Biological Signalling Studies, University of Freiburg, Freiburg im Breisgau, Germany\n",
      "\n",
      "This study was supported by the Excellence Strategy of the German Federal and State Governments, (CIBSS - EXC 2189).\n",
      "---\n",
      "173\n",
      "Institute for Ophthalmic Research, Tübingen, Germany\n",
      "(2)\n",
      "Tübingen AI Center, Tübingen, Germany\n",
      "(3)\n",
      "University Eye Clinic, University of Tübingen, 72076 Tübingen, Germany\n",
      "\n",
      "We thank Wieland Brendel for his support with BagNets. This research was supported by the German Ministry of Science and Education (BMBF, 01GQ1601 and 01IS18039A) and the German Science Foundation (BE5601/4-2 and EXC 2064, project number 390727645). Hanna Faber received research funding from the Junior Clinician Scientist Program of the Faculty of Medicine, Eberhard Karls University of Tübingen, Germany (application number 463–0–0). Additional funding was provided by Novartis AG through a research grant. The funding bodies did not have any influence in the study planning and design. The authors thank the International Max Planck Research School for Intelligent Systems (IMPRS-IS) for supporting Indu Ilanchezian.\n",
      "---\n",
      "174\n",
      "University of Thessaly, Papasiopoulou str. 2-4, 35131 Lamia, Greece\n",
      "\n",
      "This work was supported in part by the grant No. 5024 of the Special Account of Research Grants of the University of Thessaly, Greece.\n",
      "---\n",
      "180\n",
      "Institute for Systems and Robotics, Instituto Superior Técnico, Lisbon, Portugal\n",
      "\n",
      "This work was supported by the FCT project and multi-year funding [CEECIND/ 00326/2017] and LARSyS - FCT Plurianual funding 2020–2023; and by a Google Research Award’21. The Titan Xp used in this project were donated by the NVIDIA Corporation.\n",
      "---\n",
      "255\n",
      "(1)\r\n",
      "Department of Computer Science and Technology, Peking University, Beijing, China\r\n",
      "(2)\r\n",
      "Peking University, Beijing, China\r\n",
      "(3)\r\n",
      "Deepwise AI Lab, Beijing, China\r\n",
      "(4)\r\n",
      "University of Hong Kong, Pokfulam, Hong Kong   This work was supported by MOST-2018AAA0102004, NSFC-61625201, and the Beijing Municipal Science and Technology Planning Project (Grant No. Z201100005620008).\n",
      "---\n",
      "257\n",
      "(1)\r\n",
      "Center for Data Science, Peking University, Beijing, China\r\n",
      "(2)\r\n",
      "Peking University, Beijing, China\r\n",
      "(3)\r\n",
      "Department of Computer Science and Technology, Peking University, Beijing, China\r\n",
      "(4)\r\n",
      "Deepwise AI Lab, Beijing, China\r\n",
      "(5)\r\n",
      "The University of Hong Kong, Pokfulam, Hong Kong   This work was supported by MOST-2018AAA0102004, NSFC-61625201 and ZheJiang Province Key Research & Development Program (No. 2020C03073).\n",
      "---\n",
      "258\n",
      "This work was supported in part by Shanghai Municipal Science and Technology Major Project (2021SHZDZX0102), 111 project (BP0719010), Shanghai Science and Technology Committee (18DZ2270700) and Shanghai Jiao Tong University Science and Technology Innovation Special Fund (ZH2018ZDA17).\n",
      "---\n",
      "262\n",
      "(1)\n",
      "Shanghai Key Laboratory of Multidimensional Information Processing, School of Communication and Electronic Engineering, East China Normal University, Shanghai, China  This work was supported in part by 2030 National Key Research and Development Program of China (2018AAA0100500), the National Nature Science Foundation of China (no. 61773166), Projects of International Cooperation of Shanghai Municipal Science and Technology Committee (14DZ2260800), the Fundamental Research Funds for the Central Universities, and the ECNU Academic Innovation Promotion Program for Excellent Doctoral Students (YBNLTS2021-040).\n",
      "---\n",
      "266\n",
      "(1)\r\n",
      "Medical Imaging, Robotics, Analytic Computing Laboratory/Engineering (MIRACLE), School of Biomedical Engineering & Suzhou Institute for Advanced Research, University of Science and Technology of China, Suzhou, China\r\n",
      "(2)\r\n",
      "Key Laboratory of Intelligent Information Processing of Chinese Academy of Sciences (CAS), Institute of Computing Technology, CAS, Beijing, China\r\n",
      "(3)\r\n",
      "School of Electronic, Electrical and Communication Engineering, University of the Chinese Academy of Science, Beijing, China\r\n",
      "(4)\r\n",
      "Healthcare Intelligence, AIC, DAMO Academy, Alibaba Group, Hangzhou, China   This research was supported in part by the Natural Science Foundation of China (grant 61732004), Youth Innovation Promotion Association CAS (grant 2018135) and Alibaba Group through Alibaba Innovative Research Program.\n",
      "---\n",
      "267\n",
      "(1)\n",
      "Department of Computer Science, Hong Kong Baptist University, kowloon, Hong Kong  This work was supported by the Health and Medical Research Fund Project under Grant 07180216. We acknowledge insightful discussion with Anthony W.H. CHAN. We also thank Vincent WS WONG, Grace LH WONG, and Howard H.W. LEUNG from the Chinese University of Hong Kong for help with data preparation.\n",
      "---\n",
      "268\n",
      "(1)\r\n",
      "Department of Electronic Engineering, The Chinese University of Hong Kong, Shatin, Hong Kong, China\r\n",
      "(2)\r\n",
      "Department of Information Engineering, The Chinese University of Hong Kong, Shatin, Hong Kong, China\r\n",
      "(3)\r\n",
      "School of Informatics, Xiamen University, Xiamen, China\r\n",
      "(4)\r\n",
      "Department of Electrical Engineering, City University of Hong Kong, Kowloon, Hong Kong, China\r\n",
      "(5)\r\n",
      "Department of Electronic and Electrical Engineering, Southern University of Science and Technology, Shenzhen, China  The work described in this paper was supported by National Key R&D program of China with Grant No. 2019YFB1312400, Hong Kong RGC CRF grant C4063-18G, and Hong Kong RGC GRF grant #14211420.\n",
      "---\n",
      "269\n",
      "(1)\r\n",
      "Department of Radiology and BRIC, University of North Carolina at Chapel Hill, Chapel Hill, NC 27599, USA\r\n",
      "(2)\r\n",
      "Brainnetome Center & National Laboratory of Pattern Recognition, Institute of Automation, Chinese Academy of Sciences, Beijing, 100190, China\r\n",
      "(3)\r\n",
      "State Key Laboratory of Cognitive Neuroscience and Learning, Beijing Normal University, Beijing, 100678, China\r\n",
      "(4)\r\n",
      "School of Computer Science and Technology, East China Normal University, Shanghai, 200241, China   This work was finished when D. Yao was visiting the University of North Carolina at Chapel Hill. D. Yao and M. Liu was partly supported by NIH grant (No. AG041721). Z. Zhang was partly supported by the National Key Research and Development Program of China (No. 2016YFD0700100).\n",
      "---\n",
      "270\n",
      "(1)\n",
      "School of Artificial Intelligence, University of Chinese Academy of Sciences, Beijing, 100149, China\n",
      "(2)\n",
      "NLPR, Institute of Automation, Chinese Academy of Sciences, Beijing, 100190, China\n",
      "(3)\n",
      "Brainnetome Center, Institute of Automation, Chinese Academy of Sciences, Beijing, 100190, China\n",
      "(4)\n",
      "CAS Center for Excellence of Brain Science and Intelligence Technology, Beijing, 100190, China   This work has been supported by the National Key Research and Development Program Grant 2018AAA0100400, the National Natural Science Foundation of China (NSFC) grants 61773376, 61836014, 61721004 and 31870984.\n",
      "---\n",
      "276\n",
      "(1)\n",
      "Department of Radiology and BRIC, University of North Carolina at Chapel Hill, Chapel Hill, NC 27599, USA\n",
      "(2)\n",
      "School of Biomedical Engineering, Southern Medical University, Guangzhou, 510515, China\n",
      "(3)\n",
      "Department of Geriatric Psychiatry, Shanghai Mental Health Center, Shanghai Jiao Tong University School of Medicine, Shanghai, 200030, China    H. Guan and M. Liu were partly supported by NIH grant (No. AG041721).\n",
      "---\n",
      "277\n",
      "(1)\n",
      "Johns Hopkins University, Baltimore, USA\n",
      "(2)\n",
      "PAII Inc., Bethesda, USA\n",
      "(3)\n",
      "PingAn Technology, Shenzhen, China\n",
      "(4)\n",
      "Changhai Hospital, Shanghai, China   Y. Xia—Work done during an internship at PAII Inc.\n",
      "---\n",
      "283\n",
      "(1)\r\n",
      "Bournemouth University, Poole, UK\r\n",
      "(2)\r\n",
      "University of Adelaide, Adelaide, Australia\r\n",
      "(3)\r\n",
      "BCN Medtech, Department of Information and Communication Technologies, Universitat Pompeu Fabra, Barcelona, Spain\r\n",
      "(4)\r\n",
      "Catalan Institution for Research and Advanced Studies (ICREA), Barcelona, Spain    This work was partially supported by a Marie Skłodowska-Curie Global Fellowship (No. 892297) and by Australian Research Council grants (DP180103232 and FT190100525).\n",
      "---\n",
      "284\n",
      "(1)\n",
      "Department of Medical Physics and Biomedical Engineering, University College London, London, UK\n",
      "(2)\n",
      "Wellcome/EPSRC Centre for Interventional and Surgical Sciences (WEISS), University College London, London, UK\n",
      "(3)\n",
      "School of Biomedical Engineering and Imaging Sciences (BMEIS), King’s College London, London, UK\n",
      "(4)\n",
      "Department of Clinical and Experimental Epilepsy, UCL Queen Square Institute of Neurology, London, UK\n",
      "(5)\n",
      "Department of Clinical Neurophysiology, National Hospital for Neurology and Neurosurgery, London, UK\n",
      "\n",
      "This work is supported by the Engineering and Physical Sciences Research Council (EPSRC) [EP/R512400/1]. This work is additionally supported by the EPSRC-funded UCL Centre for Doctoral Training in Intelligent, Integrated Imaging in Healthcare (i4health) [EP/S021930/1] and the Wellcome/EPSRC Centre for Interventional and Surgical Sciences (WEISS, UCL) [203145Z/16/Z]. The data acquisition was supported by the National Institute of Neurological Disorders and Stroke [U01-NS090407].\n",
      "\n",
      "This publication represents, in part, independent research commissioned by the Wellcome Innovator Award [218380/Z/19/Z/]. The views expressed in this publication are those of the authors and not necessarily those of the Wellcome Trust.\n",
      "\n",
      "The weights for the 2D and 3D models were downloaded from TorchVision and https://​github.​com/​moabitcoin/​ig65m-pytorch, respectively.\n",
      "---\n",
      "286\n",
      "(1)\n",
      "School of Electronic Information and Communication, Huazhong University of Science and Technology, Wuhan, China\n",
      "(2)\n",
      "Britton Chance Center for Biomedical Photonics, Wuhan National Laboratory for Optoelectronics, Huazhong University of Science and Technology, Wuhan, China\n",
      "(3)\n",
      "MoE Key Laboratory for Biomedical Photonics, Collaborative Innovation Center for Biomedical Engineering, School of Engineering Sciences, Huazhong University of Science and Technology, Wuhan, China\n",
      "(4)\n",
      "Hong Kong University of Science and Technology, Hong Kong, China\n",
      "(5)\n",
      "Wuhan National Laboratory for Optoelectronics, Huazhong University of Science and Technology, Wuhan, China\n",
      "\n",
      "This work was supported by the National Natural Science Foundation of China (6187241762061160490), the project of Wuhan Science and Technology Bureau (2020010601012167), the Open Project of Wuhan National Laboratory for Optoelectronics (2018WNLOKF025), the Fundamental Research Funds for the Central Universities (2021XXJS033).\n",
      "---\n",
      "288\n",
      "(1)\n",
      "Institute of Intelligent Machines, HFIPS, Chinese Academy of Sciences, Hefei, China\n",
      "(2)\n",
      "University of Science and Technology of China, Hefei, China\n",
      "(3)\n",
      "School of Information Engineering, Zhengzhou University, Zhengzhou, China\n",
      "(4)\n",
      "Nullmax, Shanghai, China\n",
      "(5)\n",
      "The First Affiliated Hospital of USTC, Division of Life Sciences and Medicine, University of Science and Technology of China, Hefei, China\n",
      "\n",
      "This work is supported in part by the grant of NSFC (61804100, 61973294, 61806181), KRDP of Anhui Province (201904a05020086) and CAS (GJTD-2018-15).\n",
      "---\n",
      "290\n",
      "(1)\n",
      "School of Computer Science and Engineering, Sun Yat-sen University, Guangzhou, China\n",
      "(2)\n",
      "Key Laboratory of Machine Intelligence and Advanced Computing, MOE, China\n",
      "(3)\n",
      "Pazhou Lab, Guangzhou, China\n",
      "\n",
      "This work is supported in part by the National Natural Science Foundation of China (grant No. 62071502, U1811461), the Guangdong Key Research and Development Program (grant No. 2020B1111190001, 2019B020228001), and the Meizhou Science and Technology Program (grant No. 2019A0102005).\n",
      "---\n",
      "291\n",
      "(1)\n",
      "School of Computer Science and Engineering, Sun Yat-sen University, Guangzhou, China\n",
      "(2)\n",
      "Key Laboratory of Machine Intelligence and Advanced Computing, MOE, Guangzhou, China\n",
      "\n",
      "This work is supported by the National Natural Science Foundation of China (No. 62071502, U1811461), the Guangdong Key Research and Development Program (No. 2020B1111190001, 2019B020228001), and the Meizhou Science and Technology Program (No. 2019A0102005).\n",
      "---\n",
      "294\n",
      "(1)\n",
      "National Engineering Laboratory for Integrated Aero-Space-Ground-Ocean Big Data Application Technology, School of Computer Science and Engineering, Northwestern Polytechnical University, Xi’an, 710072, Shaanxi, China\n",
      "(2)\n",
      "Research and Development Institute of Northwestern Polytechnical University in Shenzhen, Shenzhen, 518057, China\n",
      "(3)\n",
      "School of Biomedical Engineering, ShanghaiTech University, Shanghai, China\n",
      "(4)\n",
      "Shanghai United Imaging Intelligence Co., Ltd., Shanghai, China\n",
      "\n",
      "This work was supported in part by the National Natural Science Foundation of China under Grants 61771397, in part by the CAAI-Huawei MindSpore Open Fund under Grants CAAIXSJLJJ-2020-005B, and in part by the China Postdoctoral Science Foundation under Grants BX2021333.\n",
      "---\n",
      "297\n",
      "(1)\n",
      "School of Computer Science and Engineering, Sun Yat-sen University, Guangzhou, China\n",
      "(2)\n",
      "Key Laboratory of Machine Intelligence and Advanced Computing, MOE, Guangzhou, China\n",
      "(3)\n",
      "Pazhou Lab, Guangzhou, China\n",
      "\n",
      "This work is supported by the National Natural Science Foundation of China (No. 62071502, U1811461), the Guangdong Key Research and Development Program (No. 2020B1111190001, 2019B020228001), and the Meizhou Science and Technology Program (No. 2019A0102005).\n",
      "---\n",
      "298\n",
      "(1)\n",
      "National Engineering Laboratory for Integrated Aero-Space-Ground-Ocean Big Data Application Technology, School of Computer Science and Engineering, Northwestern Polytechnical University, Xi’an, 710072, Shaanxi, China\n",
      "(2)\n",
      "Research and Development Institute of Northwestern Polytechnical University in Shenzhen, Shenzhen, 518057, China\n",
      "(3)\n",
      "School of Biomedical and Engineering, ShanghaiTech University, Shanghai, 201210, China\n",
      "\n",
      "This work was supported in part by the National Natural Science Foundation of China under Grants 61771397, in part by the CAAI-Huawei MindSpore Open Fund under Grants CAAIXSJLJJ-2020-005B, and in part by the China Postdoctoral Science Foundation under Grants BX2021333.\n",
      "---\n",
      "300\n",
      "(1)\n",
      "Department of Brain and Cognitive Engineering, Korea University, Seoul, Republic of Korea\n",
      "(2)\n",
      "Department of Artificial Intelligence, Korea University, Seoul, Republic of Korea\n",
      "\n",
      "This work was supported by National Research Foundation of Korea (NRF) grant funded by the Korea government (MSIT) (No. 2019R1A2C1006543) and partially by Institute of Information & communications Technology Planning & Evaluation (IITP) grant funded by the Korea government (MSIT) (No. 2019-0-00079, Artificial Intelligence Graduate School Program (Korea University)).\n",
      "---\n",
      "302\n",
      "(1)\n",
      "Xiamen University, Xiamen, China\n",
      "(2)\n",
      "Tencent Jarvis Lab, Shenzhen, China\n",
      "\n",
      "This work was supported by the Fundamental Research Funds for the Central Universities (Grant No. 20720190012), Key-Area Research and Development Program of Guangdong Province, China (No. 2018B010111001), and Scientific  and Technical Innovation 2030 - “New Generation Artificial Intelligence” Project (No. 2020AAA0104100).\n",
      "---\n",
      "308\n",
      "(1)\n",
      "Imperial College London, SW7 2AZ London, UK\n",
      "(2)\n",
      "King’s College London, St Thomas’ Hospital, SE1 7EH London, UK\n",
      "(3)\n",
      "Friedrich–Alexander University Erlangen–Nürnberg, Erlangen, Germany\n",
      "\n",
      "Support from Wellcome Trust IEH Award iFind project [102431] and UK Research and Innovation London Medical Imaging and Artificial Intelligence Centre for Value Based Healthcare. JT was supported by the ICL President’s Scholarship.\n",
      "---\n",
      "309\n",
      "(1)\n",
      "Department of Computer Science, Oklahoma State University, Stillwater, OK, USA\n",
      "(2)\n",
      "Oklahoma Animal Disease Diagnostic Laboratory, College of Veterinary Medicine, Oklahoma State University, Stillwater, OK, USA\n",
      "\n",
      "This research was supported in part by the US Department of Agriculture (USDA) grants AP20VSD and B000C011.\n",
      "\n",
      "We thank Dr. Kitty Cardwell and Dr. Andres Espindola (Institute of Biosecurity and Microbial Forensics, Oklahoma State University) for providing access and assisting with use of the MiFi platform.\n",
      "---\n",
      "310\n",
      "(1)\n",
      "Institute for Infocomm Research, A*STAR, Singapore, Singapore\n",
      "(2)\n",
      "College of Computer Science, Sichuan University, Chengdu, Sichuan, China\n",
      "\n",
      "Research efforts were supported by funding and infrastructure for deep learning and medical imaging research from the Institute for Infocomm Research, Science and Engineering Research Council, A*STAR, Singapore. We thank Victor Getty, Vijay Chandrasekhar and Ivan Ho Mien from the Institute for Infocomm Research, A*STAR for their valuable inputs. We also acknowledge insightful discussions with Jayashree Kalpathy-Cramer at the Massachusetts General Hospital, Boston, USA\n",
      "---\n",
      "311\n",
      "Center for Computational Natural Sciences and Bioinformatics, IIIT Hyderabad, Hyderabad, India\n",
      "\n",
      "This study was supported by funding from IHub-Data and IIIT Hyderabad. We would also like to thank Dr. K Sudarsana Reddy for the discussions we had regarding the theoretical correctness of the method presented.\n",
      "---\n",
      "312\n",
      "(1)\n",
      "Department of Science and Technology, Linkoping University, Linköping, Sweden\n",
      "(2)\n",
      "Center for Medical Image Science and Visualization, Linkoping University, Linköping, Sweden\n",
      "(3)\n",
      "Sectra AB, Linköping, Sweden\n",
      "\n",
      "We would like to thank Martin Lindvall for the interesting discussions and insights into the use of cancer type-specific primary tumor data for lymph node metastasis detection, and Panagiotis Tsirikoglou for the suggestions in results analysis. This work was partially supported by the Wallenberg AI, Autonomous Systems and Software Program (WASP) funded by the Knut and Alice Wallenberg Foundation, the strategic research environment ELLIIT, and the VINNOVA grant 2017-02447 for the Analytic Imaging Diagnostics Arena (AIDA).\n",
      "---\n",
      "313\n",
      "Intelligent Systems Program, School of Computing and Information, University of Pittsburgh, Pittsburgh, PA, USA\n",
      "(2)\n",
      "Department of Radiology, University of Pittsburgh School of Medicine, Pittsburgh, PA, USA\n",
      "(3)\n",
      "Magee-Womens Hospital, University of Pittsburgh Medical Center, Pittsburgh, PA, USA\n",
      "(4)\n",
      "Department of Electrical and Computer Engineering, Swanson School of Engineering, University of Pittsburgh, Pittsburgh, PA, USA\n",
      "(5)\n",
      "Department of Biomedical Informatics and Department of Bioengineering, University of Pittsburgh, Pittsburgh, PA, USA\n",
      "\n",
      "This work was supported by National Institutes of Health grants (1R01CA193603, 3R01CA193603-03S1, and 1R01CA218405), the UPMC Hillman Cancer Center Developmental Pilot Program, and an Amazon Machine Learning Research Award. This work used the Extreme Science and Engineering Discovery Environment (XSEDE), which is supported by National Science Foundation (NSF) grant number ACI-1548562. Specifically, it used the Bridges-2 system, which is supported by NSF award number ACI-1928147, at the Pittsburgh Supercomputing Center (PSC).\n",
      "---\n",
      "314\n",
      "EECS, Vanderbilt University, Nashville, TN 37235, USA\n",
      "(2)\n",
      "Vanderbilt University Medical Center, Nashville, TN 37235, USA\n",
      "\n",
      "This research was supported by NSF CAREER 1452485, R01 EB017230 and R01 CA253923. This study was supported in part by U01 CA196405 to Massion. This project was supported in part by the National Center for Research Resources, Grant UL1 RR024975-01, and is now at the National Center for Advancing Translational Sciences, Grant 2 UL1 TR000445-06. This study was funded in part by the Martineau Innovation Fund Grant through the Vanderbilt-Ingram Cancer Center Thoracic Working Group and NCI Early Detection Research Network 2U01CA152662 to PPM.\n",
      "\n",
      "---\n",
      "318\n",
      "Artificial Intelligence in Medical Imaging (AI-Med), Department of Child and Adolescent Psychiatry, Ludwig-Maximilians-Universität, Munich, Germany\n",
      "\n",
      "This research was supported by the Bavarian State Ministry of Science and the Arts and coordinated by the Bavarian Research Institute for Digital Transformation, and the Federal Ministry of Education and Research in the call for Computational Life Sciences (DeepMentia, 031L0200A).\n",
      "---\n",
      "322\n",
      "aetherAI, Taipei, Taiwan\n",
      "(2)\n",
      "AstraZeneca, London, UK\n",
      "\n",
      "We are grateful to Taiwan’s National Center for High-performance Computing for providing computing resources. We also thank Szu-Hua Chen, M.D. (aetherAI) for valuable advice.\n",
      "---\n",
      "324\n",
      "Department of Medical Biophysics, University of Toronto, Toronto, ON, Canada\n",
      "(2)\n",
      "Department of Medical Imaging, University of Toronto, Toronto, ON, Canada\n",
      "(3)\n",
      "Sunnybrook Research Institute, Toronto, ON, Canada\n",
      "(4)\n",
      "Centre Hospitalier Universitaire de Lyon, Lyon, France\n",
      "\n",
      "\n",
      "The authors would like to thank The Natural Sciences and Engineering Research Council of Canada (NSERC) for funding, and acknowledge the contribution of Drs. Karanicolas, Law and Coburn in helping to create the patient cohort for this study.\n",
      "---\n",
      "329\n",
      "(1)\n",
      "Rensselaer Polytechnic Institute, Troy, NY 12180, USA\n",
      "(2)\n",
      "IBM Research, Almaden Research Center, San Jose, CA 95120, USA\n",
      "(3)\n",
      "Virginia Tech, Blacksburg, VA 24061, USA\n",
      "\n",
      "This work was supported by the Rensselaer-IBM AI ResearchCollaboration, part of the IBM AI Horizons Network.\n",
      "---\n",
      "331\n",
      "\n",
      "Department of Computer Science, Stony Brook University, Stony Brook, NY, USA\n",
      "(2)\n",
      "Department of Biomedical Informatics, Stony Brook University, Stony Brook, NY, USA\n",
      "(3)\n",
      "Department of Radiology, Newark Beth Israel Medical Center, Newark, NJ, USA\n",
      "\n",
      "\n",
      "Reported research was supported by the OVPR and IEDM seed grants, 2020 at Stony Brook University, NIGMS T32GM008444, and NIH 75N92020D00021 (subcontract). The content is solely the responsibility of the authors and does not necessarily represent the official views of the National Institutes of Health.\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "#column 1: id\n",
    "#column 23: affiliations y/n\n",
    "#column 24: who\n",
    "\n",
    "demo = df[df.iloc[:,23] == 'Yes']\n",
    "demo = demo.iloc[:,[1,24]]\n",
    "demo.reset_index()\n",
    "print('Number of articles who acknowledge funding etc: ', len(demo))\n",
    "\n",
    "\n",
    "for index in range(len(demo)):\n",
    "    print(demo.iloc[index, 0])\n",
    "    print(demo.iloc[index, 1])\n",
    "    print('---')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "35d08b59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of articles who don't acknowledge funding etc:  15\n",
      "82\n",
      "The University of Hong Kong, Pok Fu Lam, Hong Kong\n",
      "(2)\n",
      "VoxelCloud Inc., Gayley Avenue 1085, Los Angeles, CA 90024, USA\n",
      "---\n",
      "124\n",
      "\n",
      "Department of Electrical Engineering, Stanford University, Stanford, USA\n",
      "(2)\n",
      "Institute for Computational and Mathematical Engineering, Stanford University, Stanford, USA\n",
      "(3)\n",
      "Department of Computer Science, Stanford University, Stanford, USA\n",
      "(4)\n",
      "Department of Radiology, Stanford University, Stanford, USA\n",
      "(5)\n",
      "Khoury College of Computer Sciences, Northeastern University, Boston, USA\n",
      "(6)\n",
      "Department of Biomedical Data Science, Stanford University, Stanford, USA\n",
      "---\n",
      "265\n",
      "Medical Imaging, Robotics, Analytic Computing Laboratory/Engineering (MIRACLE), School of Biomedical Engineering & Suzhou Institute for Advanced Research, University of Science and Technology of China, Suzhou, China\n",
      "(2)\n",
      "Key Laboratory of Intelligent Information Processing of Chinese Academy of Sciences (CAS), Institute of Computing Technology, CAS, Beijing, China\n",
      "(3)\n",
      "School of Electronic, Electrical and Communication Engineering, University of the Chinese Academy of Science, Beijing, China\n",
      "(4)\n",
      "Healthcare Intelligence, AIC, DAMO Academy, Alibaba Group, Hangzhou, China  Nothing is mentioned\n",
      "---\n",
      "271\n",
      "(1)\n",
      "Stony Brook University, Stony Brook, NY, USA  Nothing is mentioned\n",
      "---\n",
      "278\n",
      "(1)\n",
      "PAII Inc., Bethesda, MD 20817, USA\n",
      "(2)\n",
      "Ruijin Hospital, Shanghai, China\n",
      "(3)\n",
      "Chang Gung Memorial Hospital, Linkou, Taoyuan, Taiwan ROC\n",
      "(4)\n",
      "PingAn Technology, Shenzhen, China  Nothing is mentioned\n",
      "---\n",
      "280\n",
      "(1)\n",
      "Medical Imaging Center, Vingroup Big Data Institute, Hanoi, Vietnam\n",
      "(2)\n",
      "School of Information and Communication Technology, Hanoi University of Science and Technology, Hanoi, Vietnam\n",
      "(3)\n",
      "College of Engineering and Computer Science, VinUniversity, Hanoi, Vietnam\n",
      "(4)\n",
      "Department of Mathematics, Yale University, New Heaven, USA  Nothing is mentioned\n",
      "---\n",
      "287\n",
      "(1)\n",
      "MIT CSAIL, Cambridge, USA\n",
      "(2)\n",
      "Chung Shan Medical University, Taichung, Taiwan\n",
      "---\n",
      "301\n",
      "(1)\n",
      "Tencent AI Lab, Shenzhen, China\n",
      "(2)\n",
      "Peking Union Medical College Hospital, Beijing, China\n",
      "---\n",
      "304\n",
      "(1)\n",
      "Simon Fraser University, Burnaby, Canada\n",
      "(2)\n",
      "Pacific Centre for Reproductive Medicine, Burnaby, Canada\n",
      "---\n",
      "306\n",
      "(1)\n",
      "NEC Laboratories, Beijing, China\n",
      "---\n",
      "315\n",
      ")\n",
      "Department of Computer Science and Information Technology, La Trobe University, Melbourne, Australia\n",
      "(2)\n",
      "Department of Computer Science and Technology, Heilongjiang University, Harbin, China\n",
      "(3)\n",
      "College of Intelligence and Computing, Tianjin University, Tianjin, China\n",
      "(4)\n",
      "Department of Radiation Oncology, Shandong Cancer Hospital and Institute, Shandong First Medical University and Shandong Academy of Medical Sciences, Jinan, China\n",
      "---\n",
      "316\n",
      "Tempus Labs, Inc., Chicago, IL, USA\n",
      "---\n",
      "320\n",
      "Computer Aided Medical Procedures, Technical University of Munich, Munich, Germany\n",
      "(2)\n",
      "Sharif University of Technology, Tehran, Iran\n",
      "(3)\n",
      "Whiting School of Engineering, Johns Hopkins University, Baltimore, USA\n",
      "---\n",
      "321\n",
      "Department of Computer Science and Information Technology, La Trobe University, Melbourne, Australia\n",
      "(2)\n",
      "Department of Radiation Oncology, Shandong Cancer Hospital and Institute, Shandong First Medical University and Shandong Academy of Medical Sciences, Jinan, China\n",
      "(3)\n",
      "College of Intelligence and Computing, Tianjin University, Tianjin, China\n",
      "(4)\n",
      "School of Software Technology, Zhejiang University, Hangzhou, China\n",
      "(5)\n",
      "Department of Computer Science and Technology, Heilongjiang University, Harbin, China\n",
      "---\n",
      "325\n",
      "Department of Computer Science, University of Texas at Dallas, Richardson, TX 75080, USA\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "#column 1: id\n",
    "#column 23: affiliations y/n\n",
    "#column 24: who\n",
    "\n",
    "demo = df[df.iloc[:,23] == 'No']\n",
    "demo = demo.iloc[:,[1,24]]\n",
    "demo.reset_index()\n",
    "print(\"Number of articles who don't acknowledge funding etc: \", len(demo))\n",
    "\n",
    "\n",
    "for index in range(len(demo)):\n",
    "    print(demo.iloc[index, 0])\n",
    "    print(demo.iloc[index, 1])\n",
    "    print('---')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5257a032",
   "metadata": {},
   "source": [
    "## Ethics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d6c739ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of articles who include respect for persons:  8\n",
      "106\n",
      "Participants in all three datasets gave informed consent for use of their data.\n",
      "---\n",
      "173\n",
      "Additionally, we obtained 29 fundus images from patients (11 male, 18 female, all older than 47 years) at the University Eye Hospital with permission of the Institutional Ethics Board. We used these additional images as an independent test set.\n",
      "\n",
      "So not necessarily consent by patients themselves, at least not mentioned, but the ethics board was asked\n",
      "---\n",
      "280\n",
      "Since this research did not impact clinical care, patient consent was waived. To keep patient’s Protected Health Information (PHI) secure, all patient-identifiable information associated with the images has been removed. Several DICOM attributes that are important for evaluating the spine conditions like patient’s age and sex were retained.\n",
      "---\n",
      "301\n",
      "the experiments were implemented on a dataset consisting of 300 CT volumes collected from our collaborating hospitals with approval from the local research ethics committee. \n",
      "\n",
      "Though this does not explicitly mention consent from patients, someone still approved it\n",
      "---\n",
      "308\n",
      " The scans are of volunteers at 18–24 weeks gestation (Ethics: anonymous during review), in a fetal cardiology clinic, where patients are referred to from primary screening and secondary care sites \n",
      "(so only for the second dataset used)\n",
      "---\n",
      "309\n",
      "For constructing the dataset for the training and evaluation of automated metagenome-based pathogen detection, we collected metagenome sequences from 13 Bovine Respiratory Disease Complex (BRDC) lung specimens at a local (name redacted to preserve anonymity) diagnostic laboratory using the DNeasy Blood and Tissue Kit (Qiagen, Hilden, Germany).\n",
      "\n",
      "Mentioning the redacting of the name for privacy\n",
      "---\n",
      "312\n",
      "All three datasets are publicly available for use in legal and ethical medical diagnostics research.\n",
      "\n",
      " In the conducted experiments, the target colon adenocarcinoma dataset consists of data from 37 anonymized patients, \n",
      "---\n",
      "324\n",
      "We used a retrospective cohort of 108 colorectal cancer liver metastases (CRLM) patients that were eligible for hepatic resection and were treated at our institution. Informed consent was waived by the institutional review board.\n",
      "\n",
      "So not necessarily a good thing..\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "#column 1: id\n",
    "#column 25: respect for persons\n",
    "#column 27: benefience\n",
    "#column 29: justice\n",
    "#column 31: law/public interest\n",
    "\n",
    "demo = df[df.iloc[:,25] == 'Yes']\n",
    "demo = demo.iloc[:,[1,26]]\n",
    "demo.reset_index()\n",
    "print('Number of articles who include respect for persons: ', len(demo))\n",
    "\n",
    "\n",
    "for index in range(len(demo)):\n",
    "    print(demo.iloc[index, 0])\n",
    "    print(demo.iloc[index, 1])\n",
    "    print('---')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5755e970",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of articles who include benefience:  2\n",
      "255\n",
      "Experimentally, our CA-Net outperforms the 1st place by a noticeable margin on Kaggle DSB2017 dataset.\n",
      "---\n",
      "257\n",
      "From the introduction: \n",
      "For image-based disease benign/malignant diagnosis, it is crucial to learn the disease-related representation for prediction, due to the necessity of trustworthy (to patients), explainable (to clinicians) and good generalization ability in healthcare.\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "#column 1: id\n",
    "#column 25: respect for persons\n",
    "#column 27: benefience\n",
    "#column 29: justice\n",
    "#column 31: law/public interest\n",
    "\n",
    "demo = df[df.iloc[:,27] == 'Yes']\n",
    "demo = demo.iloc[:,[1,28]]\n",
    "demo.reset_index()\n",
    "print('Number of articles who include beneficence: ', len(demo))\n",
    "\n",
    "\n",
    "for index in range(len(demo)):\n",
    "    print(demo.iloc[index, 0])\n",
    "    print(demo.iloc[index, 1])\n",
    "    print('---')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "044bbedb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of articles who include justice:  0\n"
     ]
    }
   ],
   "source": [
    "#column 1: id\n",
    "#column 25: respect for persons\n",
    "#column 27: benefience\n",
    "#column 29: justice\n",
    "#column 31: law/public interest\n",
    "\n",
    "demo = df[df.iloc[:,29] == 'Yes']\n",
    "demo = demo.iloc[:,[1,30]]\n",
    "demo.reset_index()\n",
    "print('Number of articles who include justice: ', len(demo))\n",
    "\n",
    "\n",
    "for index in range(len(demo)):\n",
    "    print(demo.iloc[index, 0])\n",
    "    print(demo.iloc[index, 1])\n",
    "    print('---')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c0a2952e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of articles who include law/public interest:  45\n",
      "173\n",
      "Our code is available at https://​github.​com/​berenslab/​genderBagNets.\n",
      "---\n",
      "74\n",
      "Our code is made publicly available here.\n",
      "\n",
      "Electronic supplementary material\n",
      "The online version of this chapter (https://​doi.​org/​10.​1007/​978-3-030-87196-3_​6) contains supplementary material, which is available to authorized users.\n",
      "\n",
      "There are several references throughout to the supplementary material\n",
      "\n",
      "From the conclusion: This demonstrates that our model can learn a meaningful and relevant representation of healthy brains which can be used to discriminate patients in small data-sets. An ablation study showed that our method consistently improves upon SimCLR for three different sets of transformations. We also made a step towards a debiased algorithm by demonstrating that our model is less sensitive to the site effect than other SOTA fully supervised algorithms trained from scratch. We think this is still an important issue leading to strong biases in machine learning algorithms and it currently leads to costly harmonization protocols between hospitals during acquisitions. Finally, as a step towards reproducible research, we made our code public and we will release the BHB dataset to the scientific community soon.\n",
      "---\n",
      "321\n",
      "Electronic supplementary material\n",
      "The online version of this chapter (https://​doi.​org/​10.​1007/​978-3-030-87240-3_​69) contains supplementary material, which is available to authorized users\n",
      "---\n",
      "316\n",
      "Electronic supplementary material\n",
      "The online version of this chapter (https://​doi.​org/​10.​1007/​978-3-030-87240-3_​64) contains supplementary material, which is available to authorized users.\n",
      "---\n",
      "309\n",
      "Electronic supplementary material\n",
      "The online version of this chapter (https://​doi.​org/​10.​1007/​978-3-030-87240-3_​57) contains supplementary material, which is available to authorized users.\n",
      "---\n",
      "304\n",
      "Code is available: https://​github.​com/​llockhar/​Embryo-Stage-Onset-Detection.\n",
      "---\n",
      "284\n",
      "The code, models and features dataset are available at https://​github.​com/​fepegar/​gestures-miccai-2021.\n",
      "Electronic supplementary material\n",
      "The online version of this chapter (https://​doi.​org/​10.​1007/​978-3-030-87240-3_​32) contains supplementary material, which is available to authorized users\n",
      "\n",
      "---\n",
      "280\n",
      "Supplementary electronic material\n",
      "---\n",
      "278\n",
      "Supplementary electronic material\n",
      "---\n",
      "258\n",
      "Electronic supplementary material\n",
      "The online version of this chapter (https://​doi.​org/​10.​1007/​978-3-030-87240-3_​6) contains supplementary material, which is available to authorized users.\n",
      "---\n",
      "324\n",
      "A Keras implementation of AMINN is released (https://​github.​com/​martellab-sri/​AMINN).\n",
      "\n",
      "Electronic supplementary material\n",
      "The online version of this chapter (https://​doi.​org/​10.​1007/​978-3-030-87240-3_​72) contains supplementary material, which is available to authorized users.\n",
      "---\n",
      "331\n",
      "Electronic supplementary material\n",
      "The online version of this chapter (https://​doi.​org/​10.​1007/​978-3-030-87240-3_​79) contains supplementary material, which is available to authorized users.\n",
      "---\n",
      "170\n",
      "Electronic supplementary material\n",
      "The online version of this chapter (https://​doi.​org/​10.​1007/​978-3-030-87199-4_​42) contains supplementary material, which is available to authorized users.\n",
      "---\n",
      "106\n",
      "All code is publicly available1.\n",
      "---\n",
      "118\n",
      "(Code is available at https://​github.​com/​LLYXC/​OXnet.).\n",
      "---\n",
      "124\n",
      "Electronic supplementary material\n",
      "The online version of this chapter (https://​doi.​org/​10.​1007/​978-3-030-87196-3_​56) contains supplementary material, which is available to authorized users.\n",
      "---\n",
      "322\n",
      "Electronic supplementary material\n",
      "The online version of this chapter (https://​doi.​org/​10.​1007/​978-3-030-87240-3_​70) contains supplementary material, which is available to authorized users.\n",
      "---\n",
      "320\n",
      "Electronic supplementary material\n",
      "The online version of this chapter (https://​doi.​org/​10.​1007/​978-3-030-87240-3_​68) contains supplementary material, which is available to authorized users.\n",
      "---\n",
      "318\n",
      "Our implementation is available at https://​github.​com/​ai-med/​DAFT.\n",
      "\n",
      "Electronic supplementary material\n",
      "The online version of this chapter (https://​doi.​org/​10.​1007/​978-3-030-87240-3_​66) contains supplementary material, which is available to authorized users.\n",
      "---\n",
      "312\n",
      "Electronic supplementary material\n",
      "The online version of this chapter (https://​doi.​org/​10.​1007/​978-3-030-87240-3_​60) contains supplementary material, which is available to authorized users\n",
      "---\n",
      "311\n",
      "Electronic supplementary material\n",
      "The online version of this chapter (https://​doi.​org/​10.​1007/​978-3-030-87240-3_​59) contains supplementary material, which is available to authorized users.\n",
      "---\n",
      "310\n",
      "Electronic supplementary material\n",
      "The online version of this chapter (https://​doi.​org/​10.​1007/​978-3-030-87240-3_​58) contains supplementary material, which is available to authorized users.\n",
      "---\n",
      "302\n",
      "The source code is available at: https://​github.​com/​SunjHan/​Hybrid-Representation-Learning-Approach-for-Rare-Disease-Classification.\n",
      "---\n",
      "283\n",
      "Code is released at https://​github.​com/​agaldran/​balanced_​mixup\n",
      "---\n",
      "271\n",
      "The code is publicly available on Github\n",
      "---\n",
      "269\n",
      "The table showing the demographics and electronic supplementary material\n",
      "---\n",
      "268\n",
      "Also has supplementary electronic material, but there is a mention of what the supplementary material contains in the text, more info about the datasets, so some of the above questions may have different answers if this was available\n",
      "---\n",
      "266\n",
      "There is a doi in the electronic supplementary material, but still only available behind a paywall and am unsure how much more material is actually provided\n",
      "---\n",
      "262\n",
      "Electronic supplementary material\n",
      "The online version of this chapter (https://​doi.​org/​10.​1007/​978-3-030-87240-3_​10) contains supplementary material, which is available to authorized users.\n",
      "---\n",
      "255\n",
      "To some degree perhaps - though who knows what is actually in this supplementary material?\n",
      "Also no mention is made of the repo/code for reproducibility... \n",
      "Electronic supplementary material\n",
      "The online version of this chapter (https://​doi.​org/​10.​1007/​978-3-030-87240-3_​3) contains supplementary material, which is available to authorized users.\n",
      "---\n",
      "138\n",
      "Electronic supplementary material\n",
      "The online version of this chapter (https://​doi.​org/​10.​1007/​978-3-030-87199-4_​10) contains supplementary material, which is available to authorized users.\n",
      "\n",
      "They actually mention (ish) what is is the supplementary material: \n",
      "5 Experiments\n",
      "Models. We compare four models: the single-view model, the late-join model, and the token-based and pixel-based cross-view transformers. All models use the same ResNet-18 architecture [4] for the convolution and pooling blocks up to the global average pooling layer. We use pre-trained weights on ImageNet, as provided by PyTorch. After global average pooling, we concatenate the feature vectors for both iews and use this as input for a single fully connected layer that computes the output. (See the supplementary material for a detailed view.)\n",
      "\n",
      "The transformer performance was not very sensitive to the number of heads or tokens: all settings produced similar results (see the table in the supplementary results)\n",
      "---\n",
      "139\n",
      "Electronic supplementary material\n",
      "The online version of this chapter (https://​doi.​org/​10.​1007/​978-3-030-87199-4_​11) contains supplementary material, which is available to authorized users.\n",
      "---\n",
      "145\n",
      "This one also includes some mention of what is in the supplementary material\n",
      "\n",
      "Electronic supplementary material\n",
      "The online version of this chapter (https://​doi.​org/​10.​1007/​978-3-030-87199-4_​17) contains supplementary material, which is available to authorized users.\n",
      "\n",
      "Implementation details for the SCM and the classifier, and the best validation log-likelihood for each model are shown in the supplementary material.\n",
      "Detailed demographic information of the datasets is provided in the supplementary material.\n",
      "---\n",
      "159\n",
      "(Code will be made available at https://​github.​com/​liuquande/​FedIRM).\n",
      "---\n",
      "160\n",
      "One of their main contributions is a privacy aspect, keeping used data private, but more on the model level than on the personal level....\n",
      "\n",
      "We also propose the peer anonymization (PA) technique as a core component of $$\\texttt {FedPerl}$$. PA preserves privacy and reduces the communication cost while maintaining the performance without additional complexity. \n",
      "\n",
      "Recently, deep learning-based methods have shown dermatologist-level [5, 24] or superior performance [8, 12, 28] in skin cancer classification. Yet, most of these methods rely on a large curated amount of centralized labeled data, which is usually not available due to privacy issues [16].\n",
      "\n",
      "Our novel peer anonymization (PA) technique, is simple yet effective to anonymize the peer such that it is less prone to model inversion or deanonymization. PA is designed carefully to reduce the communication cost while maintains performance. Nevertheless, a privacy guarantee for aggregated models (not individuals) is an open issue and has not been thoroughly investigated in the community and mathematical analysis is yet to be proven. Generalization to unseen client is yet to be investigated in future work. This includes investigating different approaches to profile the clients in building the community. Further, a dynamic policy of when and which community to approach should be further investigated.\n",
      "\n",
      "also includes github and info about supplementary material\n",
      "(https://​github.​com/​tbdair/​FedPerlV1.​0).\n",
      "\n",
      "Electronic supplementary material\n",
      "The online version of this chapter (https://​doi.​org/​10.​1007/​978-3-030-87199-4_​32) contains supplementary material, which is available to authorized users.\n",
      "\n",
      "Implementation. We opt for EfficientNet as our architecture. Adam for optimization for 500 rounds. The batch size and participation rate were set to 16 & 0.3, respectively. The learning rate, $$\\beta $$, $$\\gamma $$, T were investigated and found best at 0.00005, 0.5, 0.01, and 2, respectively, whereas $$\\tau $$ found best at 0.6 & 0.9 for the federated and local models respectively. Further details in the suppl. material.\n",
      "---\n",
      "161\n",
      "Topic is a solution to the issue of: the patient privacy and ethical concerns impede constructing centralized datasets with increasing size (which have been shown to do well with computer aided diagnosis)\n",
      "\n",
      "The code and dataset are available at https://​github.​com/​CityU-AIM-Group/​PRR-FL.\n",
      "---\n",
      "164\n",
      "Pseudocode included\n",
      "---\n",
      "180\n",
      "The code is available at https://​github.​com/​catarina-barata/​CBIR_​Explainability_​Skin_​Cancer.\n",
      "\n",
      "Electronic supplementary material\n",
      "The online version of this chapter (https://​doi.​org/​10.​1007/​978-3-030-87199-4_​52) contains supplementary material, which is available to authorized users.\n",
      "---\n",
      "69\n",
      "Electronic supplementary material\n",
      "The online version of this chapter (https://​doi.​org/​10.​1007/​978-3-030-87196-3_​1) contains supplementary material, which is available to authorized users.\n",
      "---\n",
      "72\n",
      "Codes are available in https://​github.​com/​hongweilibran/​imbalanced-SSL.\n",
      "\n",
      "Electronic supplementary material\n",
      "The online version of this chapter (https://​doi.​org/​10.​1007/​978-3-030-87196-3_​4) contains supplementary material, which is available to authorized users.\n",
      "\n",
      "\n",
      "We build a 3D convolutional neural network with two bottleneck blocks as the encoder for all experiments (details in Supplementary).\n",
      "---\n",
      "73\n",
      "Our code is available at https://​github.​com/​easonyang1996/​CS-CO.\n",
      "---\n",
      "78\n",
      "The code and data are available at https://​github.​com/​hrlblab/​SimTriplet.\n",
      "---\n",
      "308\n",
      "Code available at https://​github.​com/​jemtan/​PII.\n",
      "---\n",
      "266\n",
      "Their code is freely available on github, link in abstract\n",
      "---\n",
      "257\n",
      "To provide convenience for latter works, we publish our spitted test set of DDSM [2] in supplementary.\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "#column 1: id\n",
    "#column 25: respect for persons\n",
    "#column 27: benefience\n",
    "#column 29: justice\n",
    "#column 31: law/public interest\n",
    "\n",
    "demo = df[df.iloc[:,31] == 'Yes']\n",
    "demo = demo.iloc[:,[1,32]]\n",
    "demo.reset_index()\n",
    "print('Number of articles who include law/public interest: ', len(demo))\n",
    "\n",
    "\n",
    "for index in range(len(demo)):\n",
    "    print(demo.iloc[index, 0])\n",
    "    print(demo.iloc[index, 1])\n",
    "    print('---')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "129caeb0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
