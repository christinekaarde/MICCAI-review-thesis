{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3549e80a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7ec11211",
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading in files\n",
    "df_2012 = pd.read_csv(r'C:\\Users\\chris\\Desktop\\Value-Analysis-Thesis\\mining inital data\\database_miccai_2012.csv')\n",
    "df_2021 = pd.read_csv(r'C:\\Users\\chris\\Desktop\\Value-Analysis-Thesis\\mining inital data\\database_miccai_2021.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7b861175",
   "metadata": {},
   "outputs": [],
   "source": [
    "#removing unnecessary index column\n",
    "df_2012 = df_2012.drop(\"Unnamed: 0\", axis = 1)\n",
    "df_2021 = df_2021.drop(\"Unnamed: 0\", axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "52099382",
   "metadata": {},
   "outputs": [],
   "source": [
    "#first I create a dictionary of the words in the string\n",
    "#having it as a separate method means only running it once\n",
    "def create_string_dic(string):\n",
    "    list_of_words = string.split(\" \")\n",
    "    string_dictionary = {}\n",
    "    for word in list_of_words:\n",
    "        word = word.lower().strip() #making all words lower case and removing all white spaces\n",
    "        if word in string_dictionary: #will return true if word already is assigned a value\n",
    "            string_dictionary[word] = string_dictionary.get(word) + 1\n",
    "        else:\n",
    "            string_dictionary[word] = 1\n",
    "    return string_dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fec3698d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_for_keywords(string_dic, keywords_dic):\n",
    "    running_counter = 0\n",
    "    for word in keywords_dic.keys():\n",
    "        if word in string_dic: #will add value if it exists, otherwise will give the keyword a 0\n",
    "            keywords_dic.get(word).append(string_dic.get(word))\n",
    "            running_counter += string_dic.get(word)\n",
    "            #running_counter += 1\n",
    "        else:\n",
    "            keywords_dic.get(word).append(0)\n",
    "        if 'category' in word: #the last keyword is the category which should\n",
    "            #correspond to the running counter instead of 0 (as I am reasonably sure the word 'category: keyword_category')\n",
    "            #does not occur in the strings I am searching\n",
    "            keywords_dic.get(word)[-1] = (running_counter)\n",
    "\n",
    "    return keywords_dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f42c1b1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#finding the abstracts\n",
    "def find_abstract(year, place):\n",
    "    abstract_list = []\n",
    "    with open(place, \"r\", encoding = 'utf-8') as part:\n",
    "        article = part.read()           \n",
    "        abstracts = [i.start() for i in re.finditer(\"Abstract\", article)]\n",
    "        for index in abstracts: \n",
    "            if year == 2012 and article[index+8] != \"s\": #removing the \"Abstracts\", aka the references in 2012\n",
    "                abstract_list.append(article[index:index+2000])\n",
    "            elif year == 2021 and article[index+9] != \"T\": #removing the references in 2021 (\"abstract track\")\n",
    "                abstract_list.append(article[index:index+2000])\n",
    "    return abstract_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0bf94baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def creating_dic(year, place, df):\n",
    "    #saving the abstract\n",
    "    abstract_list = find_abstract(year, place)\n",
    "    #creating the list of dictionaries for each article\n",
    "    list_of_dic = []\n",
    "    #getting the title to combine with the abstract\n",
    "    titles = df['Title'].to_list()\n",
    "    #combining title and abstract\n",
    "    for index in range(len(titles)):\n",
    "        titles[index] = titles[index] + \" \" + abstract_list[index]\n",
    "    #creating dictionary of strings to search through - only run once(technically)\n",
    "    for title in titles:\n",
    "        list_of_dic.append(create_string_dic(title))\n",
    "    return list_of_dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "006bf8c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dic2012 = creating_dic(2012, r\"C:\\Users\\chris\\Desktop\\Value-Analysis-Thesis\\combining proceedings txt\\miccai_2012_full_txt.txt\", df_2012)\n",
    "dic2021 = creating_dic(2021, r\"C:\\Users\\chris\\Desktop\\Value-Analysis-Thesis\\combining proceedings txt\\miccai_2021_full_txt.txt\", df_2021)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8f580725",
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialising the keyword dictionary and searching the strings for the given key words\n",
    "#creating a dataframe where each column is a keyword and the value is the number of occurences of that word \n",
    "#each row corresponds to the index of the article\n",
    "def generate_keyword_search_df(keywords, list_of_dic):\n",
    "    initial_keywords_dic = {key:[] for key in keywords}\n",
    "    for index in range(len(list_of_dic)):\n",
    "        keyword_dic = (check_for_keywords(list_of_dic[index], initial_keywords_dic))\n",
    "    df = pd.DataFrame(keyword_dic) \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "13372ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading in the keywords file and creating the list of lowercase words to check for\n",
    "def reading_keywords(place):\n",
    "    with open(place, \"r\", encoding = 'utf-8') as part:\n",
    "        string = part.read()\n",
    "        string = string.lower()\n",
    "        keywords = string.split('\\n') \n",
    "    return keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fca3e009",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_rules(df, rules_file):\n",
    "    category = 'category: ' + rules_file[:len(rules_file)-6]\n",
    "    with open(rules_file, \"r\", encoding = 'utf-8') as part:\n",
    "        string = part.read()\n",
    "        string = string.lower()\n",
    "        rules = string.split('\\n') \n",
    "        #don't really like the triple loop, but will do for now..\n",
    "        for index in range(len(df)):\n",
    "            for rule in rules:\n",
    "                threshold = 0\n",
    "                element_exists = True\n",
    "                elements = rule.split(' + ')\n",
    "                for i in range(len(elements)):   \n",
    "                    threshold += df.loc[index, elements[i].strip()]\n",
    "                    if df.loc[index, elements[i].strip()] == 0:\n",
    "                        element_exists = False #if just one isn't there, set to false and do not allow rule to add one\n",
    "                if threshold == len(elements) and element_exists: #meaning each element in the rule was present \n",
    "                    #think this may also react if one word has the same word count as the rule length, so \n",
    "                    #fake adding in rule was present +1 if learning was there twice but one element of the rule is 0\n",
    "                    df.loc[index, category] +=1\n",
    "                           \n",
    "    return df[category]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ef745157",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_and_check(keywords_list, rules_list, dic):\n",
    "    #checking the classification keywords first and their rules\n",
    "    dfA = check_rules(generate_keyword_search_df(reading_keywords(keywords_list[0]), dic), rules_list[0])\n",
    "    #then checking the other keywords and their rules\n",
    "    dfB = check_rules(generate_keyword_search_df(reading_keywords(keywords_list[1]), dic), rules_list[1])\n",
    "    \n",
    "    #merging the two found dataframes\n",
    "    df = pd.merge(dfA, dfB, right_index = True, left_index = True)\n",
    "    \n",
    "    #adding the category of the column with the most highest value found in the search\n",
    "    category = df.idxmax(axis = 1)\n",
    "    category.name = 'category'\n",
    "    df= df.join(category)\n",
    "    #doing the threshold check to add the unknown category for both columns less than two (meaning low indication of either)\n",
    "    #or same value in both columns (meaning no indiation either way)\n",
    "    df = threshold_check(df)\n",
    "    #only the final category series is returned (to be added to original database)\n",
    "    \n",
    "    return df['category']\n",
    "    #return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f42e1bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def threshold_check(df):\n",
    "    unknown = 'category: unknown'\n",
    "    for i in range(len(df)):\n",
    "        if df.iloc[i, 0] < 2 and df.iloc[i, 1] < 2: #checking if both columns are below 2, meaning low indication of either category\n",
    "            df.loc[i, 'category'] = unknown\n",
    "        elif df.iloc[i, 0] == df.iloc[i, 1]: #adding a check if they are the same, then no indication either way\n",
    "            df.loc[i, 'category'] = unknown\n",
    "    return df  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b88f8ccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords_list= ['classification keywords', 'other keywords']\n",
    "rules_list = ['classification rules', 'other rules']\n",
    "\n",
    "df2012_category=search_and_check(keywords_list, rules_list, dic2012)\n",
    "df2021_category=search_and_check(keywords_list, rules_list, dic2021)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d128650d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#adding the newly found categories\n",
    "df_2012 = df_2012.join(df2012_category)\n",
    "df_2021 = df_2021.join(df2021_category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5297a465",
   "metadata": {},
   "outputs": [],
   "source": [
    "#filtering on classification only to be saved as a csv\n",
    "df2012_class = df_2012[df_2012['category'] == 'category: classification']\n",
    "df2021_class = df_2021[df_2021['category'] == 'category: classification']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4627b47c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving updated classification only database to csv\n",
    "df2012_class.to_csv(\"database_miccai_2012_with_cat.csv\")\n",
    "df2021_class.to_csv(\"database_miccai_2021_with_cat.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "52e2e6fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "90"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_2012[df_2012['category'] == 'category: classification'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9c18ed2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "101"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_2012[df_2012['category'] == 'category: other'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f5b673d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "61"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_2012[df_2012['category'] == 'category: unknown'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "582f4008",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "286"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_2021[df_2021['category'] == 'category: classification'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5ec9c6a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "175"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_2021[df_2021['category'] == 'category: other'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b11e2709",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "70"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_2021[df_2021['category'] == 'category: unknown'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1a90295",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
