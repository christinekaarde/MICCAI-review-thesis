{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8ac42d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ab29b4cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#helper function to find lines in html document with DOI and titles of articles\n",
    "def has_doi(href):\n",
    "    return href and re.compile(\"chapter/\").search(href)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "08810aeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mining(html_doc, year):\n",
    "    #opening the html document (copy pasted and saved as a .doc file)\n",
    "    doc = open(html_doc)\n",
    "    #parsing the document\n",
    "    soup = BeautifulSoup(doc, 'html.parser')\n",
    "        \n",
    "    list_of_doi = soup.find_all(href=has_doi)\n",
    "        \n",
    "    #getting the titles and the doi's from list generated helper function\n",
    "\n",
    "    titles = []\n",
    "    doi_str = []\n",
    "\n",
    "    for element in list_of_doi:\n",
    "        titles.append(element.get_text()) #returns the titles as the only text in the list\n",
    "        string = str(element)\n",
    "        first_substring = '/chapter'\n",
    "        second_substring ='\">'\n",
    "        doi_str.append(string[(string.find(first_substring)):string.find(second_substring)]) #separates out the DOIS\n",
    "            \n",
    "    ## now the lines containing author are found\n",
    "    authors = soup.find_all(\"li\", class_=\"c-author-list__item\")\n",
    "        \n",
    "    #keeping only the author names\n",
    "    authors_str = []\n",
    "    for element in authors:\n",
    "        string = str(element)\n",
    "        first_substring = 'item\">'\n",
    "        second_substring ='</li>'\n",
    "        authors_str.append(string[(string.find(first_substring)+6):string.find(second_substring)])\n",
    "            \n",
    "    #now the lines containing page numbers are found\n",
    "    page_numbers= soup.find_all('div', class_ = \"c-meta\")\n",
    "        \n",
    "    #keeping only the page numbers\n",
    "    page_numbers_str = []\n",
    "\n",
    "    for element in page_numbers:\n",
    "        string = element.get_text()[6:-1] #removes the white spaces and \"Pages \"\n",
    "        both = string.split(\"-\")\n",
    "        if int(both[1])-int(both[0]) > 1: #checks that the article spans more than one page\n",
    "            page_numbers_str.append(string)\n",
    "       #am still missing a how to filter out the front/back matters!\n",
    "                \n",
    "    #a check that I've found the same amount of authors, titles, dois and page numbers\n",
    "    #can be commented out if it works\n",
    "    print('page', len(page_numbers_str))\n",
    "    print('author', len(authors_str))\n",
    "    print('title', len(titles))\n",
    "    print('doi', len(doi_str))\n",
    "    print(page_numbers_str)\n",
    "    if len(page_numbers_str) == len(authors_str) == len(titles) == len(doi_str):\n",
    "        print(\"true\")\n",
    "    else:\n",
    "        print(\"You have an error!\")\n",
    "            \n",
    "    #need to create a list of the year of publication to add to dataframe \n",
    "    year_of_pub = []\n",
    "    for element in titles:\n",
    "        year_of_pub.append(year)\n",
    "            \n",
    "    data = {'Title': titles,\n",
    "        'Authors': authors_str,\n",
    "        'Page numbers' : page_numbers_str,\n",
    "        'DOI': doi_str,\n",
    "        'Year of publication' : year_of_pub\n",
    "        }\n",
    "\n",
    "    df = pd.DataFrame(data)\n",
    "\n",
    "    #df.to_csv(str(document)+'.csv')\n",
    "\n",
    "    return df #note that this will only return the last df - could be changed to add previous to this one and return the final full version?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "768f75cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#helper function to combine all df together\n",
    "def data_together(data, year):\n",
    "    combined_frame = pd.concat(data, ignore_index = True, sort = False)\n",
    "    combined_frame.to_csv('miccai_'+ str(year) +'.csv')\n",
    "    return combined_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f54e99a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Authors</th>\n",
       "      <th>Page numbers</th>\n",
       "      <th>DOI</th>\n",
       "      <th>Year of publication</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Reliable Assessment of Perfusivity and Diffusi...</td>\n",
       "      <td>M. Freiman, S. D. Voss, R. V. Mulkern, J. M. P...</td>\n",
       "      <td>Pages 1-9</td>\n",
       "      <td>/chapter/10.1007/978-3-642-33415-3_1</td>\n",
       "      <td>2012.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Multi-organ Abdominal CT Segmentation Using Hi...</td>\n",
       "      <td>Robin Wolz, Chengwen Chu, Kazunari Misawa, Ken...</td>\n",
       "      <td>Pages 10-17</td>\n",
       "      <td>/chapter/10.1007/978-3-642-33415-3_2</td>\n",
       "      <td>2012.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Radiation-Free Drill Guidance in Interlocking ...</td>\n",
       "      <td>Benoit Diotte, Pascal Fallavollita, Lejing Wan...</td>\n",
       "      <td>Pages 18-25</td>\n",
       "      <td>/chapter/10.1007/978-3-642-33415-3_3</td>\n",
       "      <td>2012.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Developing Essential Rigid-Flexible Outer Shea...</td>\n",
       "      <td>Siyang Zuo, Takeshi Ohdaira, Kenta Kuwana, Yos...</td>\n",
       "      <td>Pages 26-33</td>\n",
       "      <td>/chapter/10.1007/978-3-642-33415-3_4</td>\n",
       "      <td>2012.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Surgical Gesture Classification from Video Data</td>\n",
       "      <td>BenjamÃ­n BÃ©jar Haro, Luca Zappella, RenÃ© Vidal</td>\n",
       "      <td>Pages 34-41</td>\n",
       "      <td>/chapter/10.1007/978-3-642-33415-3_5</td>\n",
       "      <td>2012.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>An Invariant Shape Representation Using the An...</td>\n",
       "      <td>A. A. Joshi, S. Ashrafulla, D. W. Shattuck, H....</td>\n",
       "      <td>Pages 607-614</td>\n",
       "      <td>/chapter/10.1007/978-3-642-33454-2_75</td>\n",
       "      <td>2012.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>Phase Contrast Image Restoration via Dictionar...</td>\n",
       "      <td>Hang Su, Zhaozheng Yin, Takeo Kanade, Seungil Huh</td>\n",
       "      <td>Pages 615-622</td>\n",
       "      <td>/chapter/10.1007/978-3-642-33454-2_76</td>\n",
       "      <td>2012.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>Context-Constrained Multiple Instance Learning...</td>\n",
       "      <td>Yan Xu, Jianwen Zhang, Eric I-Chao Chang, Maod...</td>\n",
       "      <td>Pages 623-630</td>\n",
       "      <td>/chapter/10.1007/978-3-642-33454-2_77</td>\n",
       "      <td>2012.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>Structural-Flow Trajectories for Unravelling 3...</td>\n",
       "      <td>Katerina Fragkiadaki, Weiyu Zhang, Jianbo Shi,...</td>\n",
       "      <td>Pages 631-638</td>\n",
       "      <td>/chapter/10.1007/978-3-642-33454-2_78</td>\n",
       "      <td>2012.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252</th>\n",
       "      <td>Online Blind Calibration of Non-uniform Photod...</td>\n",
       "      <td>Nicolas Savoire, Barbara AndrÃ©, Tom Vercauteren</td>\n",
       "      <td>Pages 639-646</td>\n",
       "      <td>/chapter/10.1007/978-3-642-33454-2_79</td>\n",
       "      <td>2012.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>253 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Title  \\\n",
       "0    Reliable Assessment of Perfusivity and Diffusi...   \n",
       "1    Multi-organ Abdominal CT Segmentation Using Hi...   \n",
       "2    Radiation-Free Drill Guidance in Interlocking ...   \n",
       "3    Developing Essential Rigid-Flexible Outer Shea...   \n",
       "4      Surgical Gesture Classification from Video Data   \n",
       "..                                                 ...   \n",
       "248  An Invariant Shape Representation Using the An...   \n",
       "249  Phase Contrast Image Restoration via Dictionar...   \n",
       "250  Context-Constrained Multiple Instance Learning...   \n",
       "251  Structural-Flow Trajectories for Unravelling 3...   \n",
       "252  Online Blind Calibration of Non-uniform Photod...   \n",
       "\n",
       "                                               Authors   Page numbers  \\\n",
       "0    M. Freiman, S. D. Voss, R. V. Mulkern, J. M. P...      Pages 1-9   \n",
       "1    Robin Wolz, Chengwen Chu, Kazunari Misawa, Ken...    Pages 10-17   \n",
       "2    Benoit Diotte, Pascal Fallavollita, Lejing Wan...    Pages 18-25   \n",
       "3    Siyang Zuo, Takeshi Ohdaira, Kenta Kuwana, Yos...    Pages 26-33   \n",
       "4    BenjamÃ­n BÃ©jar Haro, Luca Zappella, RenÃ© Vidal    Pages 34-41   \n",
       "..                                                 ...            ...   \n",
       "248  A. A. Joshi, S. Ashrafulla, D. W. Shattuck, H....  Pages 607-614   \n",
       "249  Hang Su, Zhaozheng Yin, Takeo Kanade, Seungil Huh  Pages 615-622   \n",
       "250  Yan Xu, Jianwen Zhang, Eric I-Chao Chang, Maod...  Pages 623-630   \n",
       "251  Katerina Fragkiadaki, Weiyu Zhang, Jianbo Shi,...  Pages 631-638   \n",
       "252   Nicolas Savoire, Barbara AndrÃ©, Tom Vercauteren  Pages 639-646   \n",
       "\n",
       "                                       DOI  Year of publication  \n",
       "0     /chapter/10.1007/978-3-642-33415-3_1               2012.0  \n",
       "1     /chapter/10.1007/978-3-642-33415-3_2               2012.0  \n",
       "2     /chapter/10.1007/978-3-642-33415-3_3               2012.0  \n",
       "3     /chapter/10.1007/978-3-642-33415-3_4               2012.0  \n",
       "4     /chapter/10.1007/978-3-642-33415-3_5               2012.0  \n",
       "..                                     ...                  ...  \n",
       "248  /chapter/10.1007/978-3-642-33454-2_75               2012.0  \n",
       "249  /chapter/10.1007/978-3-642-33454-2_76               2012.0  \n",
       "250  /chapter/10.1007/978-3-642-33454-2_77               2012.0  \n",
       "251  /chapter/10.1007/978-3-642-33454-2_78               2012.0  \n",
       "252  /chapter/10.1007/978-3-642-33454-2_79               2012.0  \n",
       "\n",
       "[253 rows x 5 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#saving all 2012 together as one with the helper function above\n",
    "miccai =['miccai 2012 part 1 page 1 of 5.doc', 'miccai 2012 part 1 page 2 of 5.doc', \n",
    "         'miccai 2012 part 1 page 3 of 5.doc' , 'miccai 2012 part 1 page 4 of 5.doc', \n",
    "         'miccai 2012 part 1 page 5 of 5.doc', 'miccai 2012 part 2 page 1 of 5.doc', \n",
    "         'miccai 2012 part 2 page 2 of 5.doc', 'miccai 2012 part 2 page 3 of 5.doc' ,\n",
    "         'miccai 2012 part 2 page 4 of 5.doc', 'miccai 2012 part 2 page 5 of 5.doc', \n",
    "         'miccai 2012 part 3 page 1 of 5.doc', 'miccai 2012 part 3 page 2 of 5.doc', \n",
    "         'miccai 2012 part 3 page 3 of 5.doc' , 'miccai 2012 part 3 page 4 of 5.doc', \n",
    "         'miccai 2012 part 3 page 5 of 5.doc']\n",
    "\n",
    "data = []\n",
    "for element in miccai:  \n",
    "    data.append(mining(element, 2012))\n",
    "\n",
    "data_together(data, 2012)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "80bacf7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page 18\n",
      "author 18\n",
      "title 18\n",
      "doi 18\n",
      "['Pages 3-13', 'Pages 14-24', 'Pages 25-35', 'Pages 36-46', 'Pages 47-56', 'Pages 57-67', 'Pages 68-77', 'Pages 78-88', 'Pages 89-98', 'Pages 99-108', 'Pages 109-119', 'Pages 120-130', 'Pages 131-141', 'Pages 142-152', 'Pages 153-163', 'Pages 164-174', 'Pages 175-185', 'Pages 186-195']\n",
      "true\n",
      "page 20\n",
      "author 20\n",
      "title 20\n",
      "doi 20\n",
      "['Pages 196-205', 'Pages 206-216', 'Pages 217-228', 'Pages 229-238', 'Pages 239-249', 'Pages 250-260', 'Pages 261-270', 'Pages 271-281', 'Pages 282-292', 'Pages 293-303', 'Pages 304-314', 'Pages 315-325', 'Pages 326-336', 'Pages 337-347', 'Pages 348-357', 'Pages 358-368', 'Pages 369-378', 'Pages 379-388', 'Pages 389-399', 'Pages 400-409']\n",
      "true\n",
      "page 20\n",
      "author 20\n",
      "title 20\n",
      "doi 20\n",
      "['Pages 410-419', 'Pages 420-430', 'Pages 431-441', 'Pages 442-450', 'Pages 451-460', 'Pages 461-470', 'Pages 471-481', 'Pages 482-492', 'Pages 493-502', 'Pages 503-513', 'Pages 514-524', 'Pages 525-535', 'Pages 536-547', 'Pages 548-558', 'Pages 559-568', 'Pages 569-578', 'Pages 579-588', 'Pages 589-599', 'Pages 600-610', 'Pages 611-621']\n",
      "true\n",
      "page 12\n",
      "author 12\n",
      "title 12\n",
      "doi 12\n",
      "['Pages 622-632', 'Pages 633-643', 'Pages 644-655', 'Pages 656-667', 'Pages 668-677', 'Pages 678-688', 'Pages 689-698', 'Pages 699-708', 'Pages 709-719', 'Pages 720-730', 'Pages 731-741', 'Pages C1-C1']\n",
      "true\n",
      "page 18\n",
      "author 18\n",
      "title 18\n",
      "doi 18\n",
      "['Pages 3-12', 'Pages 13-24', 'Pages 25-35', 'Pages 36-46', 'Pages 47-57', 'Pages 58-68', 'Pages 69-79', 'Pages 80-89', 'Pages 90-101', 'Pages 102-112', 'Pages 113-123', 'Pages 124-133', 'Pages 134-144', 'Pages 145-154', 'Pages 155-165', 'Pages 166-176', 'Pages 177-188', 'Pages 189-198']\n",
      "true\n",
      "page 20\n",
      "author 19\n",
      "title 19\n",
      "doi 19\n",
      "['Pages 199-209', 'Pages 210-220', 'Pages 221-230', 'Pages 231-241', 'Pages 242-251', 'Pages 252-261', 'Pages 262-272', 'Pages 273-283', 'Pages 284-293', 'Pages 295-295', 'Pages 297-306', 'Pages 307-317', 'Pages 318-329', 'Pages 330-340', 'Pages 341-351', 'Pages 352-361', 'Pages 362-372', 'Pages 373-382', 'Pages 383-393', 'Pages 394-404']\n",
      "You have an error!\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "All arrays must be of the same length",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_9628/224079780.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0melement\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmiccai\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 29\u001b[1;33m     \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmining\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0melement\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2021\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     30\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[0mdata_together\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2021\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_9628/713507783.py\u001b[0m in \u001b[0;36mmining\u001b[1;34m(html_doc, year)\u001b[0m\n\u001b[0;32m     72\u001b[0m         }\n\u001b[0;32m     73\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 74\u001b[1;33m     \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     75\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     76\u001b[0m     \u001b[1;31m#df.to_csv(str(document)+'.csv')\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    612\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    613\u001b[0m             \u001b[1;31m# GH#38939 de facto copy defaults to False only in non-dict cases\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 614\u001b[1;33m             \u001b[0mmgr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdict_to_mgr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtyp\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmanager\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    615\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMaskedArray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    616\u001b[0m             \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmrecords\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mmrecords\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\construction.py\u001b[0m in \u001b[0;36mdict_to_mgr\u001b[1;34m(data, index, columns, dtype, typ, copy)\u001b[0m\n\u001b[0;32m    462\u001b[0m         \u001b[1;31m# TODO: can we get rid of the dt64tz special case above?\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    463\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 464\u001b[1;33m     return arrays_to_mgr(\n\u001b[0m\u001b[0;32m    465\u001b[0m         \u001b[0marrays\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata_names\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtyp\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtyp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconsolidate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    466\u001b[0m     )\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\construction.py\u001b[0m in \u001b[0;36marrays_to_mgr\u001b[1;34m(arrays, arr_names, index, columns, dtype, verify_integrity, typ, consolidate)\u001b[0m\n\u001b[0;32m    117\u001b[0m         \u001b[1;31m# figure out the index, if necessary\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    118\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mindex\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 119\u001b[1;33m             \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_extract_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    120\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    121\u001b[0m             \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mensure_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\construction.py\u001b[0m in \u001b[0;36m_extract_index\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m    633\u001b[0m             \u001b[0mlengths\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mraw_lengths\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    634\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 635\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"All arrays must be of the same length\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    636\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    637\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhave_dicts\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: All arrays must be of the same length"
     ]
    }
   ],
   "source": [
    "#saving all 2021 together as one with the helper function above\n",
    "miccai =['miccai 2021 part 1 page 1 of 4.doc', 'miccai 2021 part 1 page 2 of 4.doc', \n",
    "         'miccai 2021 part 1 page 3 of 4.doc' , 'miccai 2021 part 1 page 4 of 4.doc', \n",
    "         \n",
    "         'miccai 2021 part 2 page 1 of 4.doc', 'miccai 2021 part 2 page 2 of 4.doc', \n",
    "         'miccai 2021 part 2 page 3 of 4.doc' , 'miccai 2021 part 2 page 4 of 4.doc',\n",
    "         \n",
    "         'miccai 2021 part 3 page 1 of 4.doc', 'miccai 2021 part 3 page 2 of 4.doc', \n",
    "         'miccai 2021 part 3 page 3 of 4.doc' , 'miccai 2021 part 3 page 4 of 4.doc',\n",
    "         \n",
    "        'miccai 2021 part 4 page 1 of 4.doc', 'miccai 2021 part 4 page 2 of 4.doc', \n",
    "         'miccai 2021 part 4 page 3 of 4.doc' , 'miccai 2021 part 4 page 4 of 4.doc',\n",
    "         \n",
    "        'miccai 2021 part 5 page 1 of 5.doc', 'miccai 2021 part 5 page 2 of 5.doc', \n",
    "         'miccai 2021 part 5 page 3 of 5.doc' , 'miccai 2021 part 5 page 4 of 5.doc', \n",
    "         'miccai 2021 part 5 page 5 of 5.doc',\n",
    "        \n",
    "        'miccai 2021 part 6 page 1 of 4.doc', 'miccai 2021 part 6 page 2 of 4.doc', \n",
    "         'miccai 2021 part 6 page 3 of 4.doc' , 'miccai 2021 part 6 page 4 of 4.doc',\n",
    "        \n",
    "        'miccai 2021 part 7 page 1 of 5.doc', 'miccai 2021 part 7 page 2 of 5.doc', \n",
    "         'miccai 2021 part 7 page 3 of 5.doc' , 'miccai 2021 part 7 page 4 of 5.doc', \n",
    "         'miccai 2021 part 7 page 5 of 5.doc', \n",
    "        \n",
    "        'miccai 2021 part 8 page 1 of 2.doc', 'miccai 2021 part 8 page 2 of 2.doc']\n",
    "\n",
    "data = []\n",
    "for element in miccai:  \n",
    "    data.append(mining(element, 2021))\n",
    "\n",
    "data_together(data, 2021)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ed87cd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "miccai =['miccai 2021 part 1 page 1 of 4.doc', 'miccai 2021 part 1 page 2 of 4.doc', \n",
    "         'miccai 2021 part 1 page 3 of 4.doc' , 'miccai 2021 part 1 page 4 of 4.doc', \n",
    "         \n",
    "         'miccai 2021 part 2 page 1 of 4.doc', 'miccai 2021 part 2 page 2 of 4.doc', \n",
    "         'miccai 2021 part 2 page 3 of 4.doc' , 'miccai 2021 part 2 page 4 of 4.doc',\n",
    "         \n",
    "         'miccai 2021 part 3 page 1 of 4.doc', 'miccai 2021 part 3 page 2 of 4.doc', \n",
    "         'miccai 2021 part 3 page 3 of 4.doc' , 'miccai 2021 part 3 page 4 of 4.doc',\n",
    "         \n",
    "        'miccai 2021 part 4 page 1 of 4.doc', 'miccai 2021 part 4 page 2 of 4.doc', \n",
    "         'miccai 2021 part 4 page 3 of 4.doc' , 'miccai 2021 part 4 page 4 of 4.doc',\n",
    "         \n",
    "        'miccai 2021 part 5 page 1 of 5.doc', 'miccai 2021 part 5 page 2 of 5.doc', \n",
    "         'miccai 2021 part 5 page 3 of 5.doc' , 'miccai 2021 part 5 page 4 of 5.doc', \n",
    "         'miccai 2021 part 5 page 5 of 5.doc',\n",
    "        \n",
    "        'miccai 2021 part 6 page 1 of 4.doc', 'miccai 2021 part 6 page 2 of 4.doc', \n",
    "         'miccai 2021 part 6 page 3 of 4.doc' , 'miccai 2021 part 6 page 4 of 4.doc',\n",
    "        \n",
    "        'miccai 2021 part 7 page 1 of 5.doc', 'miccai 2021 part 7 page 2 of 5.doc', \n",
    "         'miccai 2021 part 7 page 3 of 5.doc' , 'miccai 2021 part 7 page 4 of 5.doc', \n",
    "         'miccai 2021 part 7 page 5 of 5.doc', \n",
    "        \n",
    "        'miccai 2021 part 8 page 1 of 2.doc', 'miccai 2021 part 8 page 2 of 2.doc']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
