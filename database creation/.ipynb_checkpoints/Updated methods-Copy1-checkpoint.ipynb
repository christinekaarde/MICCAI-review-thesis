{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3549e80a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7ec11211",
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading in files\n",
    "df_2012 = pd.read_csv(r'C:\\Users\\chris\\Desktop\\Value-Analysis-Thesis\\mining inital data\\database_miccai_2012.csv')\n",
    "df_2021 = pd.read_csv(r'C:\\Users\\chris\\Desktop\\Value-Analysis-Thesis\\mining inital data\\database_miccai_2021.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7b861175",
   "metadata": {},
   "outputs": [],
   "source": [
    "#removing unnecessary index column\n",
    "df_2012 = df_2012.drop(\"Unnamed: 0\", axis = 1)\n",
    "df_2021 = df_2021.drop(\"Unnamed: 0\", axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "52099382",
   "metadata": {},
   "outputs": [],
   "source": [
    "#first I create a dictionary of the words in the string\n",
    "#having it as a separate method means only running it once\n",
    "def create_string_dic(string):\n",
    "    list_of_words = string.split(\" \")\n",
    "    string_dictionary = {}\n",
    "    for word in list_of_words:\n",
    "        word = word.lower().strip() #making all words lower case and removing all white spaces\n",
    "        if word in string_dictionary: #will return true if word already is assigned a value\n",
    "            string_dictionary[word] = string_dictionary.get(word) + 1\n",
    "        else:\n",
    "            string_dictionary[word] = 1\n",
    "    return string_dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fec3698d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_for_keywords(string_dic, keywords_dic):\n",
    "    running_counter = 0\n",
    "    for word in keywords_dic.keys():\n",
    "        if word in string_dic: #will add value if it exists, otherwise will give the keyword a 0\n",
    "            keywords_dic.get(word).append(string_dic.get(word))\n",
    "            running_counter += string_dic.get(word)\n",
    "        else:\n",
    "            keywords_dic.get(word).append(0)\n",
    "        if 'category' in word: #the last keyword is the category which should\n",
    "            #correspond to the running counter instead of 0 (as I am reasonably sure the word 'category: keyword_category')\n",
    "            #does not occur in the strings I am searching\n",
    "            keywords_dic.get(word)[-1] = (running_counter)\n",
    "\n",
    "    return keywords_dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f42c1b1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#finding the abstracts\n",
    "def find_abstract(year, place):\n",
    "    abstract_list = []\n",
    "    with open(place, \"r\", encoding = 'utf-8') as part:\n",
    "        article = part.read()           \n",
    "        abstracts = [i.start() for i in re.finditer(\"Abstract\", article)]\n",
    "        for index in abstracts: \n",
    "            if year == 2012 and article[index+8] != \"s\": #removing the \"Abstracts\", aka the references in 2012\n",
    "                abstract_list.append(article[index:index+2000])\n",
    "            elif year == 2021 and article[index+9] != \"T\": #removing the references in 2021 (\"abstract track\")\n",
    "                abstract_list.append(article[index:index+2000])\n",
    "    return abstract_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0bf94baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def creating_dic(year, place, df):\n",
    "    #saving the abstract\n",
    "    abstract_list = find_abstract(year, place)\n",
    "    #creating the list of dictionaries for each article\n",
    "    list_of_dic = []\n",
    "    #getting the title to combine with the abstract\n",
    "    titles = df['Title'].to_list()\n",
    "    #combining title and abstract\n",
    "    for index in range(len(titles)):\n",
    "        titles[index] = titles[index] + \" \" + abstract_list[index]\n",
    "    #creating dictionary of strings to search through - only run once(technically)\n",
    "    for title in titles:\n",
    "        list_of_dic.append(create_string_dic(title))\n",
    "    return list_of_dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "006bf8c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dic2012 = creating_dic(2012, r\"C:\\Users\\chris\\Desktop\\Value-Analysis-Thesis\\combining proceedings txt\\miccai_2012_full_txt.txt\", df_2012)\n",
    "dic2021 = creating_dic(2021, r\"C:\\Users\\chris\\Desktop\\Value-Analysis-Thesis\\combining proceedings txt\\miccai_2021_full_txt.txt\", df_2021)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8f580725",
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialising the keyword dictionary and searching the strings for the given key words\n",
    "#creating a dataframe where each column is a keyword and the value is the number of occurences of that word \n",
    "#each row corresponds to the index of the article\n",
    "def generate_keyword_search_df(keywords, list_of_dic):\n",
    "    initial_keywords_dic = {key:[] for key in keywords}\n",
    "    for index in range(len(list_of_dic)):\n",
    "        keyword_dic = (check_for_keywords(list_of_dic[index], initial_keywords_dic))\n",
    "    df = pd.DataFrame(keyword_dic) \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "13372ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading in the keywords file and creating the list of lowercase words to check for\n",
    "def reading_keywords(place):\n",
    "    with open(place, \"r\", encoding = 'utf-8') as part:\n",
    "        string = part.read()\n",
    "        string = string.lower()\n",
    "        keywords = string.split('\\n') \n",
    "    return keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fca3e009",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_rules(df, rules_file):\n",
    "    category = 'category: ' + rules_file[:len(rules_file)-6]\n",
    "    with open(rules_file, \"r\", encoding = 'utf-8') as part:\n",
    "        string = part.read()\n",
    "        string = string.lower()\n",
    "        rules = string.split('\\n') \n",
    "        for index in range(len(df)):\n",
    "            for rule in rules:\n",
    "                threshold = 0\n",
    "                element_exists = True\n",
    "                elements = rule.split(' + ')\n",
    "                for i in range(len(elements)):   \n",
    "                    threshold += df.loc[index, elements[i].strip()]\n",
    "                    if df.loc[index, elements[i].strip()] == 0:\n",
    "                        element_exists = False #if just one isn't there, set to false and do not allow rule to add one\n",
    "                        break \n",
    "                if element_exists == False:\n",
    "                    break #no need to look at other elements of a rule if one already isn't there\n",
    "                elif threshold == len(elements) and element_exists: #meaning each element in the rule was present \n",
    "                    df.loc[index, category] +=1\n",
    "                           \n",
    "    return df[category]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ef745157",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_and_check(keywords_list, rules_list, dic):\n",
    "    #checking the classification keywords first and their rules\n",
    "    dfA = check_rules(generate_keyword_search_df(reading_keywords(keywords_list[0]), dic), rules_list[0])\n",
    "    #then checking the other keywords and their rules\n",
    "    dfB = check_rules(generate_keyword_search_df(reading_keywords(keywords_list[1]), dic), rules_list[1])\n",
    "    \n",
    "    #merging the two found dataframes\n",
    "    df = pd.merge(dfA, dfB, right_index = True, left_index = True)\n",
    "    \n",
    "    #adding the category of the column with the most highest value found in the search\n",
    "    category = df.idxmax(axis = 1)\n",
    "    category.name = 'category'\n",
    "    df= df.join(category)\n",
    "    #doing the threshold check to add the unknown category for both columns less than two (meaning low indication of either)\n",
    "    #or same value in both columns (meaning no indiation either way)\n",
    "    df = threshold_check(df)\n",
    "    #only the final category series is returned (to be added to original database)\n",
    "    \n",
    "    return df['category']\n",
    "    #return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f42e1bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def threshold_check(df):\n",
    "    unknown = 'category: unknown'\n",
    "    for i in range(len(df)):\n",
    "        if df.iloc[i, 0] < 2 and df.iloc[i, 1] < 2: #checking if both columns are below 2, meaning low indication of either category\n",
    "            df.loc[i, 'category'] = unknown\n",
    "        elif df.iloc[i, 0] == df.iloc[i, 1]: #adding a check if they are the same, then no indication either way\n",
    "            df.loc[i, 'category'] = unknown\n",
    "    return df  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b88f8ccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords_list= ['classification keywords', 'other keywords']\n",
    "rules_list = ['classification rules', 'other rules']\n",
    "\n",
    "df2012_category=search_and_check(keywords_list, rules_list, dic2012)\n",
    "df2021_category=search_and_check(keywords_list, rules_list, dic2021)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d128650d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#adding the newly found categories\n",
    "df_2012 = df_2012.join(df2012_category)\n",
    "df_2021 = df_2021.join(df2021_category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "4627b47c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving updated database to csv\n",
    "#df_2012.to_csv(\"database_miccai_2012_with_cat.csv\")\n",
    "#df_2021.to_csv(\"database_miccai_2021_with_cat.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c1a90295",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Authors</th>\n",
       "      <th>Page numbers</th>\n",
       "      <th>DOI</th>\n",
       "      <th>Year of publication</th>\n",
       "      <th>Part of publication</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Reliable Assessment of Perfusivity and Diffusi...</td>\n",
       "      <td>M. Freiman, S. D. Voss, R. V. Mulkern, J. M. P...</td>\n",
       "      <td>1-9</td>\n",
       "      <td>/chapter/10.1007/978-3-642-33415-3_1</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>1</td>\n",
       "      <td>category: other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Multi-organ Abdominal CT Segmentation Using Hi...</td>\n",
       "      <td>Robin Wolz, Chengwen Chu, Kazunari Misawa, Ken...</td>\n",
       "      <td>10-17</td>\n",
       "      <td>/chapter/10.1007/978-3-642-33415-3_2</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>1</td>\n",
       "      <td>category: other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Radiation-Free Drill Guidance in Interlocking ...</td>\n",
       "      <td>Benoit Diotte, Pascal Fallavollita, Lejing Wan...</td>\n",
       "      <td>18-25</td>\n",
       "      <td>/chapter/10.1007/978-3-642-33415-3_3</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>1</td>\n",
       "      <td>category: unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Developing Essential Rigid-Flexible Outer Shea...</td>\n",
       "      <td>Siyang Zuo, Takeshi Ohdaira, Kenta Kuwana, Yos...</td>\n",
       "      <td>26-33</td>\n",
       "      <td>/chapter/10.1007/978-3-642-33415-3_4</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>1</td>\n",
       "      <td>category: unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Surgical Gesture Classification from Video Data</td>\n",
       "      <td>Benjamín Béjar Haro, Luca Zappella, René Vidal</td>\n",
       "      <td>34-41</td>\n",
       "      <td>/chapter/10.1007/978-3-642-33415-3_5</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>1</td>\n",
       "      <td>category: classification</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>An Invariant Shape Representation Using the An...</td>\n",
       "      <td>A. A. Joshi, S. Ashrafulla, D. W. Shattuck, H....</td>\n",
       "      <td>607-614</td>\n",
       "      <td>/chapter/10.1007/978-3-642-33454-2_75</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>3</td>\n",
       "      <td>category: classification</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>Phase Contrast Image Restoration via Dictionar...</td>\n",
       "      <td>Hang Su, Zhaozheng Yin, Takeo Kanade, Seungil Huh</td>\n",
       "      <td>615-622</td>\n",
       "      <td>/chapter/10.1007/978-3-642-33454-2_76</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>3</td>\n",
       "      <td>category: classification</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>Context-Constrained Multiple Instance Learning...</td>\n",
       "      <td>Yan Xu, Jianwen Zhang, Eric I-Chao Chang, Maod...</td>\n",
       "      <td>623-630</td>\n",
       "      <td>/chapter/10.1007/978-3-642-33454-2_77</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>3</td>\n",
       "      <td>category: other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>Structural-Flow Trajectories for Unravelling 3...</td>\n",
       "      <td>Katerina Fragkiadaki, Weiyu Zhang, Jianbo Shi,...</td>\n",
       "      <td>631-638</td>\n",
       "      <td>/chapter/10.1007/978-3-642-33454-2_78</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>3</td>\n",
       "      <td>category: other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>Online Blind Calibration of Non-uniform Photod...</td>\n",
       "      <td>Nicolas Savoire, Barbara André, Tom Vercauteren</td>\n",
       "      <td>639-646</td>\n",
       "      <td>/chapter/10.1007/978-3-642-33454-2_79</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>3</td>\n",
       "      <td>category: unknown</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>252 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Title  \\\n",
       "0    Reliable Assessment of Perfusivity and Diffusi...   \n",
       "1    Multi-organ Abdominal CT Segmentation Using Hi...   \n",
       "2    Radiation-Free Drill Guidance in Interlocking ...   \n",
       "3    Developing Essential Rigid-Flexible Outer Shea...   \n",
       "4      Surgical Gesture Classification from Video Data   \n",
       "..                                                 ...   \n",
       "247  An Invariant Shape Representation Using the An...   \n",
       "248  Phase Contrast Image Restoration via Dictionar...   \n",
       "249  Context-Constrained Multiple Instance Learning...   \n",
       "250  Structural-Flow Trajectories for Unravelling 3...   \n",
       "251  Online Blind Calibration of Non-uniform Photod...   \n",
       "\n",
       "                                               Authors Page numbers  \\\n",
       "0    M. Freiman, S. D. Voss, R. V. Mulkern, J. M. P...          1-9   \n",
       "1    Robin Wolz, Chengwen Chu, Kazunari Misawa, Ken...        10-17   \n",
       "2    Benoit Diotte, Pascal Fallavollita, Lejing Wan...        18-25   \n",
       "3    Siyang Zuo, Takeshi Ohdaira, Kenta Kuwana, Yos...        26-33   \n",
       "4       Benjamín Béjar Haro, Luca Zappella, René Vidal        34-41   \n",
       "..                                                 ...          ...   \n",
       "247  A. A. Joshi, S. Ashrafulla, D. W. Shattuck, H....      607-614   \n",
       "248  Hang Su, Zhaozheng Yin, Takeo Kanade, Seungil Huh      615-622   \n",
       "249  Yan Xu, Jianwen Zhang, Eric I-Chao Chang, Maod...      623-630   \n",
       "250  Katerina Fragkiadaki, Weiyu Zhang, Jianbo Shi,...      631-638   \n",
       "251    Nicolas Savoire, Barbara André, Tom Vercauteren      639-646   \n",
       "\n",
       "                                       DOI  Year of publication  \\\n",
       "0     /chapter/10.1007/978-3-642-33415-3_1               2012.0   \n",
       "1     /chapter/10.1007/978-3-642-33415-3_2               2012.0   \n",
       "2     /chapter/10.1007/978-3-642-33415-3_3               2012.0   \n",
       "3     /chapter/10.1007/978-3-642-33415-3_4               2012.0   \n",
       "4     /chapter/10.1007/978-3-642-33415-3_5               2012.0   \n",
       "..                                     ...                  ...   \n",
       "247  /chapter/10.1007/978-3-642-33454-2_75               2012.0   \n",
       "248  /chapter/10.1007/978-3-642-33454-2_76               2012.0   \n",
       "249  /chapter/10.1007/978-3-642-33454-2_77               2012.0   \n",
       "250  /chapter/10.1007/978-3-642-33454-2_78               2012.0   \n",
       "251  /chapter/10.1007/978-3-642-33454-2_79               2012.0   \n",
       "\n",
       "     Part of publication                  category  \n",
       "0                      1           category: other  \n",
       "1                      1           category: other  \n",
       "2                      1         category: unknown  \n",
       "3                      1         category: unknown  \n",
       "4                      1  category: classification  \n",
       "..                   ...                       ...  \n",
       "247                    3  category: classification  \n",
       "248                    3  category: classification  \n",
       "249                    3           category: other  \n",
       "250                    3           category: other  \n",
       "251                    3         category: unknown  \n",
       "\n",
       "[252 rows x 7 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_2012"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "237d1e8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "99"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_2012[df_2012['category'] == 'category: other'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "644844f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "91"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_2012[df_2012['category'] == 'category: classification'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0e43cae0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "62"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_2012[df_2012['category'] == 'category: unknown'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9c6d4820",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "175"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_2021[df_2021['category'] == 'category: other'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4086826f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "71"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_2021[df_2021['category'] == 'category: unknown'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "35a8673e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "285"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_2021[df_2021['category'] == 'category: classification'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb391557",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
