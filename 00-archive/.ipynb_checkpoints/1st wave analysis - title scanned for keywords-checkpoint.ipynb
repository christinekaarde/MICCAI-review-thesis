{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b7e01b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "412a4b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading in the files\n",
    "\n",
    "df_2012 = pd.read_csv(r'C:\\Users\\chris\\Desktop\\Value-Analysis-Thesis\\mining inital data\\database_miccai_2012.csv')\n",
    "df_2021 = pd.read_csv(r'C:\\Users\\chris\\Desktop\\Value-Analysis-Thesis\\mining inital data\\database_miccai_2021.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "feaed3d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#removing unnecessary index column\n",
    "df_2012 = df_2012.drop(\"Unnamed: 0\", axis = 1)\n",
    "df_2021 = df_2021.drop(\"Unnamed: 0\", axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "de309d00",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 252 entries, 0 to 251\n",
      "Data columns (total 6 columns):\n",
      " #   Column               Non-Null Count  Dtype  \n",
      "---  ------               --------------  -----  \n",
      " 0   Title                252 non-null    object \n",
      " 1   Authors              252 non-null    object \n",
      " 2   Page numbers         252 non-null    object \n",
      " 3   DOI                  252 non-null    object \n",
      " 4   Year of publication  252 non-null    float64\n",
      " 5   Part of publication  252 non-null    int64  \n",
      "dtypes: float64(1), int64(1), object(4)\n",
      "memory usage: 13.8+ KB\n"
     ]
    }
   ],
   "source": [
    "#dropping erratum article from 2012\n",
    "df_2012.drop(df_2012[df_2012[\"Title\"].str.contains(\"Erratum\")].index, inplace = True)\n",
    "df_2012.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "61b78600",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 531 entries, 0 to 530\n",
      "Data columns (total 6 columns):\n",
      " #   Column               Non-Null Count  Dtype \n",
      "---  ------               --------------  ----- \n",
      " 0   Title                531 non-null    object\n",
      " 1   Authors              531 non-null    object\n",
      " 2   Page numbers         531 non-null    object\n",
      " 3   DOI                  531 non-null    object\n",
      " 4   Year of publication  531 non-null    int64 \n",
      " 5   Part of publication  531 non-null    int64 \n",
      "dtypes: int64(2), object(4)\n",
      "memory usage: 29.0+ KB\n"
     ]
    }
   ],
   "source": [
    "#dropping corrections to articles from 2021 - still one more article found than according to \n",
    "#description on Springer!\n",
    "\n",
    "df_2021.drop(df_2021[df_2021[\"Title\"].str.contains(\"Correction to\")].index, inplace=True)\n",
    "df_2021.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ee164616",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Fairness in Cardiac MR Image Analysis: An Investigation of Bias Due to Data Imbalance in Deep Learning Based SegmentatiCardiac MR Image Analysis: An Investigation of Bias Due to Data Imbalance in Deep Learning Based Segmentation'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#fixing two found errors with wierd strings in titles\n",
    "#df_2021.loc[167]\n",
    "wrong_title = df_2021.at[167, 'Title']\n",
    "start = wrong_title[0:wrong_title.find(\"$\")-1]\n",
    "end = wrong_title[wrong_title.find(\"$\")+13:]\n",
    "\n",
    "right_title = start + end\n",
    "right_title\n",
    "\n",
    "df_2021['Title'] = df_2021['Title'].replace([wrong_title], right_title)\n",
    "df_2021.at[167, 'Title']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0a8cd4d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'y'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df_2021.loc[329]\n",
    "wrong_title = df_2021.at[329, 'Title']\n",
    "\n",
    "right_title = wrong_title[(wrong_title.find(\"Auditing\")):]\n",
    "\n",
    "\n",
    "df_2021['Title'] = df_2021['Title'].replace([wrong_title], right_title)\n",
    "df_2021.at[329, 'Title']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fa84b105",
   "metadata": {},
   "outputs": [],
   "source": [
    "#looks at the titles and checks if the word classification, prediction or detection are present\n",
    "#creates a list of 0's and 1's accordingly\n",
    "\n",
    "#need to rework this completely! \n",
    "def title_analysis(df, keywords):\n",
    "    class_list = []\n",
    "    i = 0\n",
    "    for index in df['Title']:\n",
    "        for word in keywords:\n",
    "            if index.lower().find(word) > 0:\n",
    "                class_list[i].append(1) #now appends for each instance, so for the one's where it finds multiple words, adds each time\n",
    "            else:\n",
    "                class_list[i].append(0)\n",
    "        \n",
    "    \n",
    "    #going back over the list and checking for segmentation + prediction/detection and changing to a 0 if so\n",
    "    #should also change this??\n",
    "    i = 0\n",
    "    for index in df['Title']:\n",
    "        if index.lower().find(\"segmentation\") > 0 and index.lower().find(\"prediction\") > 0:\n",
    "            class_list[i] = 0\n",
    "        elif index.lower().find(\"segmentation\") > 0 and index.lower().find(\"detection\") > 0:\n",
    "            class_list[i] = 0\n",
    "        i = i+1\n",
    "    \n",
    "    df['Keywords in title'] = class_list\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "148f9e6d",
   "metadata": {},
   "outputs": [
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'i' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_14576/4014061135.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mkeywords\u001b[0m\u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'classification'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'prediction'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'detection'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mdf_2012\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mtitle_analysis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_2012\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkeywords\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_14576/4074369056.py\u001b[0m in \u001b[0;36mtitle_analysis\u001b[1;34m(df, keywords)\u001b[0m\n\u001b[0;32m     10\u001b[0m                 \u001b[0mclass_list\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#now appends for each instance, so for the one's where it finds multiple words, adds each time\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m                 \u001b[0mclass_list\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[1;31m#going back over the list and checking for segmentation + prediction/detection and changing to a 0 if so\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mUnboundLocalError\u001b[0m: local variable 'i' referenced before assignment"
     ]
    }
   ],
   "source": [
    "#calls method for inital title analysis and adds list to the dataframe\n",
    "keywords= ['classification', 'prediction', 'detection']\n",
    "\n",
    "df_2012= title_analysis(df_2012, keywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "748bba88",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0             32\n",
       "Title                  32\n",
       "Authors                32\n",
       "Page numbers           32\n",
       "DOI                    32\n",
       "Year of publication    32\n",
       "Keywords in title      32\n",
       "dtype: int64"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#apparently this found 32 articles\n",
    "df_2012[df_2012['Keywords in title'] == 1].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "406208bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#now replicating for 2021\n",
    "\n",
    "classification_list = titleAnalysis(df_2021)\n",
    "\n",
    "df_2021['Keywords in title'] = classification_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f7b3aef4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0             100\n",
       "Title                  100\n",
       "Authors                100\n",
       "Page numbers           100\n",
       "DOI                    100\n",
       "Year of publication    100\n",
       "Keywords in title      100\n",
       "dtype: int64"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#found 100 articles in 2021\n",
    "df_2021[df_2021['Keywords in title'] == 1].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f80516af",
   "metadata": {},
   "outputs": [],
   "source": [
    "#this should probably output an edited csv for next section to work on!\n",
    "df_2012.to_csv(\"database_miccai_2012_first_wave.csv\")\n",
    "df_2021.to_csv(\"database_miccai_2021_first_wave.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7988032d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
