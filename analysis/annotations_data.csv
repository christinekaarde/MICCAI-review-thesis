Tidsstempel,What is the article's index?,Which year is the article from?,Is the article accurately labelled as classification?,"If not accurately labelled as classification, what would you label it as?",Please input the quote from which you infer the answer to the previous question (if possible),What is the aim or task of the article? (input quote),How does the article justify this aim or task? (input quote),Which method is used for classification?,Which performance measures are used? ,Does the article use segmentation as preprocessing?,Please input the quote from which you infer the answer to the previous question (if possible),Does the dataset used in the article have a title?,Please input the quote from which you infer the answer to the previous question (if possible),What is the size of the used dataset? (input quote),What type is the dataset?,Please input the quote from which you infer the answer to the previous question (if possible),Is the survey/method of how the dataset was obtained accessible?,Please input the quote from which you infer the answer to the previous question (if possible),Does the article mention the demographics of the patients/images included in the used dataset?,Please input the quote from which you infer the answer to the previous question (if possible),Does the article mention the intent for collecting the dataset? The intended task for the dataset?,Please input the quote from which you infer the answer to the previous question (if possible),Does the article disclose any affiliations?,Please input the quote from which you infer the answer to the previous question (if possible),"Does the article include anything about respect for persons (informed consent, voluntary participation) participating in the dataset? ",Please input the quote from which you infer the answer to the previous question (if possible),"Does the article have any mention of benefience, minimising risk/maximising benefit of work? ",Please input the quote from which you infer the answer to the previous question (if  possible),"Does the article have any mention of justice (equal treatment, fair selection of subjects)?",Please input the quote from which you infer the answer to the previous question (if  possible),"Does the article mention any respect for law/public interest (transparency in methods/results, accountability for actions)?",Please input the quote from which you infer the answer to the previous question (if  possible),Are there any other comments/interesting aspects?
22/09/2022 13.28.08,4,2012,Yes,It was accurately labelled,we propose and evaluate three approaches to surgical gesture classification from video.,surgical gesture analysis,"Most of the prior work on surgical gesture recognition (see, e.g., [4-6]) uses hidden Markov models (HMMs) to analyze kinematic data stored by the robot (…) Overall, our main conclusion is that methods based on video data perform equally well as methods based n kinematic data for a typical surgical training setup."," linear dynamical system, bag of features,  multiple kernel learning",Accuracy,No,"There is no mention of segmentation, but the article does write: ""We assume that each video is segmented into video surgemes"", so the segmentation has been done",Yes,"""For our tests we used the California dataset [3].""","""The dataset consists of three different tasks: suturing (SU, 39 trials), needle passing (NP, 26 trials) and knot tying (KT, 36 trials). Each task is performed by 8 surgeons with different skill levels.""",Private,"There is no mention of a public dataset, and the article writes ""The authors thank Intuitive Surgical and Carol Reiley for providing the dataset""",No,searching for the dataset yields no results,No,"no mention of demographics, though the article does specify that ""Each task is performed by 8 surgeons with different skill levels""",No,the article contains no mention of intent of data collection,Yes,"Center for Imaging Science, Johns Hopkins University  This work was funded by NSF grants 0931805 and 0941362, and by the Talentia Fellowships Programme of the Andalusian Regional Ministry of Economy, Innovation and Science",No, the article contains no information about the surgeons in the dataset or the patients they were presumably operating on,No,"the focus of the article is to promote a new method, mode of analysis, and does not mention any risk or benefit other than the usefulness of this new method",No,there is no mention of this,No,there is no mention of this,
22/09/2022 13.43.26,7,2012,Yes,It was accurately labelled,"Second, the classifier learning process does
not rely on pre-labeled training samples, but rather the training samples are extracted
from the test image itself using structural priors on relative cup and disc
positions. Third, we present a classification refinement scheme that utilizes both
structural priors and local context.",We present a superpixel based learning framework based on retinal structure priors for glaucoma diagnosis.,It is critical to detect this degeneration of the optic nerve as early as possible in order to stall its progression,SVM,accuracy,Yes,"In this work, we utilize the stateof-the-art SLIC (Simple Linear Iterative Clustering) algorithm [12] to segment the fundus disc image into compact and nearly uniform superpixels.",Yes,using a large clinical dataset called ORIGA−light,"For testing we use the ORIGA−light dataset, comprised of 168 glaucoma and 482 normal images.",Public,"Is searchable, available upon request",No,"But the dataset is available upon request, so perhaps this information is also",No,only size is mentioned,No,no mention of intent in article,Yes,"1 Institute for Infocomm Research, Agency for Science, Technology and Research, Singapore
2 Microsoft Research Asia, P.R. China
3 School of Computer Engineering, Nanyang Technological University, Singapore
4 Singapore Eye Research Institute, Singapore
5 Department of Ophthalmology, National University of Singapore, Singapore  This work is funded by Singapore A*STAR SERC Grant (092-148-00731)",No,article contains no mention of patients ,No,"no direct mention, simply mentions the method proposed gets a level of ""accuracy is comparable to or higher than the state-of-the-art technique [1], with a speedup factor of tens or hundreds.""",No,no mention of patients,Yes,"no mention of law/transparency - though they do mention ""The settings in [1] are also adopted in this work to facilitate comparisons"", so based on what that says, maybe",
26/09/2022 09.18.32,9,2012,Yes,It was accurately labelled,"Automatic detection of lung tumors and abnormal lymph
nodes are useful in assisting lung cancer staging. This paper presents a
novel detection method, by first identifying all abnormalities, then differentiating
between lung tumors and abnormal lymph nodes based on their
degree of overlap with the lung field and mediastinum.","our aim of this study is to develop a computerized method to detect
the lung tumors and abnormal lymph nodes from PET-CT thoracic images automatically.","In this work, we propose a new and intuitive idea to the detection problem –
after attempting to detect all abnormalities, if we can identify the actual lung
field (tumors inclusive), then we can differentiate lung tumors and abnormal
lymph nodes based on the degree of overlap between the detected abnormality
and the lung field.",Graph analysis,"Accuracy, Precision, Recall",No,"The PET-CT thoracic images are first preprocessed to remove the background
and soft tissues outside of the lung and mediastinum with morphological operations.
All images are then aligned based on the carina of tracheae, and rescaled
to the same size [4]. Next, the abnormalities are detected by classification of
lung field (L), mediastinum (M) or abnormalities (O) (Fig. 1c), based on PET
uptake values and CT densities.",No,"The experiment is performed on 50 sets of 3D PET-CT thoracic
images from patients with non-small cell lung cancer (NSCLC), provided by
the Royal Prince Alfred Hospital, Sydney.","A total of 54 lung tumors and 35
abnormal lymph nodes are annotated as the ground truth. For each data set,
the contour of lung field is also roughly delineated. Five images representing
the typical cases are selected manually as the training set for both structure
labeling and classification between tumors and lymph nodes. The data sets are
then randomly divided into five sets; and within each set, each image is used as
the testing image, with the other nine as the reference images.",Private,"The experiment is performed on 50 sets of 3D PET-CT thoracic
images from patients with non-small cell lung cancer (NSCLC), provided by
the Royal Prince Alfred Hospital, Sydney.",No,"The experiment is performed on 50 sets of 3D PET-CT thoracic
images from patients with non-small cell lung cancer (NSCLC), provided by
the Royal Prince Alfred Hospital, Sydney.",No,Nothing is mentioned in the article,No,Nothing is mentioned in the article,No,"Biomedical and Multimedia Information Technology (BMIT) Research Group,
School of Information Technologies, University of Sydney, Australia
2 The Russell H. Morgan Department of Radiology and Radiological Science,
Johns Hopkins University School of Medicine  Nothing is mentioned in the article",No,Nothing is mentioned in the article,No,"They only mention: Lung cancer is currently the leading cause of cancer deaths; and staging plays
a critical role in defining the prognosis and the best treatment approaches",No,Nothing is mentioned on the choice of subjects,No,"There is a lengthy theory section, but no mention of accessing the code or the dataset",
26/09/2022 09.25.02,10,2012,Yes,It was accurately labelled,"In this paper, we propose a novel domain-transfer learning method
for MCI conversion prediction. Different from most existing methods, we
classify MCI-C and MCI-NC with aid from the domain knowledge learned with
AD and NC subjects as auxiliary domain to further improve the classification
performance.","Different from most existing methods, we
classify MCI-C and MCI-NC with aid from the domain knowledge learned with
AD and NC subjects as auxiliary domain to further improve the classification
performance.","Alzheimer’s disease (AD) is the most common form of dementia in elderly people
worldwide. Early diagnosis of AD is very important for possible delay of the disease.
Mild cognitive impairment (MCI) is a prodromal stage of AD, which can be further
categorized into MCI converters (MCI-C) and MCI non-converters (MCI-NC). The
former will convert into AD in follow-up time, while the latter will not convert. Thus,
accurate diagnosis of MCI converters is of great importance.",SVM,"AUC, Specificity, Accuracy, Sensitivity",Yes,"Then, we use the FSL package to segment
each structural MR image into three different tissue types: gray matter (GM), white
matter (WM), and cerebrospinal fluid (CSF).",Yes,"we evaluate the effectiveness of our proposed DTSVM method on
multimodal data, including MRI, PET and CSF, from the AlzheimerÊs disease
Neuroimaging Initiative (ADNI) database.","the baseline ADNI subjects with all corresponding MRI, PET,
and CSF data are included, which leads to a total of 202 subjects (including 51 AD
patients, 99 MCI patients, and 52 normal controls (NC)). For 99 MCI patients, it
includes 43 MCI converters and 56 MCI non-converters. We use 51 AD and 52 NC
subjects as auxiliary domains, and 99 MCI subjects as target domains.",Public,Googling ADNI leads to a webpage where the dataset is available upon request for research,No,Nothing is mentioned in the article,No,Nothing is mentioned in the article,No,Nothing is mentioned in the article,Yes,"1 Dept. of Computer Science and Engineering,
Nanjing University of Aeronautics and Astronautics, Nanjing 210016, China
2 Dept. of Radiology and BRIC, University of North Carolina at Chapel Hill, NC 27599  This work was partially supported by NIH grants (EB006733,
EB008374, EB009634, AG041721 and MH088520), NSFC grant (60875030), and
CQKJ (KJ121111).",No,Nothing is mentioned in the article,No,Nothing is mentioned in the article,No,Nothing is mentioned in the article,No,Nothing is mentioned in the article,
26/09/2022 09.33.42,12,2012,No,Other medical imaging task,"It does not use the same performance measures, and aims to predict the outcome of facial deformation post surgery, so not really a diagnosis or a clear classification problem either.  ",,,,,,,,,,,,,,,,,,,,,,,,,,,,
26/09/2022 09.45.32,13,2012,Yes,It was accurately labelled,"We
utilize a fuzzy multi-class modeling using a stochastic expectation maximization
(SEM) algorithm to fit a finite mixture model (FMM) to the
PET image. We then propose a direct estimation formula for TLA and
SUVmean from this multi-class statistical model.","We
utilize a fuzzy multi-class modeling using a stochastic expectation maximization
(SEM) algorithm to fit a finite mixture model (FMM) to the
PET image. We then propose a direct estimation formula for TLA and
SUVmean from this multi-class statistical model.","The aforementioned functional markers computed from the PET image are
corrupted by partial volume effects and acquisition blur. Nonetheless, we recently
proposed a direct statistical estimation method, statistical lesion activity
computation (SLAC), in [6] for computing TLA, in the presence of blur.",Unsupervised learning,Accuracy,No,Not mentioned in the article,No,"To evaluate the performance, an NCAT phantom [11] with a hot liver lesion was
simulated.","To evaluate the performance, an NCAT phantom [11] with a hot liver lesion was
simulated. Realistic FDG uptake values were assigned to the various organs and
tissues of the NCAT phantom. A non spherical tumor (27.67mL) was inserted in
the liver (see Fig. 1). In the tumor, the activity was set to 18.2kBq/cc. The activity
in the liver, spleen, lungs and body was 6.3kBq/cc, 5.5kBq/cc, 0.9kBq/cc
and 2.5kBq/cc respectively. The voxel size used to generate the phantom was
1mm×1mm×1mm. 30 3min scans of the NCAT phantom were simulated using
a Monte Carlo simulator (PET-SORTEO [10]) which models among others the
spatially variant point spread function (PSF) of the ECAT Exact HR+ scanner.
Attenuation and scatter were also modeled. During reconstruction of both
datasets, the system PSF resolution was recovered by modeling as an isotropic
Gaussian with 5mm FWHM. The projection data were reconstructed using the
maximum likelihood expectation maximization (MLEM) algorithm [9] with ordered
subsets. As in clinical routine, 4 iterations over 16 subsets were performed.
The reconstruction voxel size was set to 2mm× 2mm× 2mm. The images were
post-smoothed with 5mm Gaussian FWHM.",Private,It is simulated data generated for this article of a liver lesion with a tumor inserted,Yes,"To evaluate the performance, an NCAT phantom [11] with a hot liver lesion was
simulated. Realistic FDG uptake values were assigned to the various organs and
tissues of the NCAT phantom. A non spherical tumor (27.67mL) was inserted in
the liver (see Fig. 1). In the tumor, the activity was set to 18.2kBq/cc. The activity
in the liver, spleen, lungs and body was 6.3kBq/cc, 5.5kBq/cc, 0.9kBq/cc
and 2.5kBq/cc respectively. The voxel size used to generate the phantom was
1mm×1mm×1mm. 30 3min scans of the NCAT phantom were simulated using
a Monte Carlo simulator (PET-SORTEO [10]) which models among others the
spatially variant point spread function (PSF) of the ECAT Exact HR+ scanner.
Attenuation and scatter were also modeled. During reconstruction of both
datasets, the system PSF resolution was recovered by modeling as an isotropic
Gaussian with 5mm FWHM. The projection data were reconstructed using the
maximum likelihood expectation maximization (MLEM) algorithm [9] with ordered
subsets. As in clinical routine, 4 iterations over 16 subsets were performed.
The reconstruction voxel size was set to 2mm× 2mm× 2mm. The images were
post-smoothed with 5mm Gaussian FWHM.",No,No patients were included as the data was simulated,Yes,It was created for this article,Yes,"1 Medical Imaging Research Center, UZ Leuven, Belgium
2 IBBT-KU Leuven Future Health Department, Belgium
3 Medical Image Computing (ESAT/PSI/MIC)
4 Nuclear Medicine
5 Gastroenterology
3,4,5 KU, Leuven, Belgium
6icoMetrix NV, Leuven, Belgium  The authors gratefully acknowledge the financial support
by KU Leuven’s Concerted Research Action GOA/11/006, IWT - TBM project
070717 and Research Foundation - Flanders (FWO).",No,Because no persons were involved,No,No persons involved,No,No persons involved,No,No persons involved but a very long perhaps useful theory section if one can recreate it from that?,
26/09/2022 10.18.37,14,2012,Yes,It was accurately labelled,"A novel gland segmentation and classification scheme applied
to an H&E histology image of the prostate tissue is proposed. For
gland segmentation, we associate appropriate nuclei objects with each
lumen object to create a gland segment. We further extract 22 features
to describe the structural information and contextual information for
each segment. These features are used to classify a gland segment into
one of the three classes: artifact, normal gland and cancer gland.","A novel gland segmentation and classification scheme applied
to an H&E histology image of the prostate tissue is proposed.","In detecting prostate cancer on a digitized tissue slide, the pathologist relies
on: (i) structural information; glands in a cancer region (cancer glands) appear
to have structural properties (e.g. nuclei abundance, lumen size) different from
glands in a normal region (normal glands) and (ii) contextual information; cancer
glands typically cluster into groups and are of similar shape and size1, while
shape and size of normal glands vary widely. These two sources of information
can be observed in Fig. 1b. Hence, a reasonable approach to assist a pathologist
in finding cancer regions includes segmenting out glandular regions, examining
their structural and contextual information and finally classifying them.",SVM,Accuracy,Yes,"For
gland segmentation, we associate appropriate nuclei objects with each
lumen object to create a gland segment.",No,"The dataset includes 48 images at 5× magnification (average image
size is 900 × 1,500 pixels), which come from 20 patients. Glands in images of
the same patient still have very large variability in structures. Given the pathologist’s
annotation on each image, we manually label 525 artifacts, 931 normal
glands and 1,375 cancer glands to form the (ground truth) gland dataset.","The dataset includes 48 images at 5× magnification (average image
size is 900 × 1,500 pixels), which come from 20 patients. Glands in images of
the same patient still have very large variability in structures. Given the pathologist’s
annotation on each image, we manually label 525 artifacts, 931 normal
glands and 1,375 cancer glands to form the (ground truth) gland dataset.",Private,The article contains no mention of where the dataset comes from,No,No mention in article,No,No mention in article,No,No mention in article,No,"1 Michigan State Unversity, East Lansing, MI 48824, USA
2 Ventana Medical Systems, Inc., Sunnyvale, CA 94085, USA
{nguye231,jain}@cse.msu.edu, anindya.sarkar@ventana.roche.com  No mention in article",No,No mention in article,No,No mention in article,No,No mention in article,Yes,"The article includes a link to a github repo, containing at least some of the code
The article also includes stats for running time and details about the machine it has been run on",
28/09/2022 09.54.15,15,2012,No,I don't know,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Don't know what this is, not classification I think...."
28/09/2022 10.03.14,16,2012,Yes,It was accurately labelled,"With the advent of advanced imaging techniques, genotyping,
and methods to assess clinical and biological progression, there is
a growing need for a unified framework that could exploit information
available from multiple sources to aid diagnosis and the identification
of early signs of Alzheimer’s disease (AD).","We propose a modeling
strategy using supervised feature extraction to optimally combine highdimensional
imaging modalities with several other low-dimensional disease
risk factors. The motivation is to discover new imaging biomarkers
and use them in conjunction with other known biomarkers for prognosis
of individuals at high risk of developing AD. Our framework also has the
ability to assess the relative importance of imaging modalities for predicting
AD conversion.","Mild cognitive impairment (MCI) is an intermediate stage between healthy aging
and dementia. Patients diagnosed with MCI are at high risk of developing
Alzheimer’s disease (AD), but not everyone with MCI will convert. Accurate
prognosis for MCI patients is an important prerequisite for providing the optimal
treatment and management of the disease.",SVM,"AUC, Specificity, Accuracy, Sensitivity",Yes,"Tissue-wise intensity normalization
for white matter, gray matter, and cerebrospinal fluid was performed using the expectation maximization based segmentation followed by the piecewise polynomial
histogram matching algorithm",Yes,"All the baseline and screening T1 weighted, bias-fieldcorrected
and N3 scaled structuralMagnetic Resonance Images were downloaded
from the Alzheimer’s Disease Neuroimaging Initiative (ADNI) database.","The baseline subjects that had all the clinical, APOE genotyping, FDG-PET
imaging and MRI imaging data from the ADNI database comprised of a total
of 242 individuals.",Public,ADNI is available upon request,No,Nothing is mentioned,No,Nothing is mentioned,No,Nothing is mentioned,Yes,"University of Utah, Salt Lake City, UT    Data collection and sharing for this project was funded by
the Alzheimer’s Disease Neuroimaging Initiative (ADNI) (NIH Grant U01
AG024904).The research in this paper was supported byNIHgrant 5R01EB007688,
the University of California, San Francisco (NIH grantP41 RR023953),NSF grant
CNS-0751152), and NSF CAREER Grant 1054057.",No,Nothing is mentioned,No,Nothing is mentioned,No,Nothing is mentioned,No,Nothing is mentioned,
28/09/2022 10.14.36,17,2012,No,Other medical imaging task,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Detection not classification
28/09/2022 10.21.37,19,2012,Yes,It was accurately labelled,"One important contribution of the method is
the provision of an interpretability layer, which is able to explain a particular
classification by visually mapping the most important visual patterns associated
with such classification.","A method for automatic analysis and interpretation of histopathology
images is presented. The method uses a representation of the image data
set based on bag of features histograms built from visual dictionary of Haarbased
patches and a novel visual latent semantic strategy for characterizing the
visual content of a set of images.","This paper presents a new method, ViSAI, for automatic analysis and interpretation of
histopathological images.",probabilistic classification model,"Specificity, Accuracy, Sensitivity",No,Nothing is mentioned,No,"The dataset comprises 10 labeled histopathological cases from St. Jude Children’s Research
Hospital, which 5 are anaplastic and 5 are non-anaplastic","Each slide is a whole
virtual slide of 80000×80000 pixels with one or more cancerous regions with a large
tumoral variability, manually annotated by a neuro-pathologist. For every slide, 750
individual images of 200×200 pixels non-overlapping where extracted uniformly at
random from these cancerous regions, resulting in a database of 7500 different images:
half of them anaplastic.",Private,"The dataset comprises 10 labeled histopathological cases from St. Jude Children’s Research
Hospital, which 5 are anaplastic and 5 are non-anaplastic",No,Nothing is mentioned,No,Nothing is mentioned,No,Nothing is mentioned,No,"BioIngenium Research Group, Universidad Nacional de Colombia, Bogot´a, Colombia
2 Rutgers, Department of Biomedical Engineering, Piscataway, NJ, USA
3 Children Hospital of L.A., Department of Pathology Lab Medicine, Los Angeles, CA, USA
4 St. Jude Children’s Research Hospital from Memphis, TN, USA
5 Penn State College of Medicine, Department of Pathology, Hershey, PA, USA  Nothing is mentioned",No,Nothing is mentioned,No,Nothing is mentioned,No,Nothing is mentioned,No,Nothing is mentioned,
28/09/2022 11.32.22,20,2012,No,I don't know,,,,,,,,,,,,,,,,,,,,,,,,,,,,,No clue what this one is about :D
28/09/2022 11.40.00,25,2012,Yes,It was accurately labelled,"Classification of Ambiguous Nerve Fiber
Orientations in 3D Polarized Light Imaging","3D Polarized Light Imaging (3D-PLI) has been shown to
measure the orientation of nerve fibers in post mortem human brains at
ultra high resolution. The 3D orientation in each voxel is obtained as a
pair of angles, the direction angle and the inclination angle with unknown
sign. The sign ambiguity is a major problem for the correct interpretation
of fiber orientation. Measurements from a tiltable specimen stage, that
are highly sensitive to noise, extract information, which allows drawing
conclusions about the true inclination sign. In order to reduce noise, we
propose a global classification of the inclination sign, which combines
measurements with spatial coherence constraints.","Fiber tracts are composed of axons, which connect nerve cells between each
other, and thus transmit information between brain areas. The exact courses
of fiber tracts are still far from being fully understood.",Graph analysis,"Sensitivity, RMSD",No,Nothing is mentioned (but this article is insanely convoluted!),No,"We evaluate our approach on synthetic and human brain
data.","Human Brain Data. Regions in histological sections of three post mortem
brains without pathological findings were selected to demonstrate the different
behavior of all approaches (Fig. 4(b)–(d)).
Synthetic Data. A synthetic data set consisting of a direction image ˜ ϕ and an
inclination image ˜α was created. The structure consists of rounded and crossing
fiber tracts (Fig. 4(a))",Private,The synthetic data they construct themselves and no mention is made of the human brain data,Don't know,"Not sure if someone who understands this could recreate the synthetic data, the human data no",No,Nothing is mentioned,Yes,At least the synthetic data is created for this article,No,"1 Institute of Neuroscience and Medicine (INM-1, INM-4),
Research Center J¨ulich,Germany
2 Department of Physics, University of Wuppertal, Germany
3 Department of Psychiatry, Psychotherapy and Psychosomatics,
RWTH Aachen University, Germany  Nothing is mentioned",No,Nothing is mentioned,No,Nothing is mentioned,No,Nothing is mentioned,No,Nothing is mentioned,
28/09/2022 11.41.48,28,2012,No,Other medical imaging task,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
28/09/2022 11.44.17,31,2012,No,Other medical imaging task,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"One I understand the basics of - trying to sample from MRI's to get better data faster, but not directly anything to do with classification I would say"
30/09/2022 10.58.09,33,2012,No,I don't know,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Unsure about this one, doesn't have the performance measures I would expect, but also don't understand what they are really doing and how.."
30/09/2022 11.06.10,36,2012,Yes,It was accurately labelled,"There is an increasing demand for automated detection and analysis of
dermoscopy structures and malignancy clues such as streaks in dermoscopy images,
for computer-aided early diagnosis of deadly melanoma. This paper presents
a novel approach for streak detection and visualization on dermoscopic images.
We tackle the detection of streaks by means of ridge and valley estimation. Orientation
estimation and correction is applied to detect low contrast and fuzzy streaks
lines, and candidate streaks are used to classify dermoscopy images into streaks
Absent or Present with the AUC of 90.5% on 300 dermoscopy images.","This paper presents
a novel approach for streak detection and visualization on dermoscopic images.","Melanoma is the most deadly form of skin cancer, yet treatable via excision if detected
early. There is, therefore, a demand to develop computer-aided diagnostic systems to facilitate
the early detection of melanoma.",Logistic classifier,"AUC, Accuracy, Precision, Recall, F1 score",Yes,First the lesion is segmented using Wighton et al.’s method,No,"we evaluated our proposed approach on streak detection
on a set of 300 dermoscopy images, including 105 absent and 195 present. 250
images are chosen randomly from two atlases of dermoscopy [10,1], and 50 images
are taken from experts’ archives with permission.","we evaluated our proposed approach on streak detection
on a set of 300 dermoscopy images, including 105 absent and 195 present. 250
images are chosen randomly from two atlases of dermoscopy [10,1], and 50 images
are taken from experts’ archives with permission.",Private,"we evaluated our proposed approach on streak detection
on a set of 300 dermoscopy images, including 105 absent and 195 present. 250
images are chosen randomly from two atlases of dermoscopy [10,1], and 50 images
are taken from experts’ archives with permission. - So I suppose that means mixed, the atlases may be public?",No,Nothing is mentioned,No,Nothing is mentioned,No,Nothing is mentioned,Yes,"1 School of Computing Science, Simon Fraser University, Canada
msa68@sfu.ca
2 Department of Dermatology and Skin Science, University of British Columbia, Canada
3 Cancer Control Research Program, BC Cancer Research Center, Canada   This work was funded by the Canadian NSERC, CIHR-Skin Research
Training Center and a grant from the Canadian Health Research Project (CHRP).",No,Nothing is mentioned,No,Nothing is mentioned,No,Nothing is mentioned,No,Nothing is mentioned,
30/09/2022 11.12.41,37,2012,Yes,It was accurately labelled,"Our experimental results show that the proposed method
can effectively identify the location of the foveola, facilitating diagnosis
around this important landmark.","We develop an automated method to determine the foveola
location in macular 3D-OCT images in either healthy or pathological
conditions.","The foveola is an important anatomical landmark for retinal image analysis [1]. It
is located in the center of the macula, responsible for sharp central vision. Several
clinically-relevant indices are measured with respect to the foveola location, such
as the retina’s average thickness, or drusen size within concentric circles around
the foveola [1, 2]. In addition, many macular diseases are best observed around
the foveola, such as macular hole, and age-related macular degeneration [3].
Therefore, the localization of the foveola in retinal images is an important first
step for diagnosis and longitudinal data analysis.",SVM,"mean, median, standard deviation",No,nothing is mentioned,No,"We collected a large sample of 3D SD-OCT macular scans (200x200x1024 or
512x128x1024 protocol, 6x6x2 mm; Cirrus HD-OCT; Carl Zeiss Meditec). Each
scan is then normalized to be 200x200x200 in x, y, z. For each scan, two ophthalmologists
labeled the (x, y) location of the foveola independently. We then
included a total of 170 scans from 170 eyes/126 subjects in which all scans have
good expert labeling agreement (distance ≤ 8 pixels)","We collected a large sample of 3D SD-OCT macular scans (200x200x1024 or
512x128x1024 protocol, 6x6x2 mm; Cirrus HD-OCT; Carl Zeiss Meditec). Each
scan is then normalized to be 200x200x200 in x, y, z. For each scan, two ophthalmologists
labeled the (x, y) location of the foveola independently. We then
included a total of 170 scans from 170 eyes/126 subjects in which all scans have
good expert labeling agreement (distance ≤ 8 pixels)",Private,"We collected a large sample of 3D SD-OCT macular scans (200x200x1024 or
512x128x1024 protocol, 6x6x2 mm; Cirrus HD-OCT; Carl Zeiss Meditec). Each
scan is then normalized to be 200x200x200 in x, y, z. For each scan, two ophthalmologists
labeled the (x, y) location of the foveola independently. We then
included a total of 170 scans from 170 eyes/126 subjects in which all scans have
good expert labeling agreement (distance ≤ 8 pixels)",Don't know,"We collected a large sample of 3D SD-OCT macular scans (200x200x1024 or
512x128x1024 protocol, 6x6x2 mm; Cirrus HD-OCT; Carl Zeiss Meditec). Each
scan is then normalized to be 200x200x200 in x, y, z. For each scan, two ophthalmologists
labeled the (x, y) location of the foveola independently. We then
included a total of 170 scans from 170 eyes/126 subjects in which all scans have
good expert labeling agreement (distance ≤ 8 pixels)",No,Nothing is mentioned,Yes,For the purpose of this article,Yes,"1 College of Computing, Georgia Institute of Technology, Atlanta, GA
2 UPMC Eye Center, University of Pittsburgh School of Medicine, Pittsburgh, PA
3 Department of Bioengineering, University of Pittsburgh, Pittsburgh, PA
4 Intel Science and Technology Center on Embedded Computing, Pittsburgh, PA   This research is supported in part by National Institutes of
Health contracts R01-EY013178 and P30-EY008098, The Eye and Ear Foundation
(Pittsburgh, PA), unrestricted grants from Research to Prevent Blindness,
Inc. (New York, NY), and grants from Intel Labs Pittsburgh (Pittsburgh, PA).",No,Nothing is mentioned,No,Nothing is mentioned,No,Nothing is mentioned,Yes,"There is psuedocode included for their algorithm, so partial transparency?","This one is perhaps also unclear if it is classification or not, the performance measures especially seem to indicate perhaps not, more localisation than classification, though they do do classification"
30/09/2022 11.17.42,38,2012,Yes,It was accurately labelled,"In the context of a blind source separation
of the underlying colour, we arrive at intrinsic melanin and hemoglobin
images, whose properties are then used in supervised learning to achieve excellent
malignant vs. benign skin lesion classification.","In this paper we propose a new log-chromaticity 2-D colour space,
an extension of previous approaches, which succeeds in removing confounding
factors from dermoscopic images: (i) the effects of the particular camera characteristics
for the camera system used in forming RGB images; (ii) the colour
of the light used in the dermoscope; (iii) shading induced by imaging non-flat
skin surfaces; (iv) and light intensity, removing the effect of light-intensity falloff
toward the edges of the dermoscopic image. In the context of a blind source separation
of the underlying colour, we arrive at intrinsic melanin and hemoglobin
images, whose properties are then used in supervised learning to achieve excellent
malignant vs. benign skin lesion classification.","The three most common malignant skin cancers are basal cell carcinoma (BCC), squamous
cell carcinoma (SCC), and melanoma, among which melanoma is the most deadly
with a high increasing rate in most parts of the world. Melanoma is often treatable if
detected in the early stage, particularly before the metastasis phase. Therefore, there is
an increasing demand for computer-aided diagnostic systems to catch early melanomas.
Colour has played a crucial role in the diagnosis of skin lesions by experts in most
clinical methods (see e.g. [1]). For instance, the presence of multiple colours with an
irregular distribution can signal malignancy.
Few studies have investigated the use of colour features representing biological properties
of skin lesions.",Logistic classifier,"AUC, Precision, Recall, F1 score",Yes,"For automatic segmentation of lesions, we found that
using the geometric-mean μ is as good as or better than the state of the art [12] for these
dermoscopic images, in amuch simpler algorithm.",No,"We applied a Logistic classifier to a set of 500 images, with two classes consisting of
malignant (melanoma and BCC) vs. all benign lesions","We applied a Logistic classifier to a set of 500 images, with two classes consisting of
malignant (melanoma and BCC) vs. all benign lesions",Private,"(This is the ONLY description of the dataset...) We applied a Logistic classifier to a set of 500 images, with two classes consisting of
malignant (melanoma and BCC) vs. all benign lesions",No,Nothing is mentioned,No,Nothing is mentioned,No,Nothing is mentioned,No,"School of Computing Science
Simon Fraser University
amadooei@cs.sfu.ca
http://www.cs.sfu.ca/∼amadooei  Nothing is mentioned",No,Nothing is mentioned,No,Nothing is mentioned,No,Nothing is mentioned,No,Nothing is mentioned,This article probably has the shortest description of a dataset I've seen so far!
30/09/2022 11.23.46,40,2012,Yes,It was accurately labelled,"We applied a linear Support Vector Machine (SVM) to classify candidate patch
sequences.","we present an image analysis method to
detect apoptosis in time-lapse phase-contrast microscopy, which is nondestructive
imaging.","There have been little-to-no reports of apoptosis detection in phase-contrast
microscopy. To the best of our knowledge, cell death event detection has only
been implicitly performed as a byproduct of cell tracking; i.e., if the trajectory of
a cell terminates during cell tracking, the cell is considered dead. However, this
simple heuristic often yields poor results because many cell traject",SVM,"Precision, Recall",No,Nothing is mentioned,No,"After C2C12 myoblastic stem cells were cultured for one day, Mitomycin C was
added to induce apoptosis. Afterward, three populations were imaged every 5
minutes over 45 hours, resulting in three sets of 540 image frames. As shown in
Fig. 4, most of cells were dead at the last frame. We manually annotated apoptosis
by marking the center of each apoptotic cell after it shrinks and becomes
bright, obtaining 1154 cases in total. The image sequences and ground truths
are available on the first author’s web page (www.cs.cmu.edu/∼seungilh).","After C2C12 myoblastic stem cells were cultured for one day, Mitomycin C was
added to induce apoptosis. Afterward, three populations were imaged every 5
minutes over 45 hours, resulting in three sets of 540 image frames. As shown in
Fig. 4, most of cells were dead at the last frame. We manually annotated apoptosis
by marking the center of each apoptotic cell after it shrinks and becomes
bright, obtaining 1154 cases in total. The image sequences and ground truths
are available on the first author’s web page (www.cs.cmu.edu/∼seungilh).",Public,"The image sequences and ground truths
are available on the first author’s web page (www.cs.cmu.edu/∼seungilh).",Yes,"After C2C12 myoblastic stem cells were cultured for one day, Mitomycin C was
added to induce apoptosis. Afterward, three populations were imaged every 5
minutes over 45 hours, resulting in three sets of 540 image frames. As shown in
Fig. 4, most of cells were dead at the last frame. We manually annotated apoptosis
by marking the center of each apoptotic cell after it shrinks and becomes
bright, obtaining 1154 cases in total. The image sequences and ground truths
are available on the first author’s web page (www.cs.cmu.edu/∼seungilh).",No,"Not relevant as such, uses stem cells (though no mention is made of which and whose stem cells are used of course)",Yes,For the purpose of this article,No,"Robotics Institute, Carnegie Mellon University
{seungilh,hangs,tk}@cs.cmu.edu
2 Department of Orthopedic Surgery, Stanford University
elmerker@stanford.edu  Nothing is mentioned",No,Nothing is mentioned,No,Nothing is mentioned,No,Nothing is mentioned,Yes,Pseudo code included,
03/10/2022 09.33.27,41,2012,Yes,It was accurately labelled,"We test our method on a
collection of 42 lymphocyte sequences and present results on i) discrimination of
normal and abnormal cellular morphology, ii) local statistical differences between
abnormal and normal shape sequences, and iii) classification of shape sequences
based on the dynamic cellular shape changes from one time point to another.","In this paper we propose a dynamic framework for quantitative analysis of
lymphocyte morphological changes in 2D+t image sequences","Morphological analysis of cells features prominently in a wide range of applications
including digital pathology and is essential for improving our understanding
of the basic physiological processes of organisms.",Learning Vector Quantization,"Specificity, Accuracy, Sensitivity",No,"But mentions the data is segmented prior to use: We represent the segmented cell boundary by 2D
closed, continuously parameterized curve [5–7] c ⊂ R2 given by c(s) : [0, 2π) →
R2.",No,"Our data consists of 42 lymphocyte image sequences (20∼30 seconds) of mice
undergoing back skin transplantation (age: 6-8 weeks, weight 20-22 g) observed
with phase contrast microscopy (Olympus BX51, 0.3 μ resolution, 16 × 1000
magnification). The first group consisted of 21 healthy Balb/C mice as hosts
and 21 healthy Balb/C mice as donors, whereas the second group consisted of
21 healthy Balb/C mice as hosts and 21 healthy C57BL/6 mice as donors. The
lymphocytes were obtained from the blood samples of the 42 hosts collected
from the tail 7 days after the skin transplant.","Our data consists of 42 lymphocyte image sequences (20∼30 seconds) of mice
undergoing back skin transplantation (age: 6-8 weeks, weight 20-22 g) observed
with phase contrast microscopy (Olympus BX51, 0.3 μ resolution, 16 × 1000
magnification). The first group consisted of 21 healthy Balb/C mice as hosts
and 21 healthy Balb/C mice as donors, whereas the second group consisted of
21 healthy Balb/C mice as hosts and 21 healthy C57BL/6 mice as donors. The
lymphocytes were obtained from the blood samples of the 42 hosts collected
from the tail 7 days after the skin transplant.",Private,"Our data consists of 42 lymphocyte image sequences (20∼30 seconds) of mice
undergoing back skin transplantation (age: 6-8 weeks, weight 20-22 g) observed
with phase contrast microscopy (Olympus BX51, 0.3 μ resolution, 16 × 1000
magnification). The first group consisted of 21 healthy Balb/C mice as hosts
and 21 healthy Balb/C mice as donors, whereas the second group consisted of
21 healthy Balb/C mice as hosts and 21 healthy C57BL/6 mice as donors. The
lymphocytes were obtained from the blood samples of the 42 hosts collected
from the tail 7 days after the skin transplant.",No,"Our data consists of 42 lymphocyte image sequences (20∼30 seconds) of mice
undergoing back skin transplantation (age: 6-8 weeks, weight 20-22 g) observed
with phase contrast microscopy (Olympus BX51, 0.3 μ resolution, 16 × 1000
magnification). The first group consisted of 21 healthy Balb/C mice as hosts
and 21 healthy Balb/C mice as donors, whereas the second group consisted of
21 healthy Balb/C mice as hosts and 21 healthy C57BL/6 mice as donors. The
lymphocytes were obtained from the blood samples of the 42 hosts collected
from the tail 7 days after the skin transplant.",No,"Also not relevant, tested on mice",Yes,For the article,Yes,"1 School of Information and Electronics, Beijing Inst. of Tech., Beijing, China
2 School of Computer Sci. and Engineering, Arizona State University, Tempe, USA
3 Department of General Surgery, Beijing You’An Hospital, Beijing, China
4 Laboratory of Neuro Imaging, UCLA School of Medicine, Los Angeles, CA, USA   This work is sponsored by the National Natural Science Foundation of China
(60971133) and the China Scholarship Council. anxing@bit.edu.cn",No,"Not relevant, mice testing",No,Nothing is mentioned,No,"Not relevant, mice testing",No,Nothing mentioned,
03/10/2022 09.37.26,42,2012,Yes,It was accurately labelled,"In this paper we propose a learning-based method that is general enough
to perform well across different microscopy modalities. Rather than invoking
computationally-intensive segmentation frameworks [1,9], or classifying all image
patches in a sliding-window manner [15], it uses a highly-efficient MSER region
detector [8] to find a broad number of candidate regions to be scored with a
learning-based measure. The non-overlaping subset of those regions with high
similarity to the class of interest can then be selected via dynamic programming,
while the learning can be done within the structured output framework [12].","In this paper we propose a learning-based method that is general enough
to perform well across different microscopy modalities. Rather than invoking
computationally-intensive segmentation frameworks [1,9], or classifying all image
patches in a sliding-window manner [15], it uses a highly-efficient MSER region
detector [8] to find a broad number of candidate regions to be scored with a
learning-based measure. The non-overlaping subset of those regions with high
similarity to the class of interest can then be selected via dynamic programming,
while the learning can be done within the structured output framework [12].","Automatic cell detection is a subject of interest in a wide range of cell-based
studies, as it is the basis of many automatic methods for cell counting, segmentation
and tracking. The broad diversity of cell lines and microscopy imaging
techniques require that cell detection algorithms adapt well to different scenarios.
The difficulty of the problem also increases when the cell density of the
sample is high, as in this case the cell size can vary and cell clumping is usual.
Moreover, in some applications different cell types or other similar structures
can be present in the same image, and in this case the algorithm is required to
detect only the cells of interest, posing a barrier hard to overcome with classical
image processing techniques.",SVM,"Precision, Recall",Yes,"Although the algorithm produces a set of regions, our
aim is to optimize the detection accuracy (and not the segmentation) w.r.t. the
ground truth provided in the form of dots.",No,"Three data sets for cell detection have been used to validate the method
(Figure 1). Firstly, the ICPR 2010 Histopathology Images contest [4], which
consists of 20 images of stained breast cancer tissue. It is required to detect
lymphocyte nuclei, while discriminating them from breast cancer nuclei having
very similar appearance. The second data set comes from [1] and contains 12
fluorescence microscopy images of human embryonic kidney (HEK) cells, where
the detection task is challenging due to the significant intensity variation between
cells across the image, fading boundaries, and frequent cell clumping. The third
data set contains 22 phase-contrast images of cervical cancer cell colonies of the
HeLa cell line, which presents a high variability in cell shapes and sizes.
Three variations of our method are evaluated: (I) direct classification","Three data sets for cell detection have been used to validate the method
(Figure 1). Firstly, the ICPR 2010 Histopathology Images contest [4], which
consists of 20 images of stained breast cancer tissue. It is required to detect
lymphocyte nuclei, while discriminating them from breast cancer nuclei having
very similar appearance. The second data set comes from [1] and contains 12
fluorescence microscopy images of human embryonic kidney (HEK) cells, where
the detection task is challenging due to the significant intensity variation between
cells across the image, fading boundaries, and frequent cell clumping. The third
data set contains 22 phase-contrast images of cervical cancer cell colonies of the
HeLa cell line, which presents a high variability in cell shapes and sizes.
",Don't know,Mixed I think,No,"Three data sets for cell detection have been used to validate the method
(Figure 1). Firstly, the ICPR 2010 Histopathology Images contest [4], which
consists of 20 images of stained breast cancer tissue. It is required to detect
lymphocyte nuclei, while discriminating them from breast cancer nuclei having
very similar appearance. The second data set comes from [1] and contains 12
fluorescence microscopy images of human embryonic kidney (HEK) cells, where
the detection task is challenging due to the significant intensity variation between
cells across the image, fading boundaries, and frequent cell clumping. The third
data set contains 22 phase-contrast images of cervical cancer cell colonies of the
HeLa cell line, which presents a high variability in cell shapes and sizes.
Three variations of our method are evaluated: (I) direct classification",No,Nothing is mentioned,No,Nothing is mentioned,Yes,"1 Department of Engineering Science, University of Oxford, U.K.
2 Yandex, Moscow, Russia   We are grateful to Dr. N. Rajpoot, Dr. E. Bernadis, Dr.
B. Vojnovic and Dr. G. Flaccavento for providing cell data sets. Financial support
was provided by the RCUK Centre for Doctoral Training in Healthcare
Innovation (EP/G036861/1) and ERC grant VisRec no. 228180.",No,Nothing is mentioned,No,Nothing is mentioned,No,Nothing is mentioned,No,Nothing is mentioned,
03/10/2022 09.39.15,51,2012,No,Other medical imaging task,"However, our target applications for this model are registration and reconstruction.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
03/10/2022 09.40.04,52,2012,No,Other medical imaging task,"Towards Intra-operative PET for Head
and Neck Cancer: Lymph Node Localization
Using High-Energy Probes",,,,,,,,,,,,,,,,,,,,,,,,,,,,
03/10/2022 09.45.04,53,2012,Yes,It was accurately labelled,"Our method features a novel completely
data-driven approach to breast shape prediction that does not necessitate
prior knowledge about biomechanical properties and parameters of the
breast tissue.","We therefore propose a method for 3D breast decompression
and associated lesion mapping from 3D DBT data.","According to theWorld Cancer Report 2008 (globocan.iarc.fr, 2012/01/23) breast
cancer is the most frequent cancer diagnosis in women among all specifiable
kinds of cancer. Early detection is assumed to significantly improve outcomes.",Multiple Multi-variate Random Forest Regression,Accuracy,Yes,"For this we first segment the breast
tissue area by thresholding and region growing,",No,"Nipple detection has been trained and evaluated on 122 annotated training
data sets, i.e., DBT scans.","Nipple detection has been trained and evaluated on 122 annotated training
data sets, i.e., DBT scans.",Private,"Nipple detection has been trained and evaluated on 122 annotated training
data sets, i.e., DBT scans.",No,Nothing is mentioned,No,Nothing is mentioned,Yes,I believe it was collected for this article,No,"1 Siemens AG, Corporate Technology, Erlangen, Germany
2 University Hospital Erlangen, Department of Radiology, Germany
3 Siemens AG, Healthcare, Erlangen, Germany
4 Siemens Corporation, Corporate Research and Technology, Princeton, NJ, USA  Nothing is mentioned",No,Nothing is mentioned,No,Nothing is mentioned,No,Nothing is mentioned,No,Nothing is mentioned,
07/10/2022 11.19.36,55,2012,No,Other medical imaging task,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
07/10/2022 11.21.16,59,2012,No,Other medical imaging task,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
07/10/2022 11.22.16,61,2012,No,Segmentation,"Combining CRF and Multi-hypothesis Detection
for Accurate Lesion Segmentation
in Breast Sonograms",,,,,,,,,,,,,,,,,,,,,,,,,,,,
07/10/2022 11.28.33,62,2012,Yes,It was accurately labelled,"to find discriminative regions
of 3D brain images in the classification of neurodegenerative disease.","We present a novel method of Hierarchical Manifold Learning
which aims to automatically discover regional variations within images.","We present a novel method of Hierarchical Manifold Learning
which aims to automatically discover regional variations within images.","Graph analysis, Hierarchical Manifold Learning",Accuracy,No,Nothing is mentioned,Yes,ADNI,"We have
applied HML to the Alzheimer’s Disease Neuroimaging Initiative (ADNI) [1]
dataset of 429 subjects of size 160 × 192 × 160 mm. This consists of 231 normal
control subjects and 198 subjects with Alzheimer’s disease.",Public,"We have
applied HML to the Alzheimer’s Disease Neuroimaging Initiative (ADNI) [1]
dataset of 429 subjects of size 160 × 192 × 160 mm. This consists of 231 normal
control subjects and 198 subjects with Alzheimer’s disease.",No,Nothing is mentioned,No,Nothing is mentioned,No,Nothing is mentioned,Yes,"Biomedical Image Analysis Group,
Department of Computing, Imperial College London, London, UK
2 Division of Imaging Sciences and Biomedical Engineering,
King’s College London, London, UK

We thank Marc Modat and M. Jorge Cardoso from the Centre for Medical Image
Computing, University College London, for their advice and assistance. The work is
partially funded under the 7th Framework Programme by the European Commission
(http://cordis.europa.eu/ist/).",No,Nothing is mentioned,No,Nothing is mentioned,No,Nothing is mentioned,No,Nothing is mentioned,
07/10/2022 11.29.32,82,2012,No,Other medical imaging task,"Localization of Sparse Transmural Excitation
Stimuli from Surface Mapping",,,,,,,,,,,,,,,,,,,,,,,,,,,,
07/10/2022 11.37.42,88,2012,Yes,It was accurately labelled,"Population based pattern analysis and classification for
quantifying structural and functional differences between diverse groups
has been shown to be a powerful tool for the study of a number of
diseases, and is quite commonly used especially in neuroimaging.","we show that null distributions ordinarily obtained
by permutation tests using SVMs can be analytically approximated from
the data. The analytical computation takes a small fraction of the time
it takes to do an actual permutation test, thereby rendering it possible
to quickly create statistical significance maps derived from SVMs. Such
maps are critical for understanding imaging patterns of group differences
and interpreting which anatomical regions are important in determining
the classifier’s decision.","The dominant approach
addressing this problem involves performing independent statistical testing either
pixel/voxel-wise [1] or regions of interest (ROI-wise) in the image. It has
been argued that such univariate analysis might miss group difference patterns
that span multiple voxels or regions [2]. Hence, replacing univariate methods by
multivariate methods such as SVMs [3] [4][5] has been discussed in literature.
However, unlike univariate methods [1], SVMs do not naturally provide statistical
tests (and corresponding p-values) associated with every voxel/region of
an image. Permutation testing has been suggested for interpreting SVM output
for such high dimensional data [6]. However, performing these tests is time
consuming and computationally costly",SVM,Accuracy,No,Nothing is mentioned,No,"Simulated data was generated as follows 1) grey matter tissue
density maps were generated from brain images of 152 normal subjects 2)simulated
brain shrinkage was introduced in the right frontal lobe of half of these
images by a localized reduction in intensity of the corresponding TDMs. The
vectorized TDM corresponding to each subject forms the superlong vector xi of
section 2.1.
Experiment 2: 278 TDMs were generated. This dataset contained 152 controls
and 126 Alzheimer’s patients.","Simulated data was generated as follows 1) grey matter tissue
density maps were generated from brain images of 152 normal subjects 2)simulated
brain shrinkage was introduced in the right frontal lobe of half of these
images by a localized reduction in intensity of the corresponding TDMs. The
vectorized TDM corresponding to each subject forms the superlong vector xi of
section 2.1.
Experiment 2: 278 TDMs were generated. This dataset contained 152 controls
and 126 Alzheimer’s patients.",Private,"Simulated data was generated as follows 1) grey matter tissue
density maps were generated from brain images of 152 normal subjects 2)simulated
brain shrinkage was introduced in the right frontal lobe of half of these
images by a localized reduction in intensity of the corresponding TDMs. The
vectorized TDM corresponding to each subject forms the superlong vector xi of
section 2.1.
Experiment 2: 278 TDMs were generated. This dataset contained 152 controls
and 126 Alzheimer’s patients.",No,"Simulated data was generated as follows 1) grey matter tissue
density maps were generated from brain images of 152 normal subjects 2)simulated
brain shrinkage was introduced in the right frontal lobe of half of these
images by a localized reduction in intensity of the corresponding TDMs. The
vectorized TDM corresponding to each subject forms the superlong vector xi of
section 2.1.
Experiment 2: 278 TDMs were generated. This dataset contained 152 controls
and 126 Alzheimer’s patients.",No,"Simulated data was generated as follows 1) grey matter tissue
density maps were generated from brain images of 152 normal subjects 2)simulated
brain shrinkage was introduced in the right frontal lobe of half of these
images by a localized reduction in intensity of the corresponding TDMs. The
vectorized TDM corresponding to each subject forms the superlong vector xi of
section 2.1.
Experiment 2: 278 TDMs were generated. This dataset contained 152 controls
and 126 Alzheimer’s patients.",Yes,For this article,No,"Section for Biomedical Image Analysis,
University of Pennsylvania, Philadelphia, PA 19104, USA",No,"Nothing is mentioned, also perhaps not relevant, as simulated data",No,"Nothing is mentioned, also perhaps not relevant, as simulated data",No,"Nothing is mentioned, also perhaps not relevant, as simulated data",No,Nothing is mentioned,"They don't really use accuracy as such, but that is the closest I could come to a performance measure. Also first article I can recall that doesn't have a conclusion...
Simulated data, so the ethics questions 1-3 also a bit fishy"
07/10/2022 11.39.17,89,2012,No,Other medical imaging task,"Analysis of Longitudinal Shape Variability
via Subject Specific Growth Modeling",,,,,,,,,,,,,,,,,,,,,,,,,,,,
07/10/2022 11.41.18,90,2012,No,Other medical imaging task,"Definitely classification adjacent, but contains no methods/performance measures I would expect from classification",,,,,,,,,,,,,,,,,,,,,,,,,,,,
07/10/2022 11.47.45,96,2012,No,Other medical imaging task,"Cardiac Mechanical Parameter Calibration
Based on the Unscented Transform",,,,,,,,,,,,,,,,,,,,,,,,,,,,
07/10/2022 11.52.29,97,2012,Yes,It was accurately labelled,"We then measure the accuracy score of our encoding
by training a linear classifier, which outperforms the same classifier based
on volumetric measurements.","we adapt spectral signatures for capturing morphological
changes over time. Advanced techniques for capturing temporal shape changes
frequently rely on first registering the sequence of shapes and then analyzing the
corresponding set of high dimensional deformation maps. Instead, we propose a
simple encoding motivated by the observation that small shape deformations lead
to minor refinements in the spectral signature composed of the eigenvalues of
the Laplace operator. The proposed encoding does not require registration, since
spectral signatures are invariant to pose changes. We apply our representation to
the shapes of the ventricles extracted from 22 cine MR scans of healthy controls
and Tetralogy of Fallot patients. We then measure the accuracy score of our encoding
by training a linear classifier, which outperforms the same classifier based
on volumetric measurements.","Capturing the shape and function of anatomy through volumetric measurements extracted
from 4D medical scans has become of central importance in diagnosing diseases.
For example, cardiologists rely on ejection fraction extracted from ultrasound
or cine MR scans to assess patients. These volumetric measurements, however, are not
sensitive enough to aid the diagnosis of many focal or diffuse cardiac diseases. In this
paper, we introduce a new encoding of the shape and its temporal changes based on
the spectral signature and show that this encoding is more sensitive for comparing two
shapes and their temporal dynamics than volumetric measurements.",SVM,"Accuracy, Precision, Recall",Yes,"A
medical expert then semi-automatically segmented the blood pool of the right ventricle
andmyocardium of the left ventricle at the end-diastole (ED) timepoint using ‘Segment’
[15] with manual corrections of the results.",No,"Our dataset includes the cine MR scans of 11 TOF
cases and 11 healthy volunteers (K=22)","Our dataset includes the cine MR scans of 11 TOF
cases and 11 healthy volunteers (K=22)",Private,"Our dataset includes the cine MR scans of 11 TOF
cases and 11 healthy volunteers (K=22)",No,Nothing is mentioned,No,Nothing is mentioned,Yes,"For this article: We would like to thank DongHye Ye for his help on generating
the cardiac dataset. ",Yes,"Dept. of Radiology, University of Pennsylvania, Philadelphia, PA 19104, USA
2 Microsoft Research, Cambridge, CB3 0FB, UK
3 Dept. of Computer Science, Rutgers University, Piscataway, NJ 08854, USA

We would like to thank Dong Hye Ye for his help on generating
the cardiac dataset. This project was supported in part by Grant Number UL1RR024134
and by the Institute for Translational Medicine and Therapeutics’ (ITMAT) Transdisciplinary
Program.",No,Nothing is mentioned,No,Nothing is mentioned,No,Nothing is mentioned,No,Nothing is mentioned,
07/10/2022 11.53.57,103,2012,No,Other medical imaging task,None of the obvious methods/perf measures,,,,,,,,,,,,,,,,,,,,,,,,,,,,
07/10/2022 11.55.19,105,2012,No,Other medical imaging task,A Novel Approach for Global Lung Registration,,,,,,,,,,,,,,,,,,,,,,,,,,,,
07/10/2022 11.56.15,106,2012,No,Other medical imaging task,"Analytic Regularization of Uniform Cubic
B-spline Deformation Fields",,,,,,,,,,,,,,,,,,,,,,,,,,,,
07/10/2022 12.05.24,117,2012,Yes,It was accurately labelled,"Our results demonstrate that the constrained sparse network gives better classification
performance than the conventional correlation-based network, indicating
its greater sensitivity to early stage brain pathologies.","we consider a constrained sparse linear regression model associated
with the least absolute shrinkage and selection operator (LASSO). Specifically,
we introduced sparsity into brain connectivity via l1-norm penalization, and ensured
consistent non-zero connections across subjects via l2-norm penalization.
Our results demonstrate that the constrained sparse network gives better classification
performance than the conventional correlation-based network, indicating
its greater sensitivity to early stage brain pathologies.","Mild cognitive impairment (MCI) is difficult to diagnose due to its
subtlety. Recent emergence of advanced network analysis techniques utilizing
resting-state functional Magnetic Resonance Imaging (rs-fMRI) has made the
understanding of neurological disorders more comprehensively at a whole-brain
connectivity level. However, inferring effective brain connectivity from fMRI
data is a challenging task, particularly when the ultimate goal is to obtain good
control-patient classification performance. Incorporating sparsity into connectivity
modeling can potentially produce results that are biologically more meaningful
since most biologically networks are formed by a relatively few number
of connections. However, this constraint, when applied at an individual level, will
degrade classification performance due to inter-subject variability. To address this
problem,",SVM,"AUC, Specificity, Accuracy, Sensitivity",Yes,"The images were then masked with their respective graymatter (GM)
masks, created by segmenting the GM regions from their T1-weighted images to eliminate
the physiological noise caused by cardiac and respiratory cycles in white matter
and cerebrospinal fluid [17].",No,"Resting-state fMRI (rs-fMRI) scans of 12 MCI patients and 25 healthy controls were
acquired using a 3 Tesla (Signa EXCITE, GE) scanner with the following parameters:
TR/TE = 2000/32 ms, flip angle = 77◦, imaging matrix = 64 × 64, FOV = 256 ×
256 mm2, 34 slices, 150 volumes, and voxel thickness = 4 mm.","Resting-state fMRI (rs-fMRI) scans of 12 MCI patients and 25 healthy controls were
acquired using a 3 Tesla (Signa EXCITE, GE) scanner with the following parameters:
TR/TE = 2000/32 ms, flip angle = 77◦, imaging matrix = 64 × 64, FOV = 256 ×
256 mm2, 34 slices, 150 volumes, and voxel thickness = 4 mm.",Private,"Resting-state fMRI (rs-fMRI) scans of 12 MCI patients and 25 healthy controls were
acquired using a 3 Tesla (Signa EXCITE, GE) scanner with the following parameters:
TR/TE = 2000/32 ms, flip angle = 77◦, imaging matrix = 64 × 64, FOV = 256 ×
256 mm2, 34 slices, 150 volumes, and voxel thickness = 4 mm.",Yes,"Resting-state fMRI (rs-fMRI) scans of 12 MCI patients and 25 healthy controls were
acquired using a 3 Tesla (Signa EXCITE, GE) scanner with the following parameters:
TR/TE = 2000/32 ms, flip angle = 77◦, imaging matrix = 64 × 64, FOV = 256 ×
256 mm2, 34 slices, 150 volumes, and voxel thickness = 4 mm.",Yes,"Informed consent was obtained from all subjects, and the
experimental protocols were approved by the institutional ethics board. Confirmation
of diagnosis for all subjects was made via expert consensus panels. Demographic and
clinical information of the participants is provided in Table 1.
214 C.-Y. Wee et al.
Table 1. Demographic and clinical information of the participants
Group MCI Control p-value
No. of subjects (Male/Female) 6/6 9/16 -
Age (mean ± SD) 75.0 ± 8.0 72.9 ± 7.9 0.3598a
Years of education (mean ± SD) 18.0 ± 4.1 15.8 ± 2.4 0.0491a
MMSE (mean ± SD) 28.5 ± 1.5b 29.3 ± 1.1 0.1201a",Yes,For this article,No,"Department of Radiology and BRIC,
University of North Carolina at Chapel Hill, NC, USA
2 Brain Imaging and Analysis Center,
Duke University Medical Center, Durham, NC, USA",Yes,"Informed consent was obtained from all subjects, and the
experimental protocols were approved by the institutional ethics board. ",No,Nothing is mentioned,No,Nothing is mentioned,Yes,"Informed consent was obtained from all subjects, and the
experimental protocols were approved by the institutional ethics board. ","WOW, that's a first!"
07/10/2022 12.06.32,118,2012,No,Other medical imaging task,None of the methods/perf measures,,,,,,,,,,,,,,,,,,,,,,,,,,,,
07/10/2022 12.07.36,119,2012,No,Other medical imaging task,No methods/perf measures,,,,,,,,,,,,,,,,,,,,,,,,,,,,
07/10/2022 12.09.34,121,2012,No,Other medical imaging task,Something to improve frmi datasets sensitivity/specificity,,,,,,,,,,,,,,,,,,,,,,,,,,,,
07/10/2022 12.13.48,122,2012,Yes,It was accurately labelled,"This paper presents a method for unsupervised cluster analysis using
multi-edge similarity graphs that combine information from different
modalities. The method alleviates the issues with traditional supervised
classification methods that use diagnostic labels and are therefore unable
to exploit or elucidate the underlying heterogeneity of the dataset under
analysis.","This paper presents a method for unsupervised cluster analysis using
multi-edge similarity graphs that combine information from different
modalities. The method alleviates the issues with traditional supervised
classification methods that use diagnostic labels and are therefore unable
to exploit or elucidate the underlying heterogeneity of the dataset under
analysis.","Classifying subjects based on their underlying pathology, brain structure, behavior
and cognition is an important step towards creating biomarkers. However,
pathologies like ASD and other neuropsychiatric disorders are defined over a
spectrum and the severity of the disease may vary within a population thus
making the data highly heterogeneous. Different modalities, like imaging, neurocognitive
scores etc., may characterize different aspects of this heterogeneity
to different degrees. This paper presents a method for unsupervised cluster analysis
of populations using multi-edge similarity graphs that combine information
of population heterogeneity from different modalities, producing classes that are
more representative of population variability.
Traditional superivised classification methods, utilize predefined diagnostic
labels for the subjects for training [1], [2], and hence new subjects can only be
classified into one of these diagnostic categories, thereby overlooking the underlying
heterogeneity of the pathology.","Graph analysis, Unsupervised learning",Accuracy,Yes,"Cortical parcellation and sub-cortical
segmentation of all the subjects was obtained using Freesurfer [11] on structural
T1 images, and a total of 78 ROI’s were extracted to represent the nodes of the
structural network.",No,"Two separate datasets were used in the unsupervised clustering:
– The SCZ dataset consisted of 29 female controls (CNT) and 23 female age
matched patients with schizophrenia. The DWI images were acquired on
Siemens 3T scanner with b=1000 s/mm2 and 64 gradient directions. Neurocognitive
testing was carried out on all the subjects and the speed and
accuracy of memory, emotion, reasoning, and executive functioning were
recorded.
– The ASD dataset consisted of 33 participants with ASD and 21 age matched
typically developing controls (TD’s). The DWI images were acquired on
Siemens 3T scanner with b=1000 s/mm2 and 30 gradient directions. The
cognitive and psychological tests included verbal IQ, Social Responsiveness
Scale (SRS), Social communication questionnaire (SCQ), Clinical evaluation
of language fundamentals (CELF), Full scale IQ and Autism diagnostic
observation schedule (ADOS) and perceptual reasoning index (PRI).","Two separate datasets were used in the unsupervised clustering:
– The SCZ dataset consisted of 29 female controls (CNT) and 23 female age
matched patients with schizophrenia. The DWI images were acquired on
Siemens 3T scanner with b=1000 s/mm2 and 64 gradient directions. Neurocognitive
testing was carried out on all the subjects and the speed and
accuracy of memory, emotion, reasoning, and executive functioning were
recorded.
– The ASD dataset consisted of 33 participants with ASD and 21 age matched
typically developing controls (TD’s). The DWI images were acquired on
Siemens 3T scanner with b=1000 s/mm2 and 30 gradient directions. The
cognitive and psychological tests included verbal IQ, Social Responsiveness
Scale (SRS), Social communication questionnaire (SCQ), Clinical evaluation
of language fundamentals (CELF), Full scale IQ and Autism diagnostic
observation schedule (ADOS) and perceptual reasoning index (PRI).",Private,"Two separate datasets were used in the unsupervised clustering:
– The SCZ dataset consisted of 29 female controls (CNT) and 23 female age
matched patients with schizophrenia. The DWI images were acquired on
Siemens 3T scanner with b=1000 s/mm2 and 64 gradient directions. Neurocognitive
testing was carried out on all the subjects and the speed and
accuracy of memory, emotion, reasoning, and executive functioning were
recorded.
– The ASD dataset consisted of 33 participants with ASD and 21 age matched
typically developing controls (TD’s). The DWI images were acquired on
Siemens 3T scanner with b=1000 s/mm2 and 30 gradient directions. The
cognitive and psychological tests included verbal IQ, Social Responsiveness
Scale (SRS), Social communication questionnaire (SCQ), Clinical evaluation
of language fundamentals (CELF), Full scale IQ and Autism diagnostic
observation schedule (ADOS) and perceptual reasoning index (PRI).",No,Nothing is mentioned,No,Nothing is mentioned,No,Nothing is mentioned,Yes,"Section of Biomedical Image Analysis,
University of Pennsylvania, Philadelphia, PA, USA
{Madhura.Ingalhalikar,Ragini.Verma}@uphs.upenn.edu
2 Brain Behavior Laboratory, University of Pennsylvania, Philadelphia, PA, USA
3 Lurie Family Foundation’s MEG Imaging Center, Department of Radiology,
Children’s Hospital of Philadelphia, Philadelphia, PA, USA

The authors would like to acknowledge support from the NIH grants: MH092862,
MH079938 and DC008871.",No,Nothing is mentioned,No,Nothing is mentioned,No,Nothing is mentioned,No,Nothing is mentioned,
11/10/2022 10.09.05,123,2012,No,Other medical imaging task,"In this work we explore a new
framework where these sources of information can be propagated to morphologically
dissimilar images by diffusing and mapping the information
through intermediate steps. The spatially variant data embedding uses
the local morphology and intensity similarity between images to diffuse
the information only between locally similar images. This framework can
thus be used to propagate any information from any group of subject
to every other subject in a database with great accuracy. Comparison
to state-of-the-art propagation methods showed highly statistically significant
(p < 10−4) improvements in accuracy when propagating both
structural parcelations and brain segmentations geodesically.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
11/10/2022 10.10.48,126,2012,No,Other medical imaging task,"Diffusion spectrum imaging (DSI) from multiple diffusionweighted
images (DWI) allows to image the complex geometry of water
diffusion in biological tissue. To capture the structure of DSI data, we
propose to use sparse coding constrained by physical properties of the
signal, namely symmetry and positivity, to learn a dictionary of diffusion
profiles. Given this estimated model of the signal, we can extract
better estimates of the signal from noisy measurements and also speed
up acquisition by reducing the number of acquired DWI while giving
access to high resolution DSI data. The method learns jointly for all the
acquired DWI and scales to full brain data. Working with two sets of
515 DWI images acquired on two different subjects we show that using
just half of the data (258 DWI) we can better predict the other 257 DWI
than the classic symmetry procedure. The observation holds even if the
diffusion profiles are estimated on a different subject dataset from an
undersampled q-space of 40 measurements.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
11/10/2022 10.12.09,128,2012,No,Other medical imaging task,"Diffusion MRI measures micron scale displacement of water
molecules, providing unique insight into microstructural tissue architecture.
However, current practical image resolution is in the millimeter
scale, and thus diffusivities from many tissue compartments are averaged
in each voxel, reducing the sensitivity and specificity of the measurement
to subtle pathologies. Recent studies have pointed out that eliminating
the contribution of extracellular water increases the sensitivity of the
diffusion measures to tissue architecture. Moreover, in brain imaging,
estimation of the extracellular volume appears to indicate pathological
processes such as atrophy, edema and neuroinflammation. Here we study
the free-water method, which assumes a bi-tensor model. We add low bvalue
shells to a regular DTI acquisition and present methods to improve
the estimation of the model parameters using the extra information. In
addition, we define a Laplace-Beltrami regularization operator that further
stabilizes the multi-shell estimation.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
11/10/2022 10.13.21,130,2012,No,Other medical imaging task,"Current methods in high angular resolution diffusion imaging
(HARDI) estimate the probability density function of water diffusion
as a continuous-valued orientation distribution function (ODF) on
the sphere. However, such methods could produce an ODF with negative
values, because they enforce non-negativity only at finitely many
directions. In this paper, we propose to enforce non-negativity on the
continuous domain by enforcing the positive semi-definiteness of Toeplitzlike
matrices constructed from the spherical harmonic representation of
the ODF. We study the distribution of the eigenvalues of these
matrices and use it to derive an iterative semi-definite program that
enforces non-negativity on the continuous domain. We illustrate the performance
of our method and compare it",,,,,,,,,,,,,,,,,,,,,,,,,,,,
11/10/2022 10.23.19,137,2012,Yes,It was accurately labelled,"The experimental results of applying the HCRF classifier on real, multi-centre
clinical trial images acquired from 122 patients with Relapsing Remitting MS
(RRMS) yields a 98% sensitivity rate, 0.66 positive predictive value (PPV) and
an average of 1.55 FP counts per patient when compared to a set of “silver
standard” manual labels attained by expert consensus1","we present an automatic, probabilistic Hierarchical
Conditional Random Field (HCRF) framework for detection of gadenhancing
lesions in brain images of patients with MS.","The detection of gad-enhancing lesions in brain MRI of Multiple
Sclerosis (MS) patients is of great interest since they are important
markers of disease activity. However, many of the enhancing voxels are
associated with normal structures (i.e. blood vessels) or noise in the
MRI, making the detection of gad-enhancing lesions a challenging task.",Conditional Random Fields,Sensitivity,No,"A Conditional Random
Fields (CRF) [1] classifier was recently developed for this task, without relying
on the pre-segmentation of T2w lesions and using only commonly acquired
MRI sequences (",No,"The data was acquired from 122 patients with RRMS as part of a multi center
clinical trial (31 centers). The patients had varying levels of gad-enhancing lesion
loads, located in different areas of the brain WM, and showed varying amounts
of brain atrophy.","The HCRF classifier is trained on 92 randomly selected MRI volumes and
tested on the remaining 30 cases.",Private,"The data was acquired from 122 patients with RRMS as part of a multi center
clinical trial (31 centers). The patients had varying levels of gad-enhancing lesion
loads, located in different areas of the brain WM, and showed varying amounts
of brain atrophy.",No,Nothing is mentioned,No,Nothing is mentioned,Yes,"For this article: The data was acquired from 122 patients with RRMS as part of a multi center
clinical trial (31 centers).",No,"1 Centre for Intelligent Machines, McGill University, Canada
2 Montreal Neurological Institute, McGill University, Canada
3 NeuroRx Research, Montreal, Canada",No,Nothing is mentioned,No,Nothing is mentioned,No,Nothing is mentioned,No,Nothing is mentioned,
11/10/2022 10.24.45,150,2012,No,Other medical imaging task,"Coarctation of the aorta (CoA), is a congenital defect
characterized by a severe narrowing of the aorta, usually distal to the
aortic arch. The treatment options include surgical repair, stent implantation,
and balloon angioplasty. In order to evaluate the physiological
significance of the pre-operative coarctation and to assess the
post-operative results, the hemodynamic analysis is usually performed
by measuring the pressure gradient (P) across the coarctation site via
invasive cardiac catheterization.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
11/10/2022 10.29.37,152,2012,Yes,It was accurately labelled,"a neural network-based classifier is implemented to test the
effectiveness of the proposed morphological analysis approach","By exploiting the recent developments in Multirow-Detector
Computed Tomography (MDCT) scanner technology, the complex endocardial
surface morphology of the left ventricle is studied and the cardiac segments
affected by coronary arterial stenosis localized via analysis of Computed
Tomography (CT) image data obtained from a 320-MDCT scanner. The nonrigid
endocardial surface data is analyzed using an isometry-invariant Bag-of-
Words (BOW) feature-based approach. The clinical significance of the analysis
in identifying, localizing and quantifying the incidence and extent of coronary
artery disease is investigated. Specifically, the association between the
incidence and extent of coronary artery disease and the alterations in the
endocardial surface morphology is studied. The results of the proposed
approach on 15 normal data sets, and 12 abnormal data sets exhibiting coronary
artery disease with varying levels of severity are presented. Based on the
characterization of the endocardial surface morphology using the Bag-of-Words
features, a neural network-based classifier is implemented to test the
effectiveness of the proposed morphological analysis approach.","The complex morphological structure of the left ventricular
endocardial surface and its relation to the severity of arterial stenosis has not yet
been thoroughly investigated due to the limitations of conventional imaging
techniques.


Since CAD is a leading cause of morbidity and
mortality worldwide, techniques that improve diagnostic and prognostic effectiveness
have a potentially significant clinical impact.",Neural network,Accuracy,Yes,Left Ventricle Segmentation and Meshing,No,"We employed the proposed methods for segmentation, meshing and endocardial
surface shape description on 27 MDCT data sets consisting of 12 data sets from
cardiac patients and 15 data sets from normal subjects","We employed the proposed methods for segmentation, meshing and endocardial
surface shape description on 27 MDCT data sets consisting of 12 data sets from
cardiac patients and 15 data sets from normal subjects",Private,"We employed the proposed methods for segmentation, meshing and endocardial
surface shape description on 27 MDCT data sets consisting of 12 data sets from
cardiac patients and 15 data sets from normal subjects",No,Nothing is mentioned,No,"We employed the proposed methods for segmentation, meshing and endocardial
surface shape description on 27 MDCT data sets consisting of 12 data sets from
cardiac patients and 15 data sets from normal subjects",No,"We employed the proposed methods for segmentation, meshing and endocardial
surface shape description on 27 MDCT data sets consisting of 12 data sets from
cardiac patients and 15 data sets from normal subjects",No,"1 Department of Computer Science, The University of Georgia, Athens, GA, USA
2 Piedmont Heart Institute, Atlanta, GA, USA
3 Stony Brook University Medical Center, Stony Brook, NY, USA",No,Nothing is mentioned,No,Nothing is mentioned,No,Nothing is mentioned,No,Nothing is mentioned,
11/10/2022 10.30.28,153,2012,No,Segmentation,"Prior-Based Automatic Segmentation of the
Carotid Artery Lumen in TOF MRA (PASCAL)",,,,,,,,,,,,,,,,,,,,,,,,,,,,
11/10/2022 10.32.54,154,2012,No,Other medical imaging task,"Am unsure about this one - looks almost like classification of water/fat, but doesn't have performance measures that match anything",,,,,,,,,,,,,,,,,,,,,,,,,,,,
11/10/2022 10.40.07,157,2012,No,Other medical imaging task,"New minimal-invasive interventions such as transcatheter valve procedures
exploit multiple imaging modalities to guide tools (fluoroscopy) and visualize
soft tissue (transesophageal echocardiography (TEE)). Currently, these
complementary modalities are visualized in separate coordinate systems and on
separate monitors creating a challenging clinical workflow. This paper proposes
a novel framework for fusing TEE and fluoroscopy by detecting the pose of the
TEE probe in the fluoroscopic image. Probe pose detection is challenging in
fluoroscopy and conventional computer vision techniques are not well suited.
Current research requires manual initialization or the addition of fiducials. The
main contribution of this paper is autonomous six DoF pose detection by combining
discriminative learning techniques with a fast binary template library.
The pose estimation problem is reformulated to incrementally detect pose parameters
by exploiting natural invariances in the image. The theoretical contribution
of this paper is validated on synthetic, phantom and in vivo data. The
practical application of this technique is supported by accurate results (< 5 mm
in-plane error) and computation time of 0.5s",,,,,,,,,,,,,,,,,,,,,,,,,,,,
11/10/2022 10.40.44,162,2012,No,Other medical imaging task,"We propose novel methods for (a) detection of a catheter
in fluoroscopic images and (b) reconstruction of this catheter from two
views. The novelty of (a) is a reduced user interaction and a higher
accuracy. It requires only a single seed point on the catheter in the fluoroscopic
image. Using this starting point, possible parts of the catheter
are detected using a graph search. An evaluation of the detection using
66 clinical fluoroscopic images yielded an average error of 0.7 mm ± 2.0
mm. The novelty of (b) is a better ability to deal with highly curved
objects as it selects an optimal set of point correspondences from two
point sequences describing the catheters in two fluoroscopic images. The
selected correspondences are then used for computation of the 3-D reconstruction.
The evaluation on 33 clinical biplane images yielded an
average backprojection error of 0.4 mm ± 0.6 mm.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
11/10/2022 10.47.27,163,2012,Yes,It was accurately labelled,"Feature Classification
for Tracking Articulated Surgical Tools","we describe a tracking system which
learns visual feature descriptors as class-specific landmarks on an articulated tool.","Tool tracking is an accepted capability for computer-aided surgical intervention
which has numerous applications, both in robotic and manual
minimally-invasive procedures.",Randomized Trees,Accuracy,Yes,"Although the integral images afford efficient extractions of the covariances, we can
reduce the computations further by initially segmenting the pixels of the image to identify
areas of interest to classify.",No,We experimented on previously collected porcine data from a da Vinci R  surgical robot.,"Overall, we use ∼ 15,000 training samples across the 7 classes.
Couldn't find the size of the test set",Private,Nothing public is referenced,No,Nothing is mentioned,No,"Not relevant, porcine data",Yes,For this article: We begin by collecting data to train our classifier,No,"1 Columbia University, New York NY USA
{areiter,allen}@cs.columbia.edu
2 Intuitive Surgical, Inc, Sunnyvale CA USA
tao.zhao@intusurg.com",No,"Not relevant, porcine data",No,Nothing is mentioned,No,"Not relevant, porcine data",No,Nothing is mentioned,
11/10/2022 10.50.08,169,2012,No,Other medical imaging task,"Image registration is an important tool for imaging validation
studies investigating the effect of underlying focal disease on the
imaging signal. The strength of the conclusions drawn from these analyses
is limited by statistical power. Based on the observation that in
this context, statistical power depends in part on uncertainty arising
from registration error, we derive a power calculation formula relating
registration error, sample size, and the minimum detectable difference
between normal and pathologic regions on imaging. Statistical mappings
between target registration error and fractional overlap metrics are also
derived, and Monte Carlo simulations are used to evaluate the derived
models and test the strength of their assumptions.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
11/10/2022 10.53.56,174,2012,No,Other medical imaging task,"In this work, we propose an original and efficient approach
to exploit the ability of Compressed Sensing (CS) to recover Diffusion
MRI (dMRI) signals from a limited number of samples while efficiently
recovering important diffusion features such as the Ensemble Average
Propagator (EAP) and the Orientation Distribution Function (ODF).
Some attempts to sparsely represent the diffusion signal have already
been performed. However and contrarly to what has been presented in
CS dMRI, in this work we propose and advocate the use of a well adapted
learned dictionary and show that it leads to a sparser signal estimation
as well as to an efficient reconstruction of very important diffusion
features. We first propose to learn and design a sparse and parametric
dictionary from a set of training diffusion data. Then, we propose a
framework to analytically estimate in closed form two important diffusion
features : the EAP and the ODF. Various experiments on synthetic,
phantom and human brain data have been carried out and promising
results with reduced number of atoms have been obtained on diffusion
signal reconstruction, thus illustrating the added value of our method
over state-of-the-art SHORE and SPF based approaches.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
11/10/2022 10.55.47,177,2012,No,Other medical imaging task,"The geometry of white matter tracts is of increased interest
for a variety of neuroscientific investigations, as it is a feature reflective of
normal neurodevelopment and disease factors that may affect it. In this
paper, we introduce a novel method for computing multi-scale fibre tract
shape and geometry based on the differential geometry of curve sets. By
measuring the variation of a curve’s tangent vector at a given point in all
directions orthogonal to the curve, we obtain a 2D “dispersion distribution
function” at that point. That is, we compute a function on the unit
circle which describes fibre dispersion, or fanning, along each direction
on the circle. Our formulation is then easily incorporated into a continuous
scale-space framework. We illustrate our method on different fibre
tracts and apply it to a population study on hemispheric lateralization
in healthy controls. We conclude with directions for future work.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
11/10/2022 10.58.07,182,2012,No,Other medical imaging task,"Methods that leverage neighbourhood structures in highdimensional
image spaces have recently attracted attention. These approaches
extract information from a new image using its “neighbours” in
the image space equipped with an application-specific distance. Finding
the neighbourhood of a given image is challenging due to large dataset
sizes and costly distance evaluations. Furthermore, automatic neighbourhood
search for a new image is currently not possible when the distance
is based on ground truth annotations. In this article we present a general
and efficient solution to these problems. “Neighbourhood Approximation
Forests” (NAF) is a supervised learning algorithm that approximates the
neighbourhood structure resulting from an arbitrary distance. As NAF
uses only image intensities to infer neighbours it can also be applied
to distances based on ground truth annotations. We demonstrate NAF
in two scenarios: i) choosing neighbours with respect to a deformationbased
distance, and ii) age prediction from brain MRI. The experiments
show NAF’s approximation quality, computational advantages and use
in different contexts.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
11/10/2022 11.00.34,189,2012,No,Other medical imaging task,"We propose a method for deformable registration based on
learning the manifolds of individual brain regions. Recent publications
on registration of medical images advocate the use of manifold learning
in order to confine the search space to anatomically plausible deformations.
Existing methods construct manifolds based on a single metric over
the entire image domain thus frequently miss regional brain variations.
We address this issue by first learning manifolds for specific regions and
then computing region-specific deformations from these manifolds. We
then determine deformations for the entire image domain by learning the
global manifold in such a way that it preserves the region-specific deformations.
We evaluate the accuracy of our method by applying it to the
LPBA40 dataset and measuring the overlap of the deformed segmentations.
The result shows significant improvement in registration accuracy
on cortex regions compared to other state of the art methods.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
11/10/2022 12.19.48,194,2012,Yes,It was accurately labelled,"In this paper we propose an auditory stimulation and Near Infra-Red
Spectroscopy (NIRS) hemodynamic changes acquisition protocol for preterm
neonates. This study is designed to assess the specific characteristics of
neurovascular coupling to auditory stimuli in healthy and ill neonate brains. The
method could lead to clinical application in Intra-Ventricular Hemorrhage
(IVH) diagnosis along with other techniques such as EEG. We propose a
realistic head model creation with all useful head structures and brain tissues
including the neonate fontanel for more accurate results from NIRS signals
modeling. We also design a 3D imaging tool for dynamic mapping and analysis
of brain activation onto the cortex surface. Results show significant differences
in oxy-hemoglobin between healthy neonates and subjects with IVH.","We propose a
realistic head model creation with all useful head structures and brain tissues
including the neonate fontanel for more accurate results from NIRS signals
modeling. We also design a 3D imaging tool for dynamic mapping and analysis
of brain activation onto the cortex surface. Results show significant differences
in oxy-hemoglobin between healthy neonates and subjects with IVH.","Low arterial blood oxygenation and abnormal cerebral
blood flow is believed to influence the function of the neonatal brain [1]. Preterm
neonates are at high-risk of IVH because of their lack of ability to regulate cerebral blood
flow and pressure [2].",Multimodality atlas,AUC,Yes,"The fontanel was segmented from the CT-Scan using a
variational level-set method",No,"This study was carried out on two groups; the first one is composed of 12 healthy control
subjects and the second one of 7 ill subjects with IVH of grade III-IV. All subjects of
both groups are preterm neonates of gestational age from 28 to 32 weeks; tested during
their sleep between 2 and 4 days after birth. Subjects were submitted to auditory stimuli
which consist of two digitized syllables /ba/ and /ga/ as in a previous EEG study [9].
Three stimulations conditions were used: the standard one (ST: four /ba/ male); deviant
voice (DV: three /ba/ male, one /ba/ female); and deviant phoneme (DP: three /ba/ male,
one /ga/ male). The four syllables block duration is 4s and total stimulation (20s) is
composed of five consecutive blocks. A newborn special NIRS probe showed in Fig. 1(a)
was designed and consists of two patches containing two detectors and sixteen light
sources in each of them (8 to λ=690nm; 8 to λ=830nm wavelengths). Twenty acquisition
channels, ten per hemisphere, are measured in the configuration showed in Fig. 1(b). We
used a multi-channel frequency domain based optical imaging system (Imagent, ISS Inc.)
for the acquisition of oxygenated hemoglobin (HbO) and deoxygenated hemoglobin (Hb)
changes during auditory stimuli. Values of HbO and Hb and their changes were obtained
using the relation between absorption spectroscopic coefficients of the environment and
chromophore concentrations according to the modified Beer-Lambert law [10] used in
NIRS studies.","This study was carried out on two groups; the first one is composed of 12 healthy control
subjects and the second one of 7 ill subjects with IVH of grade III-IV. All subjects of
both groups are preterm neonates of gestational age from 28 to 32 weeks; tested during
their sleep between 2 and 4 days after birth. Subjects were submitted to auditory stimuli
which consist of two digitized syllables /ba/ and /ga/ as in a previous EEG study [9].
Three stimulations conditions were used: the standard one (ST: four /ba/ male); deviant
voice (DV: three /ba/ male, one /ba/ female); and deviant phoneme (DP: three /ba/ male,
one /ga/ male). The four syllables block duration is 4s and total stimulation (20s) is
composed of five consecutive blocks. A newborn special NIRS probe showed in Fig. 1(a)
was designed and consists of two patches containing two detectors and sixteen light
sources in each of them (8 to λ=690nm; 8 to λ=830nm wavelengths). Twenty acquisition
channels, ten per hemisphere, are measured in the configuration showed in Fig. 1(b). We
used a multi-channel frequency domain based optical imaging system (Imagent, ISS Inc.)
for the acquisition of oxygenated hemoglobin (HbO) and deoxygenated hemoglobin (Hb)
changes during auditory stimuli. Values of HbO and Hb and their changes were obtained
using the relation between absorption spectroscopic coefficients of the environment and
chromophore concentrations according to the modified Beer-Lambert law [10] used in
NIRS studies.",Private,"This study was carried out on two groups; the first one is composed of 12 healthy control
subjects and the second one of 7 ill subjects with IVH of grade III-IV. All subjects of
both groups are preterm neonates of gestational age from 28 to 32 weeks; tested during
their sleep between 2 and 4 days after birth. Subjects were submitted to auditory stimuli
which consist of two digitized syllables /ba/ and /ga/ as in a previous EEG study [9].
Three stimulations conditions were used: the standard one (ST: four /ba/ male); deviant
voice (DV: three /ba/ male, one /ba/ female); and deviant phoneme (DP: three /ba/ male,
one /ga/ male). The four syllables block duration is 4s and total stimulation (20s) is
composed of five consecutive blocks. A newborn special NIRS probe showed in Fig. 1(a)
was designed and consists of two patches containing two detectors and sixteen light
sources in each of them (8 to λ=690nm; 8 to λ=830nm wavelengths). Twenty acquisition
channels, ten per hemisphere, are measured in the configuration showed in Fig. 1(b). We
used a multi-channel frequency domain based optical imaging system (Imagent, ISS Inc.)
for the acquisition of oxygenated hemoglobin (HbO) and deoxygenated hemoglobin (Hb)
changes during auditory stimuli. Values of HbO and Hb and their changes were obtained
using the relation between absorption spectroscopic coefficients of the environment and
chromophore concentrations according to the modified Beer-Lambert law [10] used in
NIRS studies.",Yes,"This study was carried out on two groups; the first one is composed of 12 healthy control
subjects and the second one of 7 ill subjects with IVH of grade III-IV. All subjects of
both groups are preterm neonates of gestational age from 28 to 32 weeks; tested during
their sleep between 2 and 4 days after birth. Subjects were submitted to auditory stimuli
which consist of two digitized syllables /ba/ and /ga/ as in a previous EEG study [9].
Three stimulations conditions were used: the standard one (ST: four /ba/ male); deviant
voice (DV: three /ba/ male, one /ba/ female); and deviant phoneme (DP: three /ba/ male,
one /ga/ male). The four syllables block duration is 4s and total stimulation (20s) is
composed of five consecutive blocks. A newborn special NIRS probe showed in Fig. 1(a)
was designed and consists of two patches containing two detectors and sixteen light
sources in each of them (8 to λ=690nm; 8 to λ=830nm wavelengths). Twenty acquisition
channels, ten per hemisphere, are measured in the configuration showed in Fig. 1(b). We
used a multi-channel frequency domain based optical imaging system (Imagent, ISS Inc.)
for the acquisition of oxygenated hemoglobin (HbO) and deoxygenated hemoglobin (Hb)
changes during auditory stimuli. Values of HbO and Hb and their changes were obtained
using the relation between absorption spectroscopic coefficients of the environment and
chromophore concentrations according to the modified Beer-Lambert law [10] used in
NIRS studies.",No,Nothing is mentioned,Yes,For this article,No,"1 GRAMFC, Inserm U1105, CHU Amiens, University of Picardie Jules Verne, Amiens, France
{marc.fournier,mahdi.mahmoudzadeh,guy.kongolo,reinhard.grebe,
fabrice.wallois}@u-picardie.fr
2 Dept. of Electrical and Electronics Engineering, Shiraz University of Technology, Shiraz, Iran
kazemi@sutech.ac.ir
3 NeuroSpin, CEA, Inserm U992, Cognitive Neuroimaging, University Paris XI, Paris, France
ghislaine.dehaene@cea.fr",No,Nothing is mentioned,No,Nothing is mentioned,No,Nothing is mentioned,No,Nothing is mentioned,
11/10/2022 12.20.57,197,2012,No,Other medical imaging task,"We propose a metamorphic geodesic regression approach approximating
spatial transformations for image time-series while simultaneously
accounting for intensity changes. Such changes occur for example
in magnetic resonance imaging (MRI) studies of the developing brain due
to myelination. To simplify computations we propose an approximate
metamorphic geodesic regression formulation that only requires pairwise
computations of image metamorphoses. The approximated solution is an
appropriately weighted average of initial momenta. To obtain initial momenta
reliably, we develop a shooting method for image metamorphosis.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
11/10/2022 12.25.55,202,2012,Yes,It was accurately labelled,"we
investigate a tree-guided sparse coding method to identify grouped imaging
features in the brain regions for guiding disease classification and interpretation.","we
investigate a tree-guided sparse coding method to identify grouped imaging
features in the brain regions for guiding disease classification and interpretation.","Neuroimage analysis based on machine learning technologies has
been widely employed to assist the diagnosis of brain diseases such as
Alzheimer's disease and its prodromal stage - mild cognitive impairment. One
of the major problems in brain image analysis involves learning the most
relevant features from a huge set of raw imaging features, which are far more
numerous than the training samples. This makes the tasks of both disease
classification and interpretation extremely challenging. Sparse coding via L1
regularization, such as Lasso, can provide an effective way to select the most
relevant features for alleviating the curse of dimensionality and achieving more
accurate classification. However, the selected features may distribute randomly
throughout the whole brain, although in reality disease-induced abnormal
changes often happen in a few contiguous regions.",SVM,Accuracy,Yes,"Then, each image was segmented
into three brain tissues, i.e., gray matter (GM), white matter (WM), and cerebrospinal
fluid (CSF),",Yes,"We evaluate the proposed classification algorithm with the T1-weighted baseline MR
brain images of 643 subjects, which include 196 AD patients, 220 MCI subjects, and
227 normal controls (NC), randomly selected from Alzheimer's Disease
Neuroimaging Initiative (ADNI) database.","We evaluate the proposed classification algorithm with the T1-weighted baseline MR
brain images of 643 subjects, which include 196 AD patients, 220 MCI subjects, and
227 normal controls (NC), randomly selected from Alzheimer's Disease
Neuroimaging Initiative (ADNI) database.",Public,ADNI,No,Nothing is mentioned,Yes,"Table 1 provides a summary of the
demographic characteristics of the studied subjects (denoted as mean ± standard
deviation). (and shows age and gender as the only demographic information)",No,Nothing is mentioned,Yes,"1 IDEA Lab, Department of Radiology and BRIC,
University of North Carolina at Chapel Hill, USA
2 Department of Instrument Science and Technology,
Shanghai Jiao Tong University, China
3 Department of Computer Science and Engineering,
Nanjing University of Aeronautics and Astronautics, China

This work was partially supported by NIH grants EB006733, EB008374, EB009634, AG041721,
and MH088520, Medical and Engineering Foundation of Shanghai Jiao Tong University (No.
YG2010MS74), and NSFC grants (No. 61005024 and 60875030).",No,Nothing is mentioned,No,Nothing is mentioned,No,Nothing is mentioned,No,Nothing is mentioned,
16/10/2022 09.34.12,203,2012,Yes,It was accurately labelled,"The benefits of our approach are twofold. First it uses the
reference database for prediction, i.e. to provide potential biomarkers in
a clinical setting. Second it increases statistical power on the new task.
We demonstrate on a set of 18 pairs of functional MRI experimental
conditions that our approach gives good prediction.","we propose to use a database
of images, rather than coordinates, and frame the problem as transfer
learning: learning a discriminant model on a reference task to apply it
to a different but related new task. To facilitate statistical analysis of
small cohorts, we use a sparse discriminant model that selects predictive
voxels on the reference task and thus provides a principled procedure to
define ROIs.","Typical cohorts in brain imaging studies are not large enough
for systematic testing of all the information contained in the images. To
build testable working hypotheses, investigators thus rely on analysis
of previous work, sometimes formalized in a so-called meta-analysis. In
brain imaging, this approach underlies the specification of regions of interest
(ROIs) that are usually selected on the basis of the coordinates of
previously detected effects. In this paper, we propose to use a database
of images, rather than coordinates, and frame the problem as transfer
learning:",logistic regression,Accuracy,No,Nothing is mentioned,No,"We use 3 studies for this meta-analysis. The first study (E1) [11] is composed
of 322 subjects and was designed to assess the inter-subject variability in some
language, calculation, and sensorimotor tasks. The second study (E2) is similar
to the first one in terms of stimuli, but its data was acquired on 35 pairs of twinsubjects.
The last study (E3) [12] characterizes brain regions in charge of the
syntactic and the semantic processing for the language. It was performed with
40 subjects, 20 of which were stimulated by pseudowords (jabberwocky stimuli)
instead of actual meaningful sentences. All the studies were pre-processed and
analyzed with the standard fMRI analysis software SPM5. The data used for this
work are the statistical images resulting from the intra-subject analyses across
the 3 studies. E1 has 34 contrasts images available, E2 56, and E3 28. The raw
images were not always acquired on the same scanner. E1 has data from a 3T
SIEMENS Trio, and a 3T Brucker scanner; E2 data were acquired on a 1.5T
GE Signa; and E3 images come from the same 3T SIEMENS Trio.","We use 3 studies for this meta-analysis. The first study (E1) [11] is composed
of 322 subjects and was designed to assess the inter-subject variability in some
language, calculation, and sensorimotor tasks. The second study (E2) is similar
to the first one in terms of stimuli, but its data was acquired on 35 pairs of twinsubjects.
The last study (E3) [12] characterizes brain regions in charge of the
syntactic and the semantic processing for the language. It was performed with
40 subjects, 20 of which were stimulated by pseudowords (jabberwocky stimuli)
instead of actual meaningful sentences. All the studies were pre-processed and
analyzed with the standard fMRI analysis software SPM5. The data used for this
work are the statistical images resulting from the intra-subject analyses across
the 3 studies. E1 has 34 contrasts images available, E2 56, and E3 28. The raw
images were not always acquired on the same scanner. E1 has data from a 3T
SIEMENS Trio, and a 3T Brucker scanner; E2 data were acquired on a 1.5T
GE Signa; and E3 images come from the same 3T SIEMENS Trio.",Private,"We use 3 studies for this meta-analysis. The first study (E1) [11] is composed
of 322 subjects and was designed to assess the inter-subject variability in some
language, calculation, and sensorimotor tasks. The second study (E2) is similar
to the first one in terms of stimuli, but its data was acquired on 35 pairs of twinsubjects.
The last study (E3) [12] characterizes brain regions in charge of the
syntactic and the semantic processing for the language. It was performed with
40 subjects, 20 of which were stimulated by pseudowords (jabberwocky stimuli)
instead of actual meaningful sentences. All the studies were pre-processed and
analyzed with the standard fMRI analysis software SPM5. The data used for this
work are the statistical images resulting from the intra-subject analyses across
the 3 studies. E1 has 34 contrasts images available, E2 56, and E3 28. The raw
images were not always acquired on the same scanner. E1 has data from a 3T
SIEMENS Trio, and a 3T Brucker scanner; E2 data were acquired on a 1.5T
GE Signa; and E3 images come from the same 3T SIEMENS Trio.",No,"We use 3 studies for this meta-analysis. The first study (E1) [11] is composed
of 322 subjects and was designed to assess the inter-subject variability in some
language, calculation, and sensorimotor tasks. The second study (E2) is similar
to the first one in terms of stimuli, but its data was acquired on 35 pairs of twinsubjects.
The last study (E3) [12] characterizes brain regions in charge of the
syntactic and the semantic processing for the language. It was performed with
40 subjects, 20 of which were stimulated by pseudowords (jabberwocky stimuli)
instead of actual meaningful sentences. All the studies were pre-processed and
analyzed with the standard fMRI analysis software SPM5. The data used for this
work are the statistical images resulting from the intra-subject analyses across
the 3 studies. E1 has 34 contrasts images available, E2 56, and E3 28. The raw
images were not always acquired on the same scanner. E1 has data from a 3T
SIEMENS Trio, and a 3T Brucker scanner; E2 data were acquired on a 1.5T
GE Signa; and E3 images come from the same 3T SIEMENS Trio.",No,"We use 3 studies for this meta-analysis. The first study (E1) [11] is composed
of 322 subjects and was designed to assess the inter-subject variability in some
language, calculation, and sensorimotor tasks. The second study (E2) is similar
to the first one in terms of stimuli, but its data was acquired on 35 pairs of twinsubjects.
The last study (E3) [12] characterizes brain regions in charge of the
syntactic and the semantic processing for the language. It was performed with
40 subjects, 20 of which were stimulated by pseudowords (jabberwocky stimuli)
instead of actual meaningful sentences. All the studies were pre-processed and
analyzed with the standard fMRI analysis software SPM5. The data used for this
work are the statistical images resulting from the intra-subject analyses across
the 3 studies. E1 has 34 contrasts images available, E2 56, and E3 28. The raw
images were not always acquired on the same scanner. E1 has data from a 3T
SIEMENS Trio, and a 3T Brucker scanner; E2 data were acquired on a 1.5T
GE Signa; and E3 images come from the same 3T SIEMENS Trio.",No,Nothing is mentioned,No,"1 Parietal Team, INRIA Saclay-ˆIle-de-France, Saclay, France
yannick.schwartz@inria.fr
2 CEA, DSV, I2BM, Neurospin bˆat 145, 91191 Gif-Sur-Yvette, France
3 INSERM, CEA, Cognitive Neuroimaging Unit, Neurospin Center, France

",No,Nothing is mentioned,No,Nothing is mentioned,No,Nothing is mentioned,No,Nothing is mentioned,
16/10/2022 09.37.47,205,2012,No,Other medical imaging task,"A bit in doubt, but none of the expected performance measures were there

Sparse learning has recently received increasing attentions in
neuroimaging research such as brain disease diagnosis and progression. Most
existing studies focus on cross-sectional analysis, i.e., learning a sparse model
based on single time-point of data. However, in some brain imaging
applications, multiple time-points of data are often available, thus longitudinal
analysis can be performed to better uncover the underlying disease progression
patterns. In this paper, we propose a novel temporally-constrained group sparse
learning method aiming for longitudinal analysis with multiple time-points of
data. Specifically, for each time-point, we train a sparse linear regression model
by using the imaging data and the corresponding responses, and further use the
group regularization to group the weights corresponding to the same brain
region across different time-points together. Moreover, to reflect the smooth
changes between adjacent time-points of data, we also include two smoothness
regularization terms into the objective function, i.e., one fused smoothness term
which requires the differences between two successive weight vectors from
adjacent time-points should be small, and another output smoothness term
which requires the differences between outputs of two successive models from
adjacent time-points should also be small. We develop an efficient algorithm to
solve the new objective function with both group-sparsity and smoothness
regularizations. We validate our method through estimation of clinical cognitive
scores using imaging data at multiple time-points which are available in the
Alzheimer’s Disease Neuroimaging Initiative (ADNI) database.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
16/10/2022 09.42.23,206,2012,Yes,It was accurately labelled,The criterion function of SFFS was the accuracy of the SVM classifier,"We applied the feature analysis method
to a large TCS dataset that is relevant for clinical practice and includes
the variability that is present under real conditions. In order to decrease
the influence to the image properties from the different settings of ultrasound
machine, we propose a local image analysis method using an
invariant scale blob detection for the hyperechogenicity estimation. The
local features are extracted from the detected blobs and the watershed
regions in half of mesencephalon area. The performance of these features
is evaluated by a feature-selection method. The cross validation results
show that the local features could be used for PD detection.","Transcranial sonography (TCS) is a new tool for the diagnosis
of Parkinson’s disease (PD) according to a distinct hyperechogenic
pattern in the substantia nigra (SN) region. However a procedure including
rating scale of SN hyperechogenicity was required for a standard clinical
setting with increased use.",SVM,"Accuracy, Confusion matrix",Yes,"Secondly, based on the manually segmented HoM images which were
marked by the physicians, the suspicious hyperechogenicity areas were localized
by the invariant scale blob detection method.",No,"The experiments were based on three data sets which were obtained with Philips
SONOS 5500 by different examiners. Dataset 1 includes 42 TCS images from 23
PD patients and 36 TCS images from 21 healthy controls. Dataset 2 includes
15 PD TCS images from ten PD patients and eight control images from four
controls. The last dataset consisted of ten PD TCS images from five PD patients
and 27 TCS from 14 controls. Totally, this large dataset includes 67 PD images
from 38 PD patients and 71 control images from 39 healthy subjects.","The experiments were based on three data sets which were obtained with Philips
SONOS 5500 by different examiners. Dataset 1 includes 42 TCS images from 23
PD patients and 36 TCS images from 21 healthy controls. Dataset 2 includes
15 PD TCS images from ten PD patients and eight control images from four
controls. The last dataset consisted of ten PD TCS images from five PD patients
and 27 TCS from 14 controls. Totally, this large dataset includes 67 PD images
from 38 PD patients and 71 control images from 39 healthy subjects.",Private,"The experiments were based on three data sets which were obtained with Philips
SONOS 5500 by different examiners. Dataset 1 includes 42 TCS images from 23
PD patients and 36 TCS images from 21 healthy controls. Dataset 2 includes
15 PD TCS images from ten PD patients and eight control images from four
controls. The last dataset consisted of ten PD TCS images from five PD patients
and 27 TCS from 14 controls. Totally, this large dataset includes 67 PD images
from 38 PD patients and 71 control images from 39 healthy subjects.",No,"The experiments were based on three data sets which were obtained with Philips
SONOS 5500 by different examiners. Dataset 1 includes 42 TCS images from 23
PD patients and 36 TCS images from 21 healthy controls. Dataset 2 includes
15 PD TCS images from ten PD patients and eight control images from four
controls. The last dataset consisted of ten PD TCS images from five PD patients
and 27 TCS from 14 controls. Totally, this large dataset includes 67 PD images
from 38 PD patients and 71 control images from 39 healthy subjects.",No,Nothing is mentioned,No,"Possibly for this article, but hard to tell...

The experiments were based on three data sets which were obtained with Philips
SONOS 5500 by different examiners. Dataset 1 includes 42 TCS images from 23
PD patients and 36 TCS images from 21 healthy controls. Dataset 2 includes
15 PD TCS images from ten PD patients and eight control images from four
controls. The last dataset consisted of ten PD TCS images from five PD patients
and 27 TCS from 14 controls. Totally, this large dataset includes 67 PD images
from 38 PD patients and 71 control images from 39 healthy subjects.",No,"1 Institute for Signal Processing, University of Luebeck, Germany
2 Department of Neurology, University Hospital Schleswig-Holstein, Germany
3 Graduate School, University of Luebeck, Germany",No,Nothing is mentioned,No,Nothing is mentioned,No,Nothing is mentioned,No,Nothing is mentioned,
16/10/2022 09.44.52,208,2012,No,Other medical imaging task,"Almost classification, they research a new possible biomarker for Alzheimers prediction, but do not directly do classification, more some form of exploration 

Cortical thinning is a widely used and powerful biomarker
for measuring disease progression in Alzheimer’s disease (AD). However,
there has been little work on the effect of atrophy on the cortical folding
patterns. In this study, we examined whether the cortical folding could
be used as a biomarker of AD. Cortical folding metrics were computed
on 678 patients from the Alzheimer’s Disease Neuroimaging Initiative
(ADNI) cohort. For each subject, the boundary between grey matter and
white matter was extracted using a level set technique. At each point on
the boundary two metrics characterising folding, curvedness and shape
index, were generated. Joint histograms using these metrics were calculated
for five regions of interest (ROIs): frontal, temporal, occipital, and
parietal lobes as well as the cingulum. Pixelwise statistical maps were
generated from the joint histograms using permutations tests. In each
ROI, a significant reduction was observed between controls and AD in
areas associated with the sulcal folds, suggesting a sulcal opening associated
with neurodegeneration. When comparing to MCI patients, the
regions of significance were smaller but overlapping with those regions
found comparing controls to AD. It indicates that the differences in cortical
folding are progressive and can be detected before formal diagnosis
of AD. Our preliminary analysis showed a viable signal in the cortical
folding patterns for Alzheimer’s disease that should be explored further.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
16/10/2022 09.51.56,213,2012,Yes,It was accurately labelled,"We propose a novel approach to detect fusion
and undocking events by first searching for docked vesicles that ‘disappear’ from
the field of view, and then using a diffusion model to classify them as either fusion
or undocking events.","We propose a novel approach to detect fusion
and undocking events by first searching for docked vesicles that ‘disappear’ from
the field of view, and then using a diffusion model to classify them as either fusion
or undocking events.","Fluorescently-tagged proteins located on vesicles can fuse with the
surface membrane (visualised as a ‘puff’) or undock and return back into the bulk
of the cell. Detection and quantitative measurement of these events from timelapse
videos has proven difficult.",own algorithm - cannot find any keywords I relate,"Accuracy, Precision, Recall",No,Nothing is mentioned,No,"Our data
set comprises of four videos1.","Our data
set comprises of four videos1.",Private,"Our data
set comprises of four videos1.",No,Nothing is mentioned,No,Nothing is mentioned,No,Nothing is mentioned,No,"1 Department of Computer Science, University of Oxford, UK
2 Department of Computer Science, University of Bristol, UK
3 Department of Biochemistry, University of Bristol, UK",No,Nothing is mentioned,No,Nothing is mentioned,No,Nothing is mentioned,No,Nothing is mentioned,
16/10/2022 09.59.07,215,2012,Yes,It was accurately labelled,"In low-resource areas, the most common method of tuberculosis
(TB) diagnosis is visual identification of rod-shaped TB bacilli
in microscopic images of sputum smears. We present an algorithm for
automated TB detection using images from digital microscopes such as
CellScope [2], a novel, portable device capable of brightfield and fluorescence
microscopy. Automated processing on such platforms could
save lives by bringing healthcare to rural areas with limited access to
laboratory-based diagnostics. Our algorithm applies morphological operations
and template matching with a Gaussian kernel to identify candidate
TB-objects. We characterize these objects using Hu moments,
geometric and photometric features, and histograms of oriented gradients
and then perform support vector machine classification.","e present an algorithm for
automated TB detection using images from digital microscopes such as
CellScope [2], a novel, portable device capable of brightfield and fluorescence
microscopy","Automated processing on such platforms could
save lives by bringing healthcare to rural areas with limited access to
laboratory-based diagnostics",SVM,"Specificity, Precision, Recall, Sensitivity",No,"We propose a TB detection algorithm for FM with three stages: (1) candidate
TB-object identification, (2) feature representation, and (3) discriminative classification.",No,"Our dataset consists of sputum smear slides collected at clinics in Uganda. Fluorescence
images of these smears were taken using CellScope, which has a 0.4NA
objective and an 8-bit monochrome CMOS camera. CellScope gives a Rayleigh
resolution of 0.76μm and is capable of effective magnifications of 2000-3000x.
The CellScope images are 1944x2592 pixels and cover a 640x490μm field of view
at the smear-referenced plane. We use 594 CellScope images (296 TB-positive,
298 TB-negative), which correspond to 290 patients (143 TB-positive, 147 TBnegative).
We have slide-level human reader and culture classification results for
all 290 slides.","Our dataset consists of sputum smear slides collected at clinics in Uganda. Fluorescence
images of these smears were taken using CellScope, which has a 0.4NA
objective and an 8-bit monochrome CMOS camera. CellScope gives a Rayleigh
resolution of 0.76μm and is capable of effective magnifications of 2000-3000x.
The CellScope images are 1944x2592 pixels and cover a 640x490μm field of view
at the smear-referenced plane. We use 594 CellScope images (296 TB-positive,
298 TB-negative), which correspond to 290 patients (143 TB-positive, 147 TBnegative).
We have slide-level human reader and culture classification results for
all 290 slides.",Public,Our dataset and human annotations will be publicly available.,Yes,"Our dataset consists of sputum smear slides collected at clinics in Uganda. Fluorescence
images of these smears were taken using CellScope, which has a 0.4NA
objective and an 8-bit monochrome CMOS camera. CellScope gives a Rayleigh
resolution of 0.76μm and is capable of effective magnifications of 2000-3000x.
The CellScope images are 1944x2592 pixels and cover a 640x490μm field of view
at the smear-referenced plane. We use 594 CellScope images (296 TB-positive,
298 TB-negative), which correspond to 290 patients (143 TB-positive, 147 TBnegative).
We have slide-level human reader and culture classification results for
all 290 slides.",No,Nothing is mentioned,No,"Perhaps for this article: We would like to thank our collaborators at the Mulago
Hospital of Kampala, Uganda, who provided the sputum smears used in this
study.",Yes,"1 UC Berkeley Department of Electrical Engineering and Computer Sciences
2 UC Berkeley Department of Bioengineering
3 UC San Francisco Medical School and San Francisco General Hospital

We would like to thank our collaborators at the Mulago
Hospital of Kampala, Uganda, who provided the sputum smears used in this
study.",No,Nothing is mentioned,Yes,"Though tuberculosis (TB) receives relatively little attention in high-income countries,
it remains the second leading cause of death from infectious disease worldwide
(second only to HIV/AIDS)

Hence, with the advent of low-cost digital microscopy, automated TB diagnosis presents a ready opportunity
for the application of modern computer vision techniques to a real-world,
high-impact problem.

Sputum smear microscopy continues to be by far the
most widely used method of TB diagnosis, suggesting that enhancements to
microscopy-based screening methods could provide significant benefit to large
numbers of TB-burdened communities across the globe.",No,Nothing is mentioned,Yes,"The dataset and code is made available - though no link to where: We will release
our dataset, annotations, and code, which we hope will provide helpful
insights for future approaches to quantitative TB diagnosis.
",
16/10/2022 10.00.01,217,2012,No,Segmentation,"We provide a fully automatic method of segmenting vertebrae
in DXA images.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
16/10/2022 10.00.59,226,2012,No,Other medical imaging task,"The recently proposed Sparse Shape Composition (SSC)
opens a new avenue for shape prior modeling. Instead of assuming any
parametric model of shape statistics, SSC incorporates shape priors onthe-
fly by approximating a shape instance (usually derived from appearance
cues) by a sparse combination of shapes in a training repository.
Theoretically, one can increase the modeling capability of SSC by including
as many training shapes in the repository. However, this strategy confronts
two limitations in practice. First, since SSC involves an iterative
sparse optimization at run-time, the more shape instances contained in
the repository, the less run-time efficiency SSC has. Therefore, a compact
and informative shape dictionary is preferred to a large shape repository.
Second, in medical imaging applications, training shapes seldom come in
one batch. It is very time consuming and sometimes infeasible to reconstruct
the shape dictionary every time new training shapes appear.
In this paper, we propose an online learning method to address these
two limitations. Our method starts from constructing an initial shape
dictionary using the K-SVD algorithm. When new training shapes come,
instead of re-constructing the dictionary from the ground up, we update
the existing one using a block-coordinates descent approach. Using the
dynamically updated dictionary, sparse shape composition can be gracefully
scaled up to model shape priors from a large number of training
shapes without sacrificing run-time efficiency. Our method is validated
on lung localization in X-Ray and cardiac segmentation in MRI time
series. Compared to the original SSC, it shows comparable performance
while being significantly more efficient.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
16/10/2022 10.06.04,227,2012,Yes,It was accurately labelled,"In this work, for the first time, we propose
an automatic 3D SNE detection approach based on random forests,
with a novel formulation of SNE probability that relies on visual context
and anatomical priors. On a 3D-TCUS dataset of 11 PD patients and 11
healthy controls, we demonstrate that our SNE detection approach yields
promising results with a sensitivity and specificity of around 83%.","In this work, for the first time, we propose
an automatic 3D SNE detection approach based on random forests,
with a novel formulation of SNE probability that relies on visual context
and anatomical priors. On a 3D-TCUS dataset of 11 PD patients and 11
healthy controls, we demonstrate that our SNE detection approach yields
promising results with a sensitivity and specificity of around 83%.","Parkinson’s disease (PD) is a neurodegenerative movement
disorder caused by decay of dopaminergic cells in the substantia nigra
(SN), which are basal ganglia residing within the midbrain area. In the
past two decades, transcranial B-mode sonography (TCUS) has emerged
as a viable tool in differential diagnosis of PD and recently has been shown
to have promising potential as a screening technique for early detection of
PD, even before onset of motor symptoms. In TCUS imaging, the degeneration
of SN cells becomes visible as bright and hyper-echogenic speckle
patches (SNE) in the midbrain. Recent research proposes the usage of 3D
ultrasound imaging in order to make the application of the TCUS technique
easier and more objective.",random forest,"Specificity, F1 score, Sensitivity",Yes,"We further assume that we are given a segmentation of the midbrain
M ⊂ Ω, either from a manual expert segmentation or alternatively from the
output of a ROI detection algorithm",No,"In this section, we evaluate our SNE detection approach on the bi-lateral 3DTCUS
dataset volume of 22 subjects, consisting of 11 PD patients and 11
healthy controls.","In this section, we evaluate our SNE detection approach on the bi-lateral 3DTCUS
dataset volume of 22 subjects, consisting of 11 PD patients and 11
healthy controls.",Private,"In this section, we evaluate our SNE detection approach on the bi-lateral 3DTCUS
dataset volume of 22 subjects, consisting of 11 PD patients and 11
healthy controls.",No,"In this section, we evaluate our SNE detection approach on the bi-lateral 3DTCUS
dataset volume of 22 subjects, consisting of 11 PD patients and 11
healthy controls.",No,"In this section, we evaluate our SNE detection approach on the bi-lateral 3DTCUS
dataset volume of 22 subjects, consisting of 11 PD patients and 11
healthy controls.",No,"In this section, we evaluate our SNE detection approach on the bi-lateral 3DTCUS
dataset volume of 22 subjects, consisting of 11 PD patients and 11
healthy controls.",No,"1 Institute of Biomathematics and Biometry, Helmholtz Zentrum M¨unchen, Germany
2 Computer Aided Medical Procedures, Technische Universit¨at M¨unchen, Germany
3 Department of Neurology, Ludwig-Maximilians-University of Munich, Germany

",No,Nothing is mentioned,No,Nothing is mentioned,No,Nothing is mentioned,No,Nothing is mentioned,
16/10/2022 10.06.50,228,2012,No,Segmentation,"Accurate segmentation of prostate in CT images is important
in image-guided radiotherapy. However, it is difficult to localize the
prostate in CT images due to low image contrast, unpredicted motion
and large appearance variations across different treatment days. To address
these issues, we propose a sparse representation based classification
method to accurately segment the prostate.

So it does use classification, but main goal is segmentation",,,,,,,,,,,,,,,,,,,,,,,,,,,,
16/10/2022 11.09.08,230,2012,Yes,It was accurately labelled,"A classifier capable of handling subjects
with unequal numbers of modalities prevents discarding any subjects, as
is traditionally done, thereby broadening the scope of the classifier to
more severe pathology.","The paper presents a method for learning multimodal classifiers
from datasets in which not all subjects have data from all modalities.","Pattern classification techniques are generating increasing interest in the neuroimaging
community as they are powerful in learning the patterns of pathology from a population, assign a probabilistic score to each subject which characterizes
pathology on an individual basis and aid in assessing treatment in conjunction
with other clinical scores",ensemble based classification framework,"AUC, Accuracy",No,Nothing is mentioned,No,"Our dataset consisted of 138 subjects (42 TD
and 96 ASD), out of which 55 subjects had complete data while others had some
feature missing (60.1% subjects with partial data). 30% of subjects were missing
MMF, 15.7% were missing M100 and 38% were missing DTI. We randomly
picked 112 subjects (51 complete and 61 subjects with partial data, making
54.4% missing data) for training and the other 26 (4 complete and 22 partial
data) as test data.","Our dataset consisted of 138 subjects (42 TD
and 96 ASD), out of which 55 subjects had complete data while others had some
feature missing (60.1% subjects with partial data). 30% of subjects were missing
MMF, 15.7% were missing M100 and 38% were missing DTI. We randomly
picked 112 subjects (51 complete and 61 subjects with partial data, making
54.4% missing data) for training and the other 26 (4 complete and 22 partial
data) as test data.",Private,"Our dataset consisted of 138 subjects (42 TD
and 96 ASD), out of which 55 subjects had complete data while others had some
feature missing (60.1% subjects with partial data). 30% of subjects were missing
MMF, 15.7% were missing M100 and 38% were missing DTI. We randomly
picked 112 subjects (51 complete and 61 subjects with partial data, making
54.4% missing data) for training and the other 26 (4 complete and 22 partial
data) as test data.",Yes,"Dataset and Preprocessing. Our dataset consisted of 138 subjects (42 TD
and 96 ASD), out of which 55 subjects had complete data while others had some
feature missing (60.1% subjects with partial data). 30% of subjects were missing
MMF, 15.7% were missing M100 and 38% were missing DTI. We randomly
picked 112 subjects (51 complete and 61 subjects with partial data, making
54.4% missing data) for training and the other 26 (4 complete and 22 partial
data) as test data.
The MEG recordings were performed using a CTF 275-channel biomagnetometer
with the following protocol: (i) binaural auditory presentation of brief
sinusoidal tone stimuli at 45dB SL.M100 latency was determined from the source
modeled peak of the stimulus-locked average of 100 trials of each token (ii) binaural
auditory presentation of interleaved standard and deviant tone and vowel
tokens (/a/, /u/). Mismatch field (MMF) latency was determined from the subtraction
of superior temporal gyrus (STG) source-modeled responses for each
token as deviant vs. standard. The DTI data were acquired on Siemens 3T VerioTM scanner using the Stejkal Tanner diffusion weighted imaging sequence
(2mm isotropic resolution) with b=1000 mm/s2 and 30 gradient directions.",No,Nothing is mentioned,Yes,For the article,Yes,"1 Section of Biomedical Image Analysis, University of Pennsylvania,
Philadelphia, PA, USA
{Madhura.Ingalhalikar,Ragini.Verma}@uphs.upenn.edu
2 Lurie Family Foundations MEG Imaging Center, Department of Radiology,
Children’s Hospital of Philadelphia, Philadelphia, PA, USA

The authors would like to acknowledge support from the NIH grants: MH092862,
MH079938 and DC008871.",No,Nothing is mentioned,No,Nothing is mentioned,No,Nothing is mentioned,No,Nothing is mentioned,
17/10/2022 08.29.42,231,2012,No,Other medical imaging task,"Abstract. Diffusion imaging, through the study of water diffusion, allows
for the characterization of brain white matter, both at the population
and individual level. In recent years, it has been employed to detect
brain abnormalities in patients suffering from a disease, e.g. from multiple
sclerosis (MS). State-of-the-art methods usually utilize a database
of matched (age, sex, ...) controls, registered onto a template, to test for
differences in the patient white matter. Such approaches however suffer
from two main drawbacks. First, registration algorithms are prone
to local errors, thereby degrading the comparison results. Second, the
database needs to be large enough to obtain reliable results. However,
in medical imaging, such large databases are hardly available. In this
paper, we propose a new method that addresses these two issues. It relies
on the search for samples in a local neighborhood of each pixel to
increase the size of the database. Then, we propose a new test based
on these samples to perform a voxelwise comparison of a patient image
with respect to a population of controls. We demonstrate on simulated
and real MS patient data how such a framework allows for an improved
detection power and a better robustness and reproducibility, even with
a small database.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
17/10/2022 08.36.09,234,2012,Yes,It was accurately labelled,"In clinical practice, physicians often exploit previously observed
patterns in coronary angiograms from similar patients to quickly
assess the state of the disease in a current patient. These assessments
involve visually observed features such as the distance of a junction from
the root and the tortuosity of the arteries. In this paper, we show how
these visual features can be automatically extracted from coronary artery
images and used for finding similar coronary angiograms from a database.
Testing on a large collection has shown the method finds clinically similar
coronary angiograms from patients with similar clinical history.","we show how
these visual features can be automatically extracted from coronary artery
images and used for finding similar coronary angiograms from a database.","X-ray Coronary angiography is a commonly used technique to assess the state
of coronary artery disease (CAD). During assessment, clinicians look for characteristic
visual features, taking into account the overall disease burden, the
complexity of individual lesions, and placing more weight on proximal stenoses
of the coronary arteries. Even though there are quantitative assessment scores
such as the Syntax Score[12], they require manual input of angiographic information.
Thus the clinicians still characterize the disease by ’eyeballing’ on salient
visual features such as lumen variation or the relative thickness of arteries (see
Fig. 1a-c)[5], the distance of the junctions from the root, the number of trifurcations,
etc.","Supervised learning, Relevant Component Analysis","Accuracy, Precision",Yes,Extracting Coronary Artery Segments,No,"From a collection of 1600 runs of X-ray angiography videos from 70 patients,
we applied a keyframe detection method [13] to retain the top 10 key frames
from each run, generating a ground truth test set of 600 images drawn across
multiple patients, viewpoints and coronary arteries.","From a collection of 1600 runs of X-ray angiography videos from 70 patients,
we applied a keyframe detection method [13] to retain the top 10 key frames
from each run, generating a ground truth test set of 600 images drawn across
multiple patients, viewpoints and coronary arteries.",Private,"From a collection of 1600 runs of X-ray angiography videos from 70 patients,
we applied a keyframe detection method [13] to retain the top 10 key frames
from each run, generating a ground truth test set of 600 images drawn across
multiple patients, viewpoints and coronary arteries.",No,Nothing is mentioned,No,Nothing is mentioned,No,Nothing is mentioned,No,"1 IBM Almaden Research Center, San Jose, CA, USA
2 Kaiser San Francisco Medical Center, San Francisco, CA, USA",No,Nothing is mentioned,No,Nothing is mentioned,No,Nothing is mentioned,No,Nothing is mentioned,
17/10/2022 08.40.16,235,2012,Yes,It was accurately labelled,"Twenty-eight features are computed for each fracture
line and sent to a committee of support vector machines for classification.","We propose a
fully automated method to detect acute vertebral body fractures on trauma CT
studies.","Assessment of trauma patients with multiple injuries, particularly in the setting of
multiple trauma patients presenting to the hospital concurrently, can be one of the
most clinically challenging situations dealt with by the radiologist. Traumatic injury
of the spine is a subset of the spectrum of blunt trauma pathology, and is common and
potentially devastating. Previous reports estimate the number of vertebral fractures
each year in the United States at more than 140,000, with 19%-50% of fractures of the
thoracolumbar spine associated with neurological injury [1]. Rapid and accurate
assessment is essential for determination of an acceptable management algorithm, and
delay in detection and management of",SVM,Sensitivity,Yes,"The cortical shell of vertebral
body is then segmented using deformable dual-surface models",No,"Our cohort includes 18 trauma patients admitted to UC Irvine Medical Center between
June 2009 and July 2010. The mean patient age was 51±11 yrs (18-86yrs). There were
13 men and 5 women. All patients were scanned on a Siemens Sensation 64 scanner.
The scanning parameters were: 2mm slice thickness, 120 kvp, no intravenous contrast
administration, and convolution kernel B40f (16 patients) or B60f (2 patients). The CT
data covered the thoracic and lumbar spines, and included 14 vertebrae on average. An
expert radiologist examined the cases and manually marked the fracture sites. Ten
patients were positive for vertebral body fractures. The total number of spatially distinct
fracture sites was 21, among the 10 patients. The remaining 8 patients had no evidence
of vertebral body fracture. The average running time is 5.6 minutes.","Our cohort includes 18 trauma patients admitted to UC Irvine Medical Center between
June 2009 and July 2010. The mean patient age was 51±11 yrs (18-86yrs). There were
13 men and 5 women. All patients were scanned on a Siemens Sensation 64 scanner.
The scanning parameters were: 2mm slice thickness, 120 kvp, no intravenous contrast
administration, and convolution kernel B40f (16 patients) or B60f (2 patients). The CT
data covered the thoracic and lumbar spines, and included 14 vertebrae on average. An
expert radiologist examined the cases and manually marked the fracture sites. Ten
patients were positive for vertebral body fractures. The total number of spatially distinct
fracture sites was 21, among the 10 patients. The remaining 8 patients had no evidence
of vertebral body fracture. The average running time is 5.6 minutes.",Private,"Our cohort includes 18 trauma patients admitted to UC Irvine Medical Center between
June 2009 and July 2010. The mean patient age was 51±11 yrs (18-86yrs). There were
13 men and 5 women. All patients were scanned on a Siemens Sensation 64 scanner.
The scanning parameters were: 2mm slice thickness, 120 kvp, no intravenous contrast
administration, and convolution kernel B40f (16 patients) or B60f (2 patients). The CT
data covered the thoracic and lumbar spines, and included 14 vertebrae on average. An
expert radiologist examined the cases and manually marked the fracture sites. Ten
patients were positive for vertebral body fractures. The total number of spatially distinct
fracture sites was 21, among the 10 patients. The remaining 8 patients had no evidence
of vertebral body fracture. The average running time is 5.6 minutes.",Yes,"Our cohort includes 18 trauma patients admitted to UC Irvine Medical Center between
June 2009 and July 2010. The mean patient age was 51±11 yrs (18-86yrs). There were
13 men and 5 women. All patients were scanned on a Siemens Sensation 64 scanner.
The scanning parameters were: 2mm slice thickness, 120 kvp, no intravenous contrast
administration, and convolution kernel B40f (16 patients) or B60f (2 patients). The CT
data covered the thoracic and lumbar spines, and included 14 vertebrae on average. An
expert radiologist examined the cases and manually marked the fracture sites. Ten
patients were positive for vertebral body fractures. The total number of spatially distinct
fracture sites was 21, among the 10 patients. The remaining 8 patients had no evidence
of vertebral body fracture. The average running time is 5.6 minutes.",Yes,"Sex and age(mean and range are reported): 

Our cohort includes 18 trauma patients admitted to UC Irvine Medical Center between
June 2009 and July 2010. The mean patient age was 51±11 yrs (18-86yrs). There were
13 men and 5 women. All patients were scanned on a Siemens Sensation 64 scanner.
The scanning parameters were: 2mm slice thickness, 120 kvp, no intravenous contrast
administration, and convolution kernel B40f (16 patients) or B60f (2 patients). The CT
data covered the thoracic and lumbar spines, and included 14 vertebrae on average. An
expert radiologist examined the cases and manually marked the fracture sites. Ten
patients were positive for vertebral body fractures. The total number of spatially distinct
fracture sites was 21, among the 10 patients. The remaining 8 patients had no evidence
of vertebral body fracture. The average running time is 5.6 minutes.",No,Nothing is mentioned,No,"1 Radiology and Imaging Sciences Department, Clinical Center, The National Institutes
of Health, Bethesda, MD 20892
2 Department of Radiological Sciences, University of California, Irvine School of Medicine",No,Nothing is mentioned,No,Nothing is mentioned,No,Nothing is mentioned,No,Nothing is mentioned,
17/10/2022 08.45.32,236,2012,,It was accurately labelled,"The proposed approach is compared with state–of–the–art
texture attributes and shows significant improvement in classification
performance with an average area under receiver operating characteristic
curves of 0.94 for five lung tissue classes.","Abstract. Texture–based computerized analysis of high–resolution
computed tomography images from patients with interstitial lung diseases
is introduced to assist radiologists in image interpretation. The
cornerstone of our approach is to learn lung texture signatures using
a linear combination of N–th order Riesz templates at multiple scales.
The weights of the linear combination are derived from one–versus–all
support vector machines. Steerability and multiscale properties of Riesz
wavelets allow for scale and rotation covariance of the texture descriptors
with infinitesimal precision. Orientations are normalized among texture
instances by locally aligning the Riesz templates, which is carried out
analytically. The proposed approach is compared with state–of–the–art
texture attributes and shows significant improvement in classification
performance with an average area under receiver operating characteristic
curves of 0.94 for five lung tissue classes. The derived lung texture
signatures illustrate optimal class–wise discriminative properties.","Abstract. Texture–based computerized analysis of high–resolution
computed tomography images from patients with interstitial lung diseases
is introduced to assist radiologists in image interpretation. ",SVM,"AUC, confusion matrix",No,Nothing is mentioned,No,"A publicly available dataset of 85 ILD cases with annotated HRCT images is used
to evaluate our approach [12]. Expert annotations were carried out in collaboration
by two radiologists with 15 and 20 years of experience in CT imaging. The
slice thickness is 1mm and the inter–slice distance is 10mm. The images were acquired
with two imaging devices at the Radiology Service of the University Hospitals
of Geneva: a Philips Mx8000 IDT 16 CT Scanner and a General Electric
HiSpeed CT. The five lung tissue classes encountered in most ILDs were chosen
as lung texture classes: healthy (H), emphysema (E), ground glass (G), fibrosis
(F) and micronodules (M). In each annotated slice, 2D hand–drawn regions of
interests (ROIs) are divided into 32×32 square blocks. The visual appearance of
the lung texture classes and their distribution are detailed in Fig. 4.","A publicly available dataset of 85 ILD cases with annotated HRCT images is used
to evaluate our approach [12]. Expert annotations were carried out in collaboration
by two radiologists with 15 and 20 years of experience in CT imaging. The
slice thickness is 1mm and the inter–slice distance is 10mm. The images were acquired
with two imaging devices at the Radiology Service of the University Hospitals
of Geneva: a Philips Mx8000 IDT 16 CT Scanner and a General Electric
HiSpeed CT. The five lung tissue classes encountered in most ILDs were chosen
as lung texture classes: healthy (H), emphysema (E), ground glass (G), fibrosis
(F) and micronodules (M). In each annotated slice, 2D hand–drawn regions of
interests (ROIs) are divided into 32×32 square blocks. The visual appearance of
the lung texture classes and their distribution are detailed in Fig. 4.",Public,"A publicly available dataset of 85 ILD cases with annotated HRCT images is used
to evaluate our approach [12]. Expert annotations were carried out in collaboration
by two radiologists with 15 and 20 years of experience in CT imaging. The
slice thickness is 1mm and the inter–slice distance is 10mm. The images were acquired
with two imaging devices at the Radiology Service of the University Hospitals
of Geneva: a Philips Mx8000 IDT 16 CT Scanner and a General Electric
HiSpeed CT. The five lung tissue classes encountered in most ILDs were chosen
as lung texture classes: healthy (H), emphysema (E), ground glass (G), fibrosis
(F) and micronodules (M). In each annotated slice, 2D hand–drawn regions of
interests (ROIs) are divided into 32×32 square blocks. The visual appearance of
the lung texture classes and their distribution are detailed in Fig. 4.",Yes,"A publicly available dataset of 85 ILD cases with annotated HRCT images is used
to evaluate our approach [12]. Expert annotations were carried out in collaboration
by two radiologists with 15 and 20 years of experience in CT imaging. The
slice thickness is 1mm and the inter–slice distance is 10mm. The images were acquired
with two imaging devices at the Radiology Service of the University Hospitals
of Geneva: a Philips Mx8000 IDT 16 CT Scanner and a General Electric
HiSpeed CT. The five lung tissue classes encountered in most ILDs were chosen
as lung texture classes: healthy (H), emphysema (E), ground glass (G), fibrosis
(F) and micronodules (M). In each annotated slice, 2D hand–drawn regions of
interests (ROIs) are divided into 32×32 square blocks. The visual appearance of
the lung texture classes and their distribution are detailed in Fig. 4.",No,"A publicly available dataset of 85 ILD cases with annotated HRCT images is used
to evaluate our approach [12]. Expert annotations were carried out in collaboration
by two radiologists with 15 and 20 years of experience in CT imaging. The
slice thickness is 1mm and the inter–slice distance is 10mm. The images were acquired
with two imaging devices at the Radiology Service of the University Hospitals
of Geneva: a Philips Mx8000 IDT 16 CT Scanner and a General Electric
HiSpeed CT. The five lung tissue classes encountered in most ILDs were chosen
as lung texture classes: healthy (H), emphysema (E), ground glass (G), fibrosis
(F) and micronodules (M). In each annotated slice, 2D hand–drawn regions of
interests (ROIs) are divided into 32×32 square blocks. The visual appearance of
the lung texture classes and their distribution are detailed in Fig. 4.",No,Nothing is mentioned,Yes,"1 University of Applied Sciences Western Switzerland (HES–SO)
2 University and University Hospitals of Geneva (HUG), Switzerland
3 Ecole Polytechnique F´ed´erale de Lausanne (EPFL), Switzerland

This work was supported by the Swiss National Science
Foundation (grants 205321–130046 and PP00P2–123438), the CIBM, and the
EU in the context of Khresmoi (257528).",No,Nothing is mentioned,No,Nothing is mentioned,No,Nothing is mentioned,No,Nothing is mentioned,
17/10/2022 08.46.32,237,2012,No,Other medical imaging task,"Abstract. In this paper we present a hybrid 0D-3D modeling method to
investigate the hepatic flow in a virtual right lobe hepatectomy (RLH),
the surgical procedure for adult-to-adult living donor liver transplanation
(LDLT). The 3D method is employed to simulate complex 3D flow in
the portal vein, and the 0D model is used to study the systemic hepatic
circulation. In particular, we quantify the flow velocity and wall shear
stress (WSS) in the left portal vein which increase dramatically post-
RLH, and also simulate the essential hepatic distribution features in a
healthy adult pre- and post-procedure. We further predict the arterial
flow in the remnant left liver, which would decrease due to a hepatic
arterial buffer response (HABR) effect. Finally we discuss the physiological
significance of these phenomena, and the potential of this hybrid
modeling approach.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
17/10/2022 08.55.02,240,2012,Yes,It was accurately labelled,"In this study, we propose a computational diagnosis system
for detecting the colorectal cancer from histopathological slices.The computational
analysis was usually performed on patch level where only
a small part of the slice is covered. However, slice-based classification
is more realistic for histopathological diagnosis.","In this study, we propose a computational diagnosis system
for detecting the colorectal cancer from histopathological slices.The computational
analysis was usually performed on patch level where only
a small part of the slice is covered. However, slice-based classification
is more realistic for histopathological diagnosis.","Colorectal cancer is the third most common cancer in both men and women
world-wide and is the third leading cause of cancer-related deaths in the Western
world [1]. For 2012, 103,000 colon cancer cases and 51,000 colon cancer
related deaths are predicted for the United States. Like for many other types
of cancer, histopathological analysis is accepted as the gold standard for malignancy
diagnosis [2]. The analysis of these data, however, is performed visually
and the detection and grading of the suspect tissue may show variability depending
on the experience and awareness of the experts. Therefore, various studies
have been performed into the development of computer-aided diagnosis systems
(CAD) to improve the ability of pathologists at discriminating between malignant
and benign tissue.",logistic classifier,"AUC, Accuracy",Yes,"The nuclei in patches could be better segmented
using more advanced techniques.",No,"A total of 120 H&E stained colon biopsy slices from 96 different patients were collected
and scanned by high resolution camera at AtriumMedical Center, Heerlen.
The original slices (sized about 70,000x120,000) consist of equal sized patches of
1024x1024 pixels. Each slice may include different numbers of patches that display
actual tissue (between 200 and 6000) depending on the size of the original
biopsy etc. Slices were labeled at two different levels: either at slice-level or at
patch-level. 55 of the slices are used for patch-based labeling where each individual
patch was assigned to one of the four primary (normal, cancer, adenomatous,
inflamed) and two secondary classes (unknown, inappropriate) by a pathologist
(see Fig.2). The unknown class is for the patches which the pathologist is not sure
and inappropriate is for the patches which are not appropriate for analysis due to
the imaging problems such as camera focus.We consider the primary classes only,
which include 6134, 2503, 2261 and 2967 patches, respectively.","A total of 120 H&E stained colon biopsy slices from 96 different patients were collected
and scanned by high resolution camera at AtriumMedical Center, Heerlen.
The original slices (sized about 70,000x120,000) consist of equal sized patches of
1024x1024 pixels. Each slice may include different numbers of patches that display
actual tissue (between 200 and 6000) depending on the size of the original
biopsy etc. Slices were labeled at two different levels: either at slice-level or at
patch-level. 55 of the slices are used for patch-based labeling where each individual
patch was assigned to one of the four primary (normal, cancer, adenomatous,
inflamed) and two secondary classes (unknown, inappropriate) by a pathologist
(see Fig.2). The unknown class is for the patches which the pathologist is not sure
and inappropriate is for the patches which are not appropriate for analysis due to
the imaging problems such as camera focus.We consider the primary classes only,
which include 6134, 2503, 2261 and 2967 patches, respectively.",Private,"A total of 120 H&E stained colon biopsy slices from 96 different patients were collected
and scanned by high resolution camera at AtriumMedical Center, Heerlen.
The original slices (sized about 70,000x120,000) consist of equal sized patches of
1024x1024 pixels. Each slice may include different numbers of patches that display
actual tissue (between 200 and 6000) depending on the size of the original
biopsy etc. Slices were labeled at two different levels: either at slice-level or at
patch-level. 55 of the slices are used for patch-based labeling where each individual
patch was assigned to one of the four primary (normal, cancer, adenomatous,
inflamed) and two secondary classes (unknown, inappropriate) by a pathologist
(see Fig.2). The unknown class is for the patches which the pathologist is not sure
and inappropriate is for the patches which are not appropriate for analysis due to
the imaging problems such as camera focus.We consider the primary classes only,
which include 6134, 2503, 2261 and 2967 patches, respectively.",No,"A total of 120 H&E stained colon biopsy slices from 96 different patients were collected
and scanned by high resolution camera at AtriumMedical Center, Heerlen.
The original slices (sized about 70,000x120,000) consist of equal sized patches of
1024x1024 pixels. Each slice may include different numbers of patches that display
actual tissue (between 200 and 6000) depending on the size of the original
biopsy etc. Slices were labeled at two different levels: either at slice-level or at
patch-level. 55 of the slices are used for patch-based labeling where each individual
patch was assigned to one of the four primary (normal, cancer, adenomatous,
inflamed) and two secondary classes (unknown, inappropriate) by a pathologist
(see Fig.2). The unknown class is for the patches which the pathologist is not sure
and inappropriate is for the patches which are not appropriate for analysis due to
the imaging problems such as camera focus.We consider the primary classes only,
which include 6134, 2503, 2261 and 2967 patches, respectively.",No,Nothing is mentioned,No,Nothing is mentioned,Yes,"1 Pattern Recognition Laboratory, Delft University of Technology, The Netherlands
2 Atrium Medical Center, Heerlen, The Netherlands
3 Department of Computer Engineering, Suleyman Demirel University, Turkey

Habil Kalkan is supported by TUBITAK-BIDEB 2219 program.",No,Nothing is mentioned,No,Nothing is mentioned,No,Nothing is mentioned,No,Nothing is mentioned,
17/10/2022 09.01.28,241,2012,No,Other medical imaging task,"Abstract. Dynamic PET imaging provides important spatial-temporal
information for metabolism analysis of organs and tissues, and generates
a great reference for clinical diagnosis and pharmacokinetic analysis.
Due to poor statistical properties of the measurement data in low
count dynamic PET acquisition and disturbances from surrounding tissues,
identifying small lesions inside the human body is still a challenging
issue. The uncertainties in estimating the arterial input function will also
limit the accuracy and reliability of the metabolism analysis of lesions.
Furthermore, the sizes of the patients and the motions during PET acquisition
will yield mismatch against general purpose reconstruction system
matrix, this will also affect the quantitative accuracy of metabolism
analyses of lesions. In this paper, we present a dynamic PET metabolism
analysis framework by defining a patient adaptive system matrix to improve
the lesion metabolism analysis. Both patient size information and
potential small lesions are incorporated by simulations of phantoms of
different sizes and individual point source responses. The new framework
improves the quantitative accuracy of lesion metabolism analysis,
and makes the lesion identification more precisely. The requirement of
accurate input functions is also reduced. Experiments are conducted on
Monte Carlo simulated data set for quantitative analysis and validation,
and on real patient scans for assessment of clinical potential.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
17/10/2022 09.10.32,242,2012,Yes,It was accurately labelled,"Distortion correction is applied to endoscopic duodenal imagery to
improve automated classification of celiac disease affected mucosa patches.","Distortion correction is applied to endoscopic duodenal imagery to
improve automated classification of celiac disease affected mucosa patches.","Computer-aided decision support systems relying on automated analysis of endoscopic
imagery receive increasing attention [1].
A specific type of degradation, present in all endoscopic images, is a barrel-type
distortion. This type of degradation is caused by the wide-angle (fish eye) nature of the
optics used in endoscopes.
The aim of correcting this distortion in endoscopy is manifold","SVM, Discriminant analysis, knn","Specificity, Accuracy, Sensitivity",No,Nothing is mentioned,No,"The image test set used in this work (see [7] for example images) stems from three
pediatric gastroscopes without magnification, types GIF-Q165 and GIF-N180, Olympus,
with two of the first type and one of the latter type, respectively. The patients
presented in the pediatric Department because of celiac-like symptoms.","From the acquired images, an experienced endoscopist extracted 128 × 128 pixels
patches significant for diagnosis. The images and patients were pre-classified by the diagnostic
outcome of the biopsy of the significant region at the hospital into the modified
Marsh classification as shown in Table 1.",Private,"The image test set used in this work (see [7] for example images) stems from three
pediatric gastroscopes without magnification, types GIF-Q165 and GIF-N180, Olympus,
with two of the first type and one of the latter type, respectively. The patients
presented in the pediatric Department because of celiac-like symptoms.",No,"The image test set used in this work (see [7] for example images) stems from three
pediatric gastroscopes without magnification, types GIF-Q165 and GIF-N180, Olympus,
with two of the first type and one of the latter type, respectively. The patients
presented in the pediatric Department because of celiac-like symptoms.",No,Nothing is mentioned,No,Nothing is mentioned,Yes,"1 Department of Computer Sciences
University of Salzburg, Austria
2 St.Anna Children’s Hospital, Dept. Pediatrics
Medical University, Vienna

This work has been partially supported by the Austrian Science Fund project no. 24366.",No,"They only mention that patients were there because they showed symptoms..:
The patients
presented in the pediatric Department because of celiac-like symptoms.",No,Nothing is mentioned,No,Nothing is mentioned,Yes,There are several links to implementations used during the preprocessing stage,
17/10/2022 09.02.58,242,2012,No,Other medical imaging task,"Abstract. Time-resolved imaging of the thorax or abdominal area is
affected by respiratory motion. Nowadays, one-dimensional respiratory
surrogates are used to estimate the current state of the lung during its
cycle, but with rather poor results. This paper presents a framework to
predict the 3D lung motion based on a patient-specific finite element
model of respiratory mechanics estimated from two CT images at end
of inspiration (EI) and end of expiration (EE). We first segment the
lung, thorax and sub-diaphragm organs automatically using a machinelearning
algorithm. Then, a biomechanical model of the lung, thorax and
sub-diaphragm is employed to compute the 3D respiratory motion. Our
model is driven by thoracic pressures, estimated automatically from the
EE and EI images using a trust-region approach. Finally, lung motion
is predicted by modulating the thoracic pressures. The effectiveness of
our approach is evaluated by predicting lung deformation during exhale
on five DIR-Lab datasets. Several personalization strategies are tested,
showing that an average error of 3.88 ± 1.54mm in predicted landmark
positions can be achieved. Since our approach is generative, it may constitute
a 3D surrogate information for more accurate medical image reconstruction
and patient respiratory analysis.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
17/10/2022 09.11.26,247,2012,No,Other medical imaging task,"Abstract. Analyzing geometry of sulcal curves on the human cortical
surface requires a shape representation invariant to Euclidean motion.
We present a novel shape representation that characterizes the shape of
a curve in terms of a coordinate system based on the eigensystem of the
anisotropic Helmholtz equation. This representation has many desirable
properties: stability, uniqueness and invariance to scaling and isometric
transformation. Under this representation, we can find a point-wise shape
distance between curves as well as a bijective smooth point-to-point correspondence.
When the curves are sampled irregularly, we also present
a fast and accurate computational method for solving the eigensystem
using a finite element formulation. This shape representation is used
to find symmetries between corresponding sulcal shapes between cortical
hemispheres. For this purpose, we automatically generate 26 sulcal
curves for 24 subject brains and then compute their invariant shape representation.
Left-right sulcal shape symmetry as measured by the shape
representation’s metric demonstrates the utility of the presented invariant
representation for shape analysis of the cortical folding pattern.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
17/10/2022 09.17.50,248,2012,Yes,It was accurately labelled,"In addition to segmentation,
since the feature vectors capture the information on the phase retardation
caused by cells, they can be used for cell stage classification between
intermitotic and mitotic/apoptotic stages. Experiments on three image
sequences demonstrate that the dictionary-based restoration method can
restore phase contrast images containing cells with different optical natures
and provide promising results on cell stage classification.","the
authors analyze the image formation process of phase contrast images
and propose an image restoration method based on the dictionary representation
of diffraction patterns.","Computer-aided image analysis of phase contrast microscopy [1] has attracted
increasing attention since it enables long-term monitoring of the proliferation
and migration processes of live cells.",K-means clustering,"Precision, Recall",Yes,The sample results of cell segmentation.,,"The proposed approach was tested on three different sets of phase contrast
images of 1040× 1392 pixels. The specifications of the datasets are summarized
in Table 1.","The proposed approach was tested on three different sets of phase contrast
images of 1040× 1392 pixels. The specifications of the datasets are summarized
in Table 1.",Private,"The proposed approach was tested on three different sets of phase contrast
images of 1040× 1392 pixels. The specifications of the datasets are summarized
in Table 1.",No,Nothing is mentioned,No,"Nothing is mentioned - also not relevant, cells?",No,Nothing is mentioned,Yes,"Department of EE, Shanghai Jiaotong University
2 Department of CS, Missouri University of Science and Technology
3 The Robotics Institute, Carnegie Mellon University

This research is supported by funds from Cell Image Analysis Consortium of Carnegie
Mellon University and University of Missouri Research Board.",No,"Nothing is mentioned, not relevant, cells?",No,Nothing is mentioned,No,"Nothing is mentioned, not relevant, cells?",Yes,The article includes pseudocode,
26/09/2022 10.25.31,8,2021,No,Segmentation,Consistent Segmentation of Longitudinal Brain MR Images with Spatio-Temporal Constrained Networks,,,,,,,,,,,,,,,,,,,,,,,,,,,,
26/09/2022 10.27.16,17,2021,No,Segmentation,Improved Brain Lesion Segmentation with Anatomical Priors from Healthy Subjects,,,,,,,,,,,,,,,,,,,,,,,,,,,,
26/09/2022 10.28.27,18,2021,No,Segmentation,CarveMix: A Simple Data Augmentation Method for Brain Lesion Segmentation,,,,,,,,,,,,,,,,,,,,,,,,,,,,
26/09/2022 10.30.02,25,2021,No,,Partially-Supervised Learning for Vessel Segmentation in Ocular Images,,,,,,,,,,,,,,,,,,,,,,,,,,,,
26/09/2022 10.31.32,30,2021,No,Segmentation,Multi-compound Transformer for Accurate Biomedical Image Segmentation,,,,,,,,,,,,,,,,,,,,,,,,,,,,
27/09/2022 11.14.02,255,2021,Yes,It was accurately labelled,"In the early diagnosis of lung cancer, an important step is classifying malignancy/benignity for each lung nodule.","Recently, the contextual features attract increasing attention, due to the complementary information they provide. Clinically, such contextual features refer to the features of nodule’s surrounding structures, such that (together with nodule’s features) they can expose discriminate patterns for the malignant/benign, such as vascular convergence and fissural attachment. To leverage such contextual features, we propose a Context Attention Network (CA-Net) which extracts both nodule’s and contextual features and then effectively fuses them during malignancy/benignity classification. To accurately identify the contextual features that contain structures distorted/attached by the nodule, we take the nodule’s features as a reference via an attention mechanism. Further, we propose a feature fusion module that can adaptively adjust the weights of nodule’s and contextual features across nodules.","Recently, the contextual features attract increasing attention, due to the complementary information they provide. Clinically, such contextual features refer to the features of nodule’s surrounding structures, such that (together with nodule’s features) they can expose discriminate patterns for the malignant/benign, such as vascular convergence and fissural attachment. To leverage such contextual features, we propose a Context Attention Network (CA-Net) which extracts both nodule’s and contextual features and then effectively fuses them during malignancy/benignity classification",Neural network,"AUC, Accuracy, Log Loss",Yes,"The whole pipeline of our method, namely Context Attention Network (CA-Net), is illustrated in Fig. 2. As shown, it is the sequential of three stages: (i) Nodule Detection that detects all nodules from the CT image;",Yes,DSB2017 dataset,"There are 1397, 198, and 506 patients in the training, validation, and test set, respectively.",Public,"Experimentally, our CA-Net outperforms the 1st place by a noticeable margin on Kaggle DSB2017 dataset.",No,Nothing is mentioned in the article,No,This is the only description in the article: This dataset provides pathologically proven lung cancer label for each patient.,No,Nothing is mentioned in the article,Yes,"(1)
Department of Computer Science and Technology, Peking University, Beijing, China
(2)
Peking University, Beijing, China
(3)
Deepwise AI Lab, Beijing, China
(4)
University of Hong Kong, Pokfulam, Hong Kong   This work was supported by MOST-2018AAA0102004, NSFC-61625201, and the Beijing Municipal Science and Technology Planning Project (Grant No. Z201100005620008).",No,Nothing is mentioned in the article,Yes,"Experimentally, our CA-Net outperforms the 1st place by a noticeable margin on Kaggle DSB2017 dataset.",No,Nothing is mentioned in the article,Yes,"To some degree perhaps - though who knows what is actually in this supplementary material?
Also no mention is made of the repo/code for reproducibility... 
Electronic supplementary material
The online version of this chapter (https://​doi.​org/​10.​1007/​978-3-030-87240-3_​3) contains supplementary material, which is available to authorized users.",
27/09/2022 11.21.06,257,2021,Yes,It was accurately labelled,"Learning disease-related representations plays a critical role in image-based cancer diagnosis, due to its trustworthy, interpretable and good generalization power.","Learning disease-related representations plays a critical role in image-based cancer diagnosis, due to its trustworthy, interpretable and good generalization power. A good representation should not only be disentangled from the disease-irrelevant features, but also incorporate the information of lesion’s attributes (e.g., shape, margin) that are often identified first during cancer diagnosis clinically. To learn such a representation, we propose a Disentangle Auto-Encoder with Graph Convolutional Network (DAE-GCN), which adopts a disentangling mechanism with the guidance of a GCN model in the AE-based framework. ","For better representation learning, the disentanglement mechanism has been proved to be an effective way [1, 3, 12], since such a mechanism prompts different independent latent units to encode different independent ground truth generation factors that vary in the data [1]. Based on the above, to capture the disease-related features without mixing other irrelevant information, in this paper we propose a Disentangle Auto-Encoder with Graph Convolutional Network (DAE-GCN), which incorporates a disentangling mechanism into an AE framework, equipped with attribution data during training stage (the attributes are not provided during the test). ","Graph analysis, Supervised learning, Neural network","AUC, Accuracy",No,"Our dataset contains $$\{x_i,A_i,y_i\}_{i \in \{1,...,n\}}$$, in which x, A, y respectively denote the patch-level mass image, attributes (e.g., circumscribed-margin, round-shape, irregular-shape), and the binary disease label. ",Yes," DDSM 
But also uses 3 ""in house"" datasets","We consider both the public dataset DDSM [2] and three in-house datasets: Inhouse1, Inhouse2 and Inhouse3. For each dataset, the region of interests (ROIs) (malignant/benign masses) are cropped based on the annotations of radiologists the same as [9]1. For all datasets, we randomly2 divide the whole set into training, validation and testing as 8:1:1 in patient-wise. ",Don't know,"We consider both the public dataset DDSM [2] and three in-house datasets: Inhouse1, Inhouse2 and Inhouse3.",No,"To evaluate the effectiveness of our DAE-GCN, we verify it on the patch-level mammogram mass benign/malignant classification. We consider both the public dataset DDSM [2] and three in-house datasets: Inhouse1, Inhouse2 and Inhouse3. For each dataset, the region of interests (ROIs) (malignant/benign masses) are cropped based on the annotations of radiologists the same as [9]1. For all datasets, we randomly2 divide the whole set into training, validation and testing as 8:1:1 in patient-wise.",No,Nothing is mentioend,No,Nothing is mentioned,Yes,"(1)
Center for Data Science, Peking University, Beijing, China
(2)
Peking University, Beijing, China
(3)
Department of Computer Science and Technology, Peking University, Beijing, China
(4)
Deepwise AI Lab, Beijing, China
(5)
The University of Hong Kong, Pokfulam, Hong Kong   This work was supported by MOST-2018AAA0102004, NSFC-61625201 and ZheJiang Province Key Research & Development Program (No. 2020C03073).",No,Nothing is mentioned,Yes,"From the introduction: 
For image-based disease benign/malignant diagnosis, it is crucial to learn the disease-related representation for prediction, due to the necessity of trustworthy (to patients), explainable (to clinicians) and good generalization ability in healthcare.",No,Nothing is mentioned,Yes,"To provide convenience for latter works, we publish our spitted test set of DDSM [2] in supplementary.",
27/09/2022 11.27.05,258,2021,Yes,It was accurately labelled,"Ultrasound (US) imaging is a fundamental modality for detecting and diagnosing breast lesions, while shear-wave elastography (SWE) serves as a crucial complementary counterpart. Although an automated breast lesion classification system is desired, training of such a system is constrained by data scarcity and modality imbalance problems due to the lack of SWE devices in rural hospitals. ","To enhance the diagnosis with only US available, in this work, we propose a knowledge-guided data augmentation framework, which consists of a modal translater and a semantic inverter, achieving cross-modal and semantic data augmentation simultaneously. ","Breast cancer, the most commonly diagnosed cancer, is the fifth leading cause of cancer death all over the world [24].",Neural network,"AUC, Accuracy, Precision, Recall, F1 score",No,Nothing is mentioned,No,"From September 2020 to January 2021, a total of 2,008 images of benign lesions and 1,466 images of malignant lesions from 593 patients were collected as the dataset used in this paper. ","From September 2020 to January 2021, a total of 2,008 images of benign lesions and 1,466 images of malignant lesions from 593 patients were collected as the dataset used in this paper. ",Private,"From September 2020 to January 2021, a total of 2,008 images of benign lesions and 1,466 images of malignant lesions from 593 patients were collected as the dataset used in this paper. ",Yes,"The Super Linear SL-15-4 probe of ultrafast ultrasound device Aixplorer (Super Sonic Imagine, Aix-en-Provence, France) was used for imaging data collection. The maximum stiffness scale of SWE images was selected as 180 Kilopascal (kPa). ",No,Nothing is mentioned,Yes,"From September 2020 to January 2021, a total of 2,008 images of benign lesions and 1,466 images of malignant lesions from 593 patients were collected as the dataset used in this paper. ",Yes,"This work was supported in part by Shanghai Municipal Science and Technology Major Project (2021SHZDZX0102), 111 project (BP0719010), Shanghai Science and Technology Committee (18DZ2270700) and Shanghai Jiao Tong University Science and Technology Innovation Special Fund (ZH2018ZDA17).",No,Nothing is mentioned,No,Nothing is mentioned,No,Nothing is mentioned,Yes,"Electronic supplementary material
The online version of this chapter (https://​doi.​org/​10.​1007/​978-3-030-87240-3_​6) contains supplementary material, which is available to authorized users.",
27/09/2022 11.29.27,259,2021,No,Other medical imaging task,"Transfer learning is an important step to extract meaningful features and overcome the data limitation in the medical Visual Question Answering (VQA) task. However, most of the existing medical VQA methods rely on external data for transfer learning, while the meta-data within the dataset is not fully utilized. In this paper, we present a new multiple meta-model quantifying method that effectively learns meta-annotation and leverages meaningful features to the medical VQA task. Our proposed method is designed to increase meta-data by auto-annotation, deal with noisy labels, and output meta-models which provide robust features for medical VQA tasks. Extensively experimental results on two public medical VQA datasets show that our approach achieves superior accuracy in comparison with other state-of-the-art methods, while does not require external data to train meta-models.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
27/09/2022 11.37.14,262,2021,Yes,It was accurately labelled,"In this paper, we propose a coherent cooperative learning framework based on transfer learning for unsupervised cross-domain classification.","In this paper, we propose a coherent cooperative learning framework based on transfer learning for unsupervised cross-domain classification.","In the practical application of medical image analysis, due to the different data distributions of source domain and target domain and the lack of the labels of target domain, domain adaptation for unsupervised cross-domain classification attracts widespread attention. However, current methods take knowledge transfer model and classification model as two separate training stages, which inadequately considers and utilizes the intrinsic information interaction between module","Unsupervised learning, Transfer learning, Neural network","Accuracy, Precision, Recall, F1 score",No,Nothing is mentioned,Yes,"We use three databases in the experiments, and their information is shown in Table 1. The Chest X-Ray1 is divided into training dataset and testing dataset [12]. Single lesion2 and Multiple lesions3 are the training datasets of two open lesion recognition competitions.","No quote, but there is Table 1 which includes the number of images of each used dataset",Public,"The Chest X-Ray1 is divided into training dataset and testing dataset [12]. Single lesion2 and Multiple lesions3 are the training datasets of two open lesion recognition competitions. (and I think the first one is also accessible, there is a link in the footnote)",No,Nothing is mentioned,No,Nothing is mentioned,No,Nothing is mentioned,Yes,"(1)
Shanghai Key Laboratory of Multidimensional Information Processing, School of Communication and Electronic Engineering, East China Normal University, Shanghai, China  This work was supported in part by 2030 National Key Research and Development Program of China (2018AAA0100500), the National Nature Science Foundation of China (no. 61773166), Projects of International Cooperation of Shanghai Municipal Science and Technology Committee (14DZ2260800), the Fundamental Research Funds for the Central Universities, and the ECNU Academic Innovation Promotion Program for Excellent Doctoral Students (YBNLTS2021-040).",No,Nothing is mentioned,No,Nothing is mentioned,No,Nothing is mentioned,Yes,"Electronic supplementary material
The online version of this chapter (https://​doi.​org/​10.​1007/​978-3-030-87240-3_​10) contains supplementary material, which is available to authorized users.",
29/09/2022 09.20.10,266,2021,Yes,It was accurately labelled,"Unsupervised anomaly detection (UAD) learns one-class classifiers exclusively with normal (i.e., healthy) images to detect any abnormal (i.e., unhealthy) samples that do not conform to the expected normal patterns","we propose a novel self-supervised representation learning method, called Constrained Contrastive Distribution learning for anomaly detection (CCD), which learns fine-grained feature representations by simultaneously predicting the distribution of augmented data and image contexts using contrastive learning with pretext constraints. ","UAD has two main advantages over its fully supervised counterpart. Firstly, it is able to directly leverage large datasets available from health screening programs that contain mostly normal image samples, avoiding the costly manual labelling of abnormal samples and the subsequent issues involved in training with extremely class-imbalanced data. Further, UAD approaches can potentially detect and localise any type of lesions that deviate from the normal patterns. One significant challenge faced by UAD methods is how to learn effective low-dimensional image representations to detect and localise subtle abnormalities, generally consisting of small lesions. ",Constrained Contrastive Distribution learning,AUC,No,Nothing is mentioned,Yes,"They use three different datasets: Hyper-Kvasir, LAG, and Liu et al's colonoscopy dataset",Different sizes,Public,"But mixed, some public, some private",No,None of the used datasets are described in great detail,No,Nothing is mentioned,No,Nothing is mentioned,No,"Medical Imaging, Robotics, Analytic Computing Laboratory/Engineering (MIRACLE), School of Biomedical Engineering & Suzhou Institute for Advanced Research, University of Science and Technology of China, Suzhou, China
(2)
Key Laboratory of Intelligent Information Processing of Chinese Academy of Sciences (CAS), Institute of Computing Technology, CAS, Beijing, China
(3)
School of Electronic, Electrical and Communication Engineering, University of the Chinese Academy of Science, Beijing, China
(4)
Healthcare Intelligence, AIC, DAMO Academy, Alibaba Group, Hangzhou, China  Nothing is mentioned",No,Nothing is mentioned,No,Nothing is mentioned,No,Nothing is mentioned,Yes,"Their code is freely available on github, link in abstract",
29/09/2022 08.59.47,266,2021,Yes,It was accurately labelled,"Universal Lesion Detection (ULD) in computed tomography (CT) [1–14], which aims to localize different types of lesions instead of identifying lesion types [15–26], plays an essential role in computer-aided diagnosis (CAD","In this paper we propose a BM-based conditional training for two-stage ULD, which can (i) reduce positive vs. negative anchor imbalance via a BM-based conditioning (BMC) mechanism for anchor sampling instead of traditional IoU-based rule; and (ii) adaptively compute size-adaptive BM (ABM) M. de Bruijne et al. (eds.)Medical Image Computing and Computer Assisted Intervention – MICCAI 2021Image Processing, Computer Vision, Pattern Recognition, and Graphics12905
https://doi.org/10.1007/978-3-030-87240-3_14
Conditional Training with Bounding Map for Universal Lesion Detection
Han Li1, 2  , Long Chen2, 3  , Hu Han2  , Ying Chi4   and S. Kevin Zhou1, 2  
(1)
Medical Imaging, Robotics, Analytic Computing Laboratory/Engineering (MIRACLE), School of Biomedical Engineering & Suzhou Institute for Advanced Research, University of Science and Technology of China, Suzhou, China
(2)
Key Laboratory of Intelligent Information Processing of Chinese Academy of Sciences (CAS), Institute of Computing Technology, CAS, Beijing, China
(3)
School of Electronic, Electrical and Communication Engineering, University of the Chinese Academy of Science, Beijing, China
(4)
Healthcare Intelligence, AIC, DAMO Academy, Alibaba Group, Hangzhou, China
 
 
Han Li
Email: han.li@miracle.ict.ac.cn
 
Long Chen
Email: long.chen@miracle.ict.ac.cn
 
Hu Han (Corresponding author)
Email: hanhu@ict.ac.cn
 
Ying Chi
Email: xinyi.cy@alibaba-inc.com
Abstract
Universal Lesion Detection (ULD) in computed tomography plays an essential role in computer-aided diagnosis. Promising ULD results have been reported by coarse-to-fine two-stage detection approaches, but such two-stage ULD methods still suffer from issues like imbalance of positive v.s. negative anchors during object proposal and insufficient supervision problem during localization regression and classification of the region of interest (RoI) proposals. While leveraging pseudo segmentation masks such as bounding map (BM) can reduce the above issues to some degree, it is still an open problem to effectively handle the diverse lesion shapes and sizes in ULD. In this paper we propose a BM-based conditional training for two-stage ULD, which can (i) reduce positive vs. negative anchor imbalance via a BM-based conditioning (BMC) mechanism for anchor sampling instead of traditional IoU-based rule; and (ii) adaptively compute size-adaptive BM (ABM) from lesion bounding-box, which is used for improving lesion localization accuracy via ABM-supervised segmentation.",we propose a novel training mechanism for ULD to effectively reduce positive vs. negative anchor imbalance via a BM-based conditioning (BMC) mechanism in stage-1 and improve lesion localization accuracy by leveraging a size-adaptive BM (ABM) for supervising the segmentation branch in stage-2. ,map regression,Sensitivity,Yes,"Sect. 2.2 introduces the BMC mechanism, and Sect. 2.3 explains the newly introduced ABM-supervised segmentation branch.",Yes,DeepLesion dataset,"The dataset contains 32,735 lesions on 32,120 axial slices from 10,594 CT studies of 4,427 unique patients. Most existing datasets typically focus on one type of lesion, while DeepLesion contains a variety of lesions with large diameters ranges (from 0.21 to 342.5 mm). The 12-bit intensity CT is rescaled to [0,255] with different window ranges settings used in different frameworks. Also, every CT slice is resized and interpolated according to the detection frameworks’ setting. We follow the official split, i.e., $$70\%$$ for training, $$15\%$$ for validation and $$15\%$$ for testing.",Public,Searching for it shows it can be found by anyone,Don't know,Nothing is mentioned,No,Nothing is mentioned,No,Nothing is mentioned,Yes,"(1)
Medical Imaging, Robotics, Analytic Computing Laboratory/Engineering (MIRACLE), School of Biomedical Engineering & Suzhou Institute for Advanced Research, University of Science and Technology of China, Suzhou, China
(2)
Key Laboratory of Intelligent Information Processing of Chinese Academy of Sciences (CAS), Institute of Computing Technology, CAS, Beijing, China
(3)
School of Electronic, Electrical and Communication Engineering, University of the Chinese Academy of Science, Beijing, China
(4)
Healthcare Intelligence, AIC, DAMO Academy, Alibaba Group, Hangzhou, China   This research was supported in part by the Natural Science Foundation of China (grant 61732004), Youth Innovation Promotion Association CAS (grant 2018135) and Alibaba Group through Alibaba Innovative Research Program.",No,Nothing is mentioned,No,Nothing is mentioned,No,Nothing is mentioned,Yes,"There is a doi in the electronic supplementary material, but still only available behind a paywall and am unsure how much more material is actually provided","I would say this is perhaps more classification adjacent, ULD seems to be about localizing different types of lesions, and is used for computer-aided diagnosis, but not as a stand alone part.. "
29/09/2022 09.53.59,267,2021,Yes,It was accurately labelled,"In this paper, we propose a selective attention regularization module (SAttenReg) to mimic the diagnosis process of pathologists. Specifically, to explicitly encourage the model to focus on clinically interpretable features (e.g., nuclei and fat droplets), SAttenReg learns the attention map with the regularization of clinically interpretable features. Furthermore, with the different contributions of histological features, the model can selectively focus on different histological features based on the distribution of nuclei in each instance. Experiments conducted on the in-house Liver-NAS and public Biopsy4Grading biopsy image datasets show that our method achieves superior classification performance with promising localization results.",we propose a selective attention regularization module (SAttenReg) to mimic the diagnosis process of pathologists.,"Nonalcoholic fatty liver disease (NAFLD) is the most common cause of liver disease worldwide [21, 22]. It is estimated that the prevalence of NAFLD is between 25% and 45%, which has become an important public health concern [4, 20]. ",Neural network,"Specificity, F1 score, Sensitivity",No,Nothing is mentioned,Yes,Biopsy4grading and Liver-NAS,"Biopsy4Grading [7] is a public liver section dataset collected from animals studies. Each liver tiles (299 $$\times $$ 299 pixels) were assigned to discrete pathologist-like sub-scores for quantifying NAS-related components of ballooning degeneration (0–2), lobular inflammation (0–3), steatosis (0–3) and fibrosis (0–4), corresponding to the Kleiner score system [11]. Liver-NAS is a private dataset of liver biopsy images collecting from 9 patients. Image tiles were generated from whole slide images ($$\sim 106259\times 306939$$ pixels) with an area of $$224\times 224$$ pixels, which can guarantee the pathologist to sufficiently identify the relevant histological features within the tile.",Private,"Both, one is public, one is private",No,Nothing is mentioned,No,Nothing is mentioned,No,Nothing is mentioned,Yes,"(1)
Department of Computer Science, Hong Kong Baptist University, kowloon, Hong Kong  This work was supported by the Health and Medical Research Fund Project under Grant 07180216. We acknowledge insightful discussion with Anthony W.H. CHAN. We also thank Vincent WS WONG, Grace LH WONG, and Howard H.W. LEUNG from the Chinese University of Hong Kong for help with data preparation.",No,Nothing is mentioned,No,Nothing is mentioned,No,Nothing is mentioned,No,Nothing is mentioned,
29/09/2022 10.01.00,268,2021,Yes,It was accurately labelled,Categorical Relation-Preserving Contrastive Knowledge Distillation for Medical Image Classification,"we propose a novel Categorical Relation-preserving Contrastive Knowledge Distillation (CRCKD) algorithm, which takes the commonly used mean-teacher model as the supervisor. ","The amount of medical images for training deep classification models is typically very scarce, making these deep models prone to overfit the training data. Studies showed that knowledge distillation (KD), especially the mean-teacher framework which is more robust to perturbations, can help mitigate the over-fitting effect. ","neural network, knowledge distillation","Accuracy, F1 score,  average precision, balanced accuracy,",No,Nothing is mentioned,Yes,"HAM10000 [23, 24] and APTOS datasets [25].","The HAM10000 consists of 10015 dermoscopy images labeled by 7 types of skin lesions. In APTOS, there are 3662 fundus images for grading diabetic retinopathy into five categories. ",Don't know,"Dataset: We evaluated our proposed CRCKD framework on the HAM10000 [23, 24] and APTOS datasets [25]. The HAM10000 consists of 10015 dermoscopy images labeled by 7 types of skin lesions. In APTOS, there are 3662 fundus images for grading diabetic retinopathy into five categories. These two datasets both suffer from severe class imbalance. A detailed description of these two datasets is provided in the supplementary material.",No,Nothing is mentioned,No,Nothing is mentioned,No,Nothing is mentioned,Yes,"(1)
Department of Electronic Engineering, The Chinese University of Hong Kong, Shatin, Hong Kong, China
(2)
Department of Information Engineering, The Chinese University of Hong Kong, Shatin, Hong Kong, China
(3)
School of Informatics, Xiamen University, Xiamen, China
(4)
Department of Electrical Engineering, City University of Hong Kong, Kowloon, Hong Kong, China
(5)
Department of Electronic and Electrical Engineering, Southern University of Science and Technology, Shenzhen, China  The work described in this paper was supported by National Key R&D program of China with Grant No. 2019YFB1312400, Hong Kong RGC CRF grant C4063-18G, and Hong Kong RGC GRF grant #14211420.",No,Nothing is mentioned,No,Nothing is mentioned,No,Nothing is mentioned,Yes,"Also has supplementary electronic material, but there is a mention of what the supplementary material contains in the text, more info about the datasets, so some of the above questions may have different answers if this was available",
29/09/2022 10.07.02,269,2021,Yes,It was accurately labelled,we propose a tensor-based multi-index representation learning (TMRL) framework for fMRI-based MDD detection,", we propose a tensor-based multi-index representation learning (TMRL) framework for fMRI-based MDD detection","Major depression disorder (MDD) is one of the most prevalent disabling disorder, characterized by depressed mood, loss of interest or pleasure in nearly all activities. This mental illness has a high mortality rate due to the suicidal behavior of MDD patients, while the high cost of treatment troubles patients, their family members, and society [1, 2]. Even though many efforts have been made in clinical neuroscience and psychiatric research, the unknown etiology and pathological mechanism still prevent us from fully understanding the disease.",representation learning,"Specificity, Accuracy, F1 score, Sensitivity",No,"Each fMRI scan was basically pre-processed by using the Data Processing Assistant for Resting-State fMRI (DPARSF). In this pipeline, we first discard the first 10 time points, followed by slice timing correction, head motion correction, regression of nuisance co-variants of head motion parameters, white matter, and cerebrospinal fluid. Images are then normalized with an EPI template in the MNI space, resampling to $$3 \times 3\times 3\,\text {mm}^{3}$$ resolution, and spatial smoothing using a $$6\,\text {mm}$$ full-width at half-maximum (FWHM) Gaussian kernel. ",Yes,The public rs-fMRI dataset,The public rs-fMRI dataset consists of 533 subjects1,Public,The public rs-fMRI dataset consists of 533 subjects1,No,Nothing is mentioned,Yes,"Article contains a table covering the gender, age, education year, first period, on medication and illness time of subjects included!",No,Nothing is mentioned,Yes,"(1)
Department of Radiology and BRIC, University of North Carolina at Chapel Hill, Chapel Hill, NC 27599, USA
(2)
Brainnetome Center & National Laboratory of Pattern Recognition, Institute of Automation, Chinese Academy of Sciences, Beijing, 100190, China
(3)
State Key Laboratory of Cognitive Neuroscience and Learning, Beijing Normal University, Beijing, 100678, China
(4)
School of Computer Science and Technology, East China Normal University, Shanghai, 200241, China   This work was finished when D. Yao was visiting the University of North Carolina at Chapel Hill. D. Yao and M. Liu was partly supported by NIH grant (No. AG041721). Z. Zhang was partly supported by the National Key Research and Development Program of China (No. 2016YFD0700100).",No,Nothing is mentioned,No,Nothing is mentioned,No,Nothing is mentioned,Yes,The table showing the demographics and electronic supplementary material,
03/10/2022 09.06.44,270,2021,Yes,It was accurately labelled,computer-aided mild cognitive impairment (MCI) conversion prediction,we propose a region ensemble model using a divide and conquer strategy to capture the disease’s finer representation,"Despite many recent advances, computer-aided mild cognitive impairment (MCI) conversion prediction is still a very challenging task due to: 1) the abnormal areas are subtle compared to the size of the whole brain, 2) the features’ dimension is much larger than the number of samples. ",Neural network,"AUC, Specificity, Accuracy, Sensitivity",Yes,"Since our method needs voxel-level annotation to extract brain regions, we use the dataset in [13] and the method in [19] to train a segmentation model which segments the whole brain into 134 regions.",Yes,We perform experiments on the public Alzheimer’s Disease Neuroimaging Initiative (ADNI) dataset [18],"Following [9–12], in all experiments, we treat ADNI-1 as the training set and leave ADNI-2 for testing to make an easier comparison. The training and testing set contains 226 sMCI vs. 167 pMCI and 239 sMCI vs. 38 pMCI, respectively. We also collect 199 AD and 229 NC samples in ADNI-1 as the additional samples to optimize the proposed relation regularized loss.",Public,ADNI is available ,No,Nothing is mentioned,No,Nothing is mentioned,No,Nothing is mentioned,Yes,"(1)
School of Artificial Intelligence, University of Chinese Academy of Sciences, Beijing, 100149, China
(2)
NLPR, Institute of Automation, Chinese Academy of Sciences, Beijing, 100190, China
(3)
Brainnetome Center, Institute of Automation, Chinese Academy of Sciences, Beijing, 100190, China
(4)
CAS Center for Excellence of Brain Science and Intelligence Technology, Beijing, 100190, China   This work has been supported by the National Key Research and Development Program Grant 2018AAA0100400, the National Natural Science Foundation of China (NSFC) grants 61773376, 61836014, 61721004 and 31870984.",No,Nothing is mentioned,No,Nothing is mentioned,No,Nothing is mentioned,No,Nothing is mentioned,
03/10/2022 09.13.12,271,2021,Yes,It was accurately labelled," Since normal human airways share an anatomical structure, we design a graph prototype whose structure follows the normal airway anatomy. Then, we learn the prototype and a graph neural network from a weakly-supervised airway dataset, i.e., only the holistic label is available, indicating if the airway has anomaly or not, but which bronchus node has the anomaly is unknown. During inference, the graph neural network predicts the anomaly score at both the holistic level and node-level of an airway. "," Since normal human airways share an anatomical structure, we design a graph prototype whose structure follows the normal airway anatomy. Then, we learn the prototype and a graph neural network from a weakly-supervised airway dataset, i.e., only the holistic label is available, indicating if the airway has anomaly or not, but which bronchus node has the anomaly is unknown. During inference, the graph neural network predicts the anomaly score at both the holistic level and node-level of an airway. ",Detecting the airway anomaly can be an essential part to aid the lung disease diagnosis. ,"Graph analysis, Neural network","Specificity, Sensitivity",No,"But the data has to be segmented before using their model: Given the segmented and classified airway results shared by [7] (Fig. 2(b–c)), we encode the anatomical structure of the airways, as well as their image properties and graph properties into feature vectors. ",Yes,"We collected datasets from 3 resources: The Lung Image Database Consortium (LIDC) [8], The Lung Tissue Research Consortium (LTRC) [9], and The National Lung Screening Trial (NLST)","We collected datasets from 3 resources: The Lung Image Database Consortium (LIDC) [8], The Lung Tissue Research Consortium (LTRC) [9], and The National Lung Screening Trial (NLST) [10], leading to 62 normal samples and 23 anomaly samples in total. ",Public,"Looking at the references and googling, all 3 seem to be public",No,Nothing is mentioned,No,Nothing is mentioned,No,Nothing is mentioned,No,"(1)
Stony Brook University, Stony Brook, NY, USA  Nothing is mentioned",No,Nothing is mentioned,No,Nothing is mentioned,No,Nothing is mentioned,Yes,The code is publicly available on Github,
03/10/2022 09.17.03,272,2021,No,Other medical imaging task,"In the experiments, we use three widely used metrics [20] to evaluate the performance of different retrieval methods. These evaluation metrics are: average cumulative gain (ACG), normalized discounted cumulative gain (NDCG), and weighted mean average precision (mAP$$_w$$).",,,,,,,,,,,,,,,,,,,,,,,,,,,,
03/10/2022 09.18.24,273,2021,No,Other medical imaging task,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
03/10/2022 09.19.11,275,2021,No,Segmentation,ASC-Net: Adversarial-Based Selective Network for Unsupervised Anomaly Segmentation,,,,,,,,,,,,,,,,,,,,,,,,,,,,
04/10/2022 11.03.57,276,2021,Yes,It was accurately labelled,this paper tackles the problem of learning a model from the source data for which can directly generalize to an unseen target domain for SCD prediction.,this paper tackles the problem of learning a model from the source data for which can directly generalize to an unseen target domain for SCD prediction.,"It is highly desired to predict the progress of SCD for possible intervention of AD-related cognitive decline. Many neuroimaging-based methods have been developed for AD diagnosis, but there are few studies devoted to automated progress prediction of SCD due to the limited number of SCD subjects. ",Neural network,"AUC, Specificity, Accuracy, Sensitivity, balanced accuracy",No,"Following [17], all brain MRIs go through a standard pre-processing pipeline, including (i) skull stripping, (ii) intensity correction, (iii) re-sampling to the same resolution of $$1\times 1\times 1$$ mm$$^{3}$$ and (iv) spatial normalization to the Automated Anatomical Labeling (AAL) template. We employ the SPM software package2 as the main tool to facilitate the MR image pre-processing.",Yes," A total of 1, 393 T1-weighted structural MRIs from the publicly available Alzheimer’s Disease Neuroimaging Initiative (ADNI) dataset1 are used in this work to train a prediction model."," A total of 1, 393 T1-weighted structural MRIs from the publicly available Alzheimer’s Disease Neuroimaging Initiative (ADNI) dataset1 are used in this work to train a prediction model.",Public," A total of 1, 393 T1-weighted structural MRIs from the publicly available Alzheimer’s Disease Neuroimaging Initiative (ADNI) dataset1 are used in this work to train a prediction model.",No,Nothing is mentioned,No,Nothing is mentioned,No,Nothing is mentioned,Yes,"(1)
Department of Radiology and BRIC, University of North Carolina at Chapel Hill, Chapel Hill, NC 27599, USA
(2)
School of Biomedical Engineering, Southern Medical University, Guangzhou, 510515, China
(3)
Department of Geriatric Psychiatry, Shanghai Mental Health Center, Shanghai Jiao Tong University School of Medicine, Shanghai, 200030, China    H. Guan and M. Liu were partly supported by NIH grant (No. AG041721).",No,Nothing is mentioned,No,Nothing is mentioned,No,Nothing is mentioned,No,Nothing is mentioned,
04/10/2022 11.08.07,277,2021,Yes,It was accurately labelled,"In this work, we investigate the feasibility of using a single-phase non-contrast CT scan, a cheaper, simpler, and safer substituent, to detect resectable pancreatic mass and classify the detection as pancreatic ductal adenocarcinoma (PDAC) or other abnormalities (nonPDAC) or normal pancreas.","In this work, we investigate the feasibility of using a single-phase non-contrast CT scan, a cheaper, simpler, and safer substituent, to detect resectable pancreatic mass and classify the detection as pancreatic ductal adenocarcinoma (PDAC) or other abnormalities (nonPDAC) or normal pancreas.","Pancreatic cancer is a relatively uncommon but most deadly cancer. Screening the general asymptomatic population is not recommended due to the risk that a significant number of false positive individuals may undergo unnecessary imaging tests (e.g., multi-phase contrast-enhanced CT scans) and follow-ups, adding health care costs greatly and no clear patient benefits",Neural network,"AUC, Specificity, Sensitivity",Yes,Segmentation for classification is the most straightforward and adopted representation of the task of pancreatic tumor detection.,No,"Our dataset of CT scans of 1627 patients, is consecutively collected in the years of 2016–2018 from a high-volume pancreatic cancer institution. ","Our dataset of CT scans of 1627 patients, is consecutively collected in the years of 2016–2018 from a high-volume pancreatic cancer institution. ",Private,"Our dataset of CT scans of 1627 patients, is consecutively collected in the years of 2016–2018 from a high-volume pancreatic cancer institution. ",No,"Our dataset of CT scans of 1627 patients, is consecutively collected in the years of 2016–2018 from a high-volume pancreatic cancer institution. ",No,Nothing is mentioned,No,Nothing is mentioned,Yes,"(1)
Johns Hopkins University, Baltimore, USA
(2)
PAII Inc., Bethesda, USA
(3)
PingAn Technology, Shenzhen, China
(4)
Changhai Hospital, Shanghai, China   Y. Xia—Work done during an internship at PAII Inc.",No,Nothing is mentioned,No,Nothing is mentioned,No,Nothing is mentioned,No,Nothing is mentioned,
04/10/2022 11.13.09,278,2021,Yes,It was accurately labelled,"When evaluated on a separate biopsy-proven dataset, ADDLE outperforms standard classifiers as well as leading annotator noise competitors [4, 9].","we introduce auto-decoded deep latent embeddings (ADDLE), which explicitly models the tendencies of each rater using an auto-decoder framework. ","Depending on the application, radiological diagnoses can be associated with high inter- and intra-rater variabilities. Most computer-aided diagnosis (CAD) solutions treat such data as incontrovertible, exposing learning algorithms to considerable and possibly contradictory label noise and biases. Thus, managing subjectivity in labels is a fundamental problem in medical imaging analysis.",Neural network,AUC,No,Nothing is mentioned,No,"To this end, we collected a big-data (BD) cohort consisting of $$3\,790$$ patients, $$312\,848$$ US images, and $$36\,602$$ US studies from the PACS of Anonymized. Through the course of clinical care, each study was given a four-class ordinal assessment of either healthy, mild, moderate, or severe steatosis from one of 65 clinicians. We used $$3\,405$$ patients for training and left the rest as a stopping criteria validation set. ","To this end, we collected a big-data (BD) cohort consisting of $$3\,790$$ patients, $$312\,848$$ US images, and $$36\,602$$ US studies from the PACS of Anonymized. Through the course of clinical care, each study was given a four-class ordinal assessment of either healthy, mild, moderate, or severe steatosis from one of 65 clinicians. We used $$3\,405$$ patients for training and left the rest as a stopping criteria validation set. ",Private,"To this end, we collected a big-data (BD) cohort consisting of $$3\,790$$ patients, $$312\,848$$ US images, and $$36\,602$$ US studies from the PACS of Anonymized. Through the course of clinical care, each study was given a four-class ordinal assessment of either healthy, mild, moderate, or severe steatosis from one of 65 clinicians. We used $$3\,405$$ patients for training and left the rest as a stopping criteria validation set. ",No,"To this end, we collected a big-data (BD) cohort consisting of $$3\,790$$ patients, $$312\,848$$ US images, and $$36\,602$$ US studies from the PACS of Anonymized. Through the course of clinical care, each study was given a four-class ordinal assessment of either healthy, mild, moderate, or severe steatosis from one of 65 clinicians. We used $$3\,405$$ patients for training and left the rest as a stopping criteria validation set. ",No,Nothing is mentioned,Yes,"For this article: To this end, we collected a big-data (BD) cohort consisting of $$3\,790$$ patients, $$312\,848$$ US images, and $$36\,602$$ US studies from the PACS of Anonymized",No,"(1)
PAII Inc., Bethesda, MD 20817, USA
(2)
Ruijin Hospital, Shanghai, China
(3)
Chang Gung Memorial Hospital, Linkou, Taoyuan, Taiwan ROC
(4)
PingAn Technology, Shenzhen, China  Nothing is mentioned",No,Nothing is mentioned,No,Nothing is mentioned,No,Nothing is mentioned,Yes,Supplementary electronic material,
04/10/2022 11.14.57,279,2021,No,Other medical imaging task,Accurate localization and identification of vertebrae from CT images is a fundamental step in clinical spine diagnosis and treatment. ,,,,,,,,,,,,,,,,,,,,,,,,,,,,
04/10/2022 11.20.08,280,2021,Yes,It was accurately labelled,"This work aims at developing and evaluating a deep learning-based framework, named VinDr-SpineXR, for the classification and localization of abnormalities from spine X-rays","This work aims at developing and evaluating a deep learning-based framework, named VinDr-SpineXR, for the classification and localization of abnormalities from spine X-rays","Radiographs are used as the most important imaging tool for identifying spine anomalies in clinical practice. The evaluation of spinal bone lesions, however, is a challenging task for radiologists",Neural network,"AUC, Specificity, F1 score, Sensitivity",No,Nothing is mentioned,No,Nothing is mentioned," In this work, more than 50,000 raw spine images in DICOM format were retrospectively collected from the Picture Archive and Communication System (PACS) of different primary hospitals between 2010–2020. ",Private," In this work, more than 50,000 raw spine images in DICOM format were retrospectively collected from the Picture Archive and Communication System (PACS) of different primary hospitals between 2010–2020. ",No,The data collection process was conducted under our cooperation with participating hospitals.,Yes," Since this research did not impact clinical care, patient consent was waived. To keep patient’s Protected Health Information (PHI) secure, all patient-identifiable information associated with the images has been removed. Several DICOM attributes that are important for evaluating the spine conditions like patient’s age and sex were retained.",Yes,For this article,No,"(1)
Medical Imaging Center, Vingroup Big Data Institute, Hanoi, Vietnam
(2)
School of Information and Communication Technology, Hanoi University of Science and Technology, Hanoi, Vietnam
(3)
College of Engineering and Computer Science, VinUniversity, Hanoi, Vietnam
(4)
Department of Mathematics, Yale University, New Heaven, USA  Nothing is mentioned",Yes,"Since this research did not impact clinical care, patient consent was waived. To keep patient’s Protected Health Information (PHI) secure, all patient-identifiable information associated with the images has been removed. Several DICOM attributes that are important for evaluating the spine conditions like patient’s age and sex were retained.",No,Nothing is mentioned,No,Nothing is mentioned,Yes,Supplementary electronic material,Interesting addition about the patients rights!
04/10/2022 11.21.01,281,2021,No,Other medical imaging task,Precise localization of polyp is crucial for early cancer screening in gastrointestinal endoscopy.,,,,,,,,,,,,,,,,,,,,,,,,,,,,
04/10/2022 11.27.12,283,2021,Yes,It was accurately labelled,Highly imbalanced datasets are ubiquitous in medical image classification problems.,"we propose a novel mechanism for sampling training data based on the popular MixUp regularization technique, which we refer to as Balanced-MixUp. ","Highly imbalanced datasets are ubiquitous in medical image classification problems. In such problems, it is often the case that rare classes associated to less prevalent diseases are severely under-represented in labeled databases, typically resulting in poor performance of machine learning algorithms due to overfitting in the learning process.",Neural network,"Matthews Correlation Coefficient,  quadratic-weighted kappa score",No,Nothing is mentioned,Yes,Multiple datasets are used,Different sizes,Public,"Eyepacs database1 the largest publicly available dataset, we use the Hyper-Kvasir dataset4, recently made available [2]",No,Nothing is mentioned,No,Nothing is mentioned,No,Nothing is mentioned,Yes,"(1)
Bournemouth University, Poole, UK
(2)
University of Adelaide, Adelaide, Australia
(3)
BCN Medtech, Department of Information and Communication Technologies, Universitat Pompeu Fabra, Barcelona, Spain
(4)
Catalan Institution for Research and Advanced Studies (ICREA), Barcelona, Spain    This work was partially supported by a Marie Skłodowska-Curie Global Fellowship (No. 892297) and by Australian Research Council grants (DP180103232 and FT190100525).",No,Nothing is mentioned,No,Nothing is mentioned,No,Nothing is mentioned,Yes,Code is released at https://​github.​com/​agaldran/​balanced_​mixup,
07/10/2022 12.53.28,284,2021,Yes,It was accurately labelled,We curated a dataset of seizure videos from 68 patients and evaluated GESTURES on its ability to classify seizures ,"Detailed analysis of seizure semiology, the symptoms and signs which occur during a seizure, is critical for management of epilepsy patients. Inter-rater reliability using qualitative visual analysis is often poor for semiological features. Therefore, automatic and quantitative analysis of video-recorded seizures is needed for objective assessment. We present GESTURES, a novel architecture combining convolutional neural networks (CNNs) and recurrent neural networks (RNNs) to learn deep representations of arbitrarily long videos of epileptic seizures.","Detailed analysis of seizure semiology, the symptoms and signs which occur during a seizure, is critical for management of epilepsy patients. Inter-rater reliability using qualitative visual analysis is often poor for semiological features. Therefore, automatic and quantitative analysis of video-recorded seizures is needed for objective assessment. We present GESTURES, a novel architecture combining convolutional neural networks (CNNs) and recurrent neural networks (RNNs) to learn deep representations of arbitrarily long videos of epileptic seizures.",Neural network,"AUC, Accuracy, F1 score",No,Don't think they mention it,No,"We curated a dataset comprising 141 FOSs and 77 TCSs videos from 68 epileptic patients undergoing presurgical evaluation at the National Hospital for Neurology and Neurosurgery, London, United Kingdom.

","We curated a dataset comprising 141 FOSs and 77 TCSs videos from 68 epileptic patients undergoing presurgical evaluation at the National Hospital for Neurology and Neurosurgery, London, United Kingdom.

",Private,"We curated a dataset comprising 141 FOSs and 77 TCSs videos from 68 epileptic patients undergoing presurgical evaluation at the National Hospital for Neurology and Neurosurgery, London, United Kingdom.

",Yes,"Patients were recorded using two full high-definition ($$1920 \times 1080$$ pixels, 30 frames per second (FPS)) cameras installed in the EMU as part of standard clinical practice. Infrared is used for acquisition in scenes with low light intensity, such as during nighttime. The acquisition software (Micromed, Treviso, Italy) automatically resizes one of the video streams ($$800 \times 450$$), superimposes it onto the top-left corner of the other stream and stores the montage using MPEG-2. See the supplementary materials for six examples of videos in our dataset.

",No,Nothing is mentioned,Yes,For the article,Yes,"(1)
Department of Medical Physics and Biomedical Engineering, University College London, London, UK
(2)
Wellcome/EPSRC Centre for Interventional and Surgical Sciences (WEISS), University College London, London, UK
(3)
School of Biomedical Engineering and Imaging Sciences (BMEIS), King’s College London, London, UK
(4)
Department of Clinical and Experimental Epilepsy, UCL Queen Square Institute of Neurology, London, UK
(5)
Department of Clinical Neurophysiology, National Hospital for Neurology and Neurosurgery, London, UK

This work is supported by the Engineering and Physical Sciences Research Council (EPSRC) [EP/R512400/1]. This work is additionally supported by the EPSRC-funded UCL Centre for Doctoral Training in Intelligent, Integrated Imaging in Healthcare (i4health) [EP/S021930/1] and the Wellcome/EPSRC Centre for Interventional and Surgical Sciences (WEISS, UCL) [203145Z/16/Z]. The data acquisition was supported by the National Institute of Neurological Disorders and Stroke [U01-NS090407].

This publication represents, in part, independent research commissioned by the Wellcome Innovator Award [218380/Z/19/Z/]. The views expressed in this publication are those of the authors and not necessarily those of the Wellcome Trust.

The weights for the 2D and 3D models were downloaded from TorchVision and https://​github.​com/​moabitcoin/​ig65m-pytorch, respectively.",No,Nothing is mentioned,No,Nothing is mentioned,No,Nothing is mentioned,Yes,"The code, models and features dataset are available at https://​github.​com/​fepegar/​gestures-miccai-2021.
Electronic supplementary material
The online version of this chapter (https://​doi.​org/​10.​1007/​978-3-030-87240-3_​32) contains supplementary material, which is available to authorized users
",
07/10/2022 12.55.00,285,2021,No,,Retina-Match: Ipsilateral Mammography Lesion Matching in a Single Shot Detection Pipeline,,,,,,,,,,,,,,,,,,,,,,,,,,,,
07/10/2022 13.00.00,286,2021,Yes,It was accurately labelled,Based on the performance measures this lesion matching is a form of classification,"A holistic understanding of dual-view transformation (DVT) is an enabling technique for computer-aided diagnosis (CAD) of breast lesion in mammogram, e.g., micro-calcification ($$\mu $$C) or mass matching, dual-view feature extraction etc. Learning a complete DVT usually relies on a dense supervision which indicates a corresponding tissue in one view for each tissue in another. Since such dense supervision is infeasible to obtain in practical, a sparse supervision of some traceable lesion tissues across two views is thus an alternative but will lead to a defective DVT, limiting the performance of existing CAD systems dramatically. To address this problem, our solution is simple but very effective, i.e., densifying the existing sparse supervision by synthesizing lesions across two views","Since such dense supervision is infeasible to obtain in practical, a sparse supervision of some traceable lesion tissues across two views is thus an alternative but will lead to a defective DVT, limiting the performance of existing CAD systems dramatically. ",Neural network,"AUC, Balanced accuracy",No,Nothing is mentioned,Yes,"we conduct several experiments of cross-view $$\mu $$C matching and evaluate on two public mammography dataset, i.e., the INbreast (115 patients and 410 images in total) and the CBIS-DDSM (3103 images in total). ","we conduct several experiments of cross-view $$\mu $$C matching and evaluate on two public mammography dataset, i.e., the INbreast (115 patients and 410 images in total) and the CBIS-DDSM (3103 images in total). ",Public,"we conduct several experiments of cross-view $$\mu $$C matching and evaluate on two public mammography dataset, i.e., the INbreast (115 patients and 410 images in total) and the CBIS-DDSM (3103 images in total). ",No,Nothing is mentioned,No,Nothing is mentioned,No,Nothing is mentioned,Yes,"(1)
School of Electronic Information and Communication, Huazhong University of Science and Technology, Wuhan, China
(2)
Britton Chance Center for Biomedical Photonics, Wuhan National Laboratory for Optoelectronics, Huazhong University of Science and Technology, Wuhan, China
(3)
MoE Key Laboratory for Biomedical Photonics, Collaborative Innovation Center for Biomedical Engineering, School of Engineering Sciences, Huazhong University of Science and Technology, Wuhan, China
(4)
Hong Kong University of Science and Technology, Hong Kong, China
(5)
Wuhan National Laboratory for Optoelectronics, Huazhong University of Science and Technology, Wuhan, China

This work was supported by the National Natural Science Foundation of China (6187241762061160490), the project of Wuhan Science and Technology Bureau (2020010601012167), the Open Project of Wuhan National Laboratory for Optoelectronics (2018WNLOKF025), the Fundamental Research Funds for the Central Universities (2021XXJS033).",No,Nothing is mentioned,No,Nothing is mentioned,No,Nothing is mentioned,No,Nothing is mentioned,
07/10/2022 13.04.36,287,2021,Yes,It was accurately labelled,"Clinical finding summaries from an orthopantomogram, or a dental panoramic radiograph, have significant potential to improve patient communication and speed up clinical judgments. While orthopantomogram is a first-line tool for dental examinations, no existing work has explored the summarization of findings from it. A finding summary has to find teeth in the imaging study and label the teeth with several types of past treatments. To tackle the problem, we develop DeepOPG that breaks the summarization process into functional segmentation and tooth localization, the latter of which is further refined by a novel dental coherence module. We also leverage weak supervision labels to improve detection results in a reinforcement learning scenario.","we develop DeepOPG that breaks the summarization process into functional segmentation and tooth localization, the latter of which is further refined by a novel dental coherence module. We also leverage weak supervision labels to improve detection results in a reinforcement learning scenario.","Clinical finding summaries from an orthopantomogram, or a dental panoramic radiograph, have significant potential to improve patient communication and speed up clinical judgments. While orthopantomogram is a first-line tool for dental examinations, no existing work has explored the summarization of findings from it. ",Neural network,AUC,Yes,we develop DeepOPG that breaks the summarization process into functional segmentation,Yes,"we use the UFBA-UESC Dental Images Deep dataset [9] where there are 1,500 OPG images in total","we use the UFBA-UESC Dental Images Deep dataset [9] where there are 1,500 OPG images in total",Public,Available upon request,No,Nothing is mentioned,No,Nothing is mentioned,No,Nothing is mentioned,No,"(1)
MIT CSAIL, Cambridge, USA
(2)
Chung Shan Medical University, Taichung, Taiwan",No,Nothing is mentioned,No,Nothing is mentioned,No,Nothing is mentioned,No,"The dataset and code are made available online.

Electronic supplementary material
The online version of this chapter (https://​doi.​org/​10.​1007/​978-3-030-87240-3_​35) contains supplementary material, which is available to authorized users.",
07/10/2022 13.09.24,288,2021,Yes,Other medical imaging task,The spine centerline extraction is formulated as a row-wise classification task,we propose a deep learning-based approach to simultaneously estimate spine centerline and spinal curvature with shared convolutional backbone,Spinal curvature estimation plays an important role in adolescent idiopathic scoliosis (AIS) evaluation and treatment. ,Graph analysis,symmetric mean absolute percentage ,No,If I understand correctly it doesn't use segmentation...,Yes,"The public dataset of 609 spinal anterior-posterior X-ray images, which is used as the training set in the Accurate Automated Spinal Curvature Estimation (AASCE) challenge 2019, is used for the evaluation of our method.","The public dataset of 609 spinal anterior-posterior X-ray images, which is used as the training set in the Accurate Automated Spinal Curvature Estimation (AASCE) challenge 2019, is used for the evaluation of our method.",Public,"The public dataset of 609 spinal anterior-posterior X-ray images, which is used as the training set in the Accurate Automated Spinal Curvature Estimation (AASCE) challenge 2019, is used for the evaluation of our method.",No,Nothing is mentioned,No,Nothing is mentioned,No,Nothing is mentioned,Yes,"(1)
Institute of Intelligent Machines, HFIPS, Chinese Academy of Sciences, Hefei, China
(2)
University of Science and Technology of China, Hefei, China
(3)
School of Information Engineering, Zhengzhou University, Zhengzhou, China
(4)
Nullmax, Shanghai, China
(5)
The First Affiliated Hospital of USTC, Division of Life Sciences and Medicine, University of Science and Technology of China, Hefei, China

This work is supported in part by the grant of NSFC (61804100, 61973294, 61806181), KRDP of Anhui Province (201904a05020086) and CAS (GJTD-2018-15).",No,Nothing is mentioned,No,Nothing is mentioned,No,Nothing is mentioned,No,Nothing is mentioned,
07/10/2022 13.11.03,289,2021,No,Other medical imaging task,"Is about a dataset, which is good, also for classification, but not a classification method on its own",,,,,,,,,,,,,,,,,,,,,,,,,,,,
07/10/2022 13.16.05,290,2021,Yes,It was accurately labelled,"Current deep learning models are characterised by catastrophic forgetting of old knowledge when learning new classes. This poses a challenge in intelligent diagnosis systems where initially only training data of a limited number of diseases are available. In this case, updating the intelligent system with data of new diseases would inevitably downgrade its performance on previously learned diseases. Inspired by the process of learning new knowledge in human brains, we propose a Bayesian generative model for continual learning built on a fixed pre-trained feature extractor. In this model, knowledge of each old class can be compactly represented by a collection of statistical distributions, e.g. with Gaussian mixture models, and naturally kept from forgetting in continual learning. Experiments on two skin image sets showed that the proposed approach outperforms state-of-the-art approaches which even keep some images of old classes during continual learning of new classes.","we propose a Bayesian generative model for continual learning built on a fixed pre-trained feature extractor. In this model, knowledge of each old class can be compactly represented by a collection of statistical distributions, e.g. with Gaussian mixture models, and naturally kept from forgetting in continual learning.","Current deep learning models are characterised by catastrophic forgetting of old knowledge when learning new classes. This poses a challenge in intelligent diagnosis systems where initially only training data of a limited number of diseases are available.  In this case, updating the intelligent system with data of new diseases would inevitably downgrade its performance on previously learned diseases. Inspired by the process of learning new knowledge in human brains,",Neural network,Recall,No,Nothing is mentioned,Yes,"The proposed approach was extensively evaluated on two medical skin image datasets. Skin7 [5] is a skin lesion dataset from the challenge of dermoscopic image classification held by the International Skin Imaging Collaboration (ISIC) in 2018. It consists of 7 disease categories, and each image is of size $$600\times 450$$ pixels. This dataset presents severe class imbalance, with the largest class 60 times larger than the smallest one. Skin40 is a subset of 193 classes of skin disease images collected from the internet [18]. Skin40 contains two types of images, dermoscopic images which have relatively consistent imaging conditions (e.g., similar illumination) and therefore low levels of imaging noise, and clinical images captured mostly with digital cameras or mobile phones. ","The proposed approach was extensively evaluated on two medical skin image datasets. Skin7 [5] is a skin lesion dataset from the challenge of dermoscopic image classification held by the International Skin Imaging Collaboration (ISIC) in 2018. It consists of 7 disease categories, and each image is of size $$600\times 450$$ pixels. This dataset presents severe class imbalance, with the largest class 60 times larger than the smallest one. Skin40 is a subset of 193 classes of skin disease images collected from the internet [18]. Skin40 contains two types of images, dermoscopic images which have relatively consistent imaging conditions (e.g., similar illumination) and therefore low levels of imaging noise, and clinical images captured mostly with digital cameras or mobile phones. ",Public,"The proposed approach was extensively evaluated on two medical skin image datasets. Skin7 [5] is a skin lesion dataset from the challenge of dermoscopic image classification held by the International Skin Imaging Collaboration (ISIC) in 2018. It consists of 7 disease categories, and each image is of size $$600\times 450$$ pixels. This dataset presents severe class imbalance, with the largest class 60 times larger than the smallest one. Skin40 is a subset of 193 classes of skin disease images collected from the internet [18]. Skin40 contains two types of images, dermoscopic images which have relatively consistent imaging conditions (e.g., similar illumination) and therefore low levels of imaging noise, and clinical images captured mostly with digital cameras or mobile phones. ",No,Nothing is mentioned,No,Nothing is mentioned,No,Nothing is mentioned,Yes,"(1)
School of Computer Science and Engineering, Sun Yat-sen University, Guangzhou, China
(2)
Key Laboratory of Machine Intelligence and Advanced Computing, MOE, China
(3)
Pazhou Lab, Guangzhou, China

This work is supported in part by the National Natural Science Foundation of China (grant No. 62071502, U1811461), the Guangdong Key Research and Development Program (grant No. 2020B1111190001, 2019B020228001), and the Meizhou Science and Technology Program (grant No. 2019A0102005).",No,Nothing is mentioned,No,Nothing is mentioned,No,Nothing is mentioned,No,Nothing is mentioned,
11/10/2022 08.54.16,291,2021,Yes,It was accurately labelled,Extensive evaluations on three different medical image classification tasks and three classifier backbones support that our method consistently improves the performance of the classifier which even has been trained by any re-balancing strategy. ,"Intelligent diagnosis is often biased toward common diseases due to data imbalance between common and rare diseases. Such bias may still exist even after applying re-balancing strategies during model training. To further alleviate the bias, we propose a novel method which works not in the training but in the inference phase.","Intelligent diagnosis is often biased toward common diseases due to data imbalance between common and rare diseases. Such bias may still exist even after applying re-balancing strategies during model training. To further alleviate the bias, we propose a novel method which works not in the training but in the inference phase. For any test input data, based on the difference between the temperature-tuned classifier output and a target probability distribution derived from the inverse frequency of different diseases, the input data can be slightly perturbed in a way similar to adversarial learning.",Neural network,Recall,No,Nothing is mentioned,Yes,"The proposed method was extensively evaluated on three imbalanced medical image datasets, Skin7 [5], OCTMNIST [27], and X-ray6 (Table 1). Specially, X-ray6 contains six diseases of X-ray images (Atelectasis, Cardiomegaly, Emphysema, Hernia, Mass, Effusion), where the six classes were selected from the original 14-class dataset ChestX-ray14 [24] by removing those classes of images which may contain multiple or ambiguous diseases in single images. ","3 different, different sizes",Private,"The proposed method was extensively evaluated on three imbalanced medical image datasets, Skin7 [5], OCTMNIST [27], and X-ray6 (Table 1). Specially, X-ray6 contains six diseases of X-ray images (Atelectasis, Cardiomegaly, Emphysema, Hernia, Mass, Effusion), where the six classes were selected from the original 14-class dataset ChestX-ray14 [24] by removing those classes of images which may contain multiple or ambiguous diseases in single images. ",No,Nothing is mentioned,No,Nothing is mentioned,Yes,"For one of the three it was created for this article specifically: 
The proposed method was extensively evaluated on three imbalanced medical image datasets, Skin7 [5], OCTMNIST [27], and X-ray6 (Table 1). Specially, X-ray6 contains six diseases of X-ray images (Atelectasis, Cardiomegaly, Emphysema, Hernia, Mass, Effusion), where the six classes were selected from the original 14-class dataset ChestX-ray14 [24] by removing those classes of images which may contain multiple or ambiguous diseases in single images. ",Yes,"(1)
School of Computer Science and Engineering, Sun Yat-sen University, Guangzhou, China
(2)
Key Laboratory of Machine Intelligence and Advanced Computing, MOE, Guangzhou, China

This work is supported by the National Natural Science Foundation of China (No. 62071502, U1811461), the Guangdong Key Research and Development Program (No. 2020B1111190001, 2019B020228001), and the Meizhou Science and Technology Program (No. 2019A0102005).",No,Nothing is mentioned,No,Nothing is mentioned,No,Nothing is mentioned,No,Nothing is mentioned,
11/10/2022 08.55.30,292,2021,No,Other medical imaging task,Vessel centerline extraction is fundamental for plentiful medical applications. ,,,,,,,,,,,,,,,,,,,,,,,,,,,,
11/10/2022 09.00.34,294,2021,Yes,It was accurately labelled,Predicting Symptoms from Multiphasic MRI via Multi-instance Attention Learning for Hepatocellular Carcinoma Grading,we propose a two-stage method for automatically predicting HCC grades according to multiphasic magnetic resonance imaging (MRI). ,"Liver cancer is the third leading cause of cancer death in the world, where the hepatocellular carcinoma (HCC) is the most common case in primary liver cancer. In general diagnosis, accurate prediction of HCC grades is of great help to the subsequent treatment to improve the survival rate. Rather than to straightly predict HCC grades from images, it will be more interpretable in clinic to first predict the symptoms and then obtain the HCC grades from the Liver Imaging Reporting and Data System (LI-RADS). Accordingly, we propose a two-stage method for automatically predicting HCC grades according to multiphasic magnetic resonance imaging (MRI). ",Neural network,"Accuracy, Precision, Recall, F1 score",No,Nothing is mentioned,No,"We evaluate our method on a dataset of 439 subjects, including 93, 98, and 248 HCC cases of grading LR-3, LR-4, and LR-5, respectively. All data were obtained using either a 1.5 T (Magnetom Aera, Siemens Healthcare, Erlangen, Germany) or a 3.0 T (uMR 770, United Imaging Healthcare, Shanghai, China) MR scanner with Gd-EOB-DTPA as contrast agent in same hospital and labeled by three radiologists with experience over 5 years. ","We evaluate our method on a dataset of 439 subjects, including 93, 98, and 248 HCC cases of grading LR-3, LR-4, and LR-5, respectively. All data were obtained using either a 1.5 T (Magnetom Aera, Siemens Healthcare, Erlangen, Germany) or a 3.0 T (uMR 770, United Imaging Healthcare, Shanghai, China) MR scanner with Gd-EOB-DTPA as contrast agent in same hospital and labeled by three radiologists with experience over 5 years. ",Private,"We evaluate our method on a dataset of 439 subjects, including 93, 98, and 248 HCC cases of grading LR-3, LR-4, and LR-5, respectively. All data were obtained using either a 1.5 T (Magnetom Aera, Siemens Healthcare, Erlangen, Germany) or a 3.0 T (uMR 770, United Imaging Healthcare, Shanghai, China) MR scanner with Gd-EOB-DTPA as contrast agent in same hospital and labeled by three radiologists with experience over 5 years. ",Yes,"We evaluate our method on a dataset of 439 subjects, including 93, 98, and 248 HCC cases of grading LR-3, LR-4, and LR-5, respectively. All data were obtained using either a 1.5 T (Magnetom Aera, Siemens Healthcare, Erlangen, Germany) or a 3.0 T (uMR 770, United Imaging Healthcare, Shanghai, China) MR scanner with Gd-EOB-DTPA as contrast agent in same hospital and labeled by three radiologists with experience over 5 years. ",No,Nothing is mentioned,Yes,"I think for this article:
We evaluate our method on a dataset of 439 subjects, including 93, 98, and 248 HCC cases of grading LR-3, LR-4, and LR-5, respectively. All data were obtained using either a 1.5 T (Magnetom Aera, Siemens Healthcare, Erlangen, Germany) or a 3.0 T (uMR 770, United Imaging Healthcare, Shanghai, China) MR scanner with Gd-EOB-DTPA as contrast agent in same hospital and labeled by three radiologists with experience over 5 years. ",Yes,"(1)
National Engineering Laboratory for Integrated Aero-Space-Ground-Ocean Big Data Application Technology, School of Computer Science and Engineering, Northwestern Polytechnical University, Xi’an, 710072, Shaanxi, China
(2)
Research and Development Institute of Northwestern Polytechnical University in Shenzhen, Shenzhen, 518057, China
(3)
School of Biomedical Engineering, ShanghaiTech University, Shanghai, China
(4)
Shanghai United Imaging Intelligence Co., Ltd., Shanghai, China

This work was supported in part by the National Natural Science Foundation of China under Grants 61771397, in part by the CAAI-Huawei MindSpore Open Fund under Grants CAAIXSJLJJ-2020-005B, and in part by the China Postdoctoral Science Foundation under Grants BX2021333.",No,Nothing is mentioned,No,Nothing is mentioned,No,Nothing is mentioned,No,Nothing is mentioned,
11/10/2022 09.08.14,297,2021,Yes,It was accurately labelled,Data Augmentation in Logit Space for Medical Image Classification with Limited Training Data,"a novel data augmentation method is proposed to effectively alleviate the over-fitting issue, not in the input space but in the logit space. ","Successful application of deep learning often depends on large amount of training data. However in practical medical image analysis, available training data are often limited, often causing over-fitting during model training. In this paper, a novel data augmentation method is proposed to effectively alleviate the over-fitting issue, not in the input space but in the logit space. ",Neural network,Accuracy,No,Nothing is mentioned (and segmentation doesn't seem to be used with neural networks?),Yes,"The proposed method was extensively evaluated on three medical image classification datasets, Skin40, Skin8, and Xray6.",Mixed sizes,Public,"At least one is public, think the two others are private",No,Nothing is mentioned,No,Nothing is mentioned,Yes,"The final dataset is created for this article, the others no:
Xray6 is a subset of ChestXray14 dataset [23], containing six diseases of X-ray images (Atelectasis, Cardiomegaly, Emphysema, Hernia, Mass, Effusion). Based on the smallest class (i.e., Hernia) which has only 110 images, the same number of images were randomly sampled from every other class, forming the small-sample Xray6 dataset. ",Yes,"(1)
School of Computer Science and Engineering, Sun Yat-sen University, Guangzhou, China
(2)
Key Laboratory of Machine Intelligence and Advanced Computing, MOE, Guangzhou, China
(3)
Pazhou Lab, Guangzhou, China

This work is supported by the National Natural Science Foundation of China (No. 62071502, U1811461), the Guangdong Key Research and Development Program (No. 2020B1111190001, 2019B020228001), and the Meizhou Science and Technology Program (No. 2019A0102005).",No,Nothing is mentioned,No,Nothing is mentioned,No,Nothing is mentioned,No,Nothing is mentioned,Really hard to find the performance measure!
11/10/2022 09.12.06,298,2021,Yes,It was accurately labelled,"In this paper, we propose the collaborative diagnosis-synthesis framework (CDSF) for joint missing neuroimage imputation and multi-modal diagnosis of neurodegenerative disorders. ","In this paper, we propose the collaborative diagnosis-synthesis framework (CDSF) for joint missing neuroimage imputation and multi-modal diagnosis of neurodegenerative disorders. ","The missing data issue is a common problem in multi-modal neuroimage (e.g., MRI and PET) based diagnosis of neurodegenerative disorders.",Neural network,"AUC, Specificity, Accuracy, F1 score, Sensitivity, Matthews correlation coefficient",No,Nothing is mentioned,Yes,"Two subsets of the Alzheimer’s Disease Neuroimaging Initiative (ADNI) studies [13], including ADNI-1 phase and ADNI-2 phase, were used for this study. All collected subjects in ADNI-1/-2 have baseline MRI data, while only part of them have PET images. We follow the same steps in [2, 10] to process the collected data. The subjects in ADNI-1/2 were divided into three categories: AD, cognitively normal (CN), and MCI. MCI could be further divided into progressive MCI (pMCI) and static MCI (sMCI) that would or would not progress to AD within 36 months after the baseline. Totally, we also have 205 AD, 231 CN, 165 pMCI, and 147 sMCI subjects in ADNI-1, and 162 AD, 209 CN, 89 pMCI, and 256 sMCI subjects in ADNI-2.","Two subsets of the Alzheimer’s Disease Neuroimaging Initiative (ADNI) studies [13], including ADNI-1 phase and ADNI-2 phase, were used for this study. All collected subjects in ADNI-1/-2 have baseline MRI data, while only part of them have PET images. We follow the same steps in [2, 10] to process the collected data. The subjects in ADNI-1/2 were divided into three categories: AD, cognitively normal (CN), and MCI. MCI could be further divided into progressive MCI (pMCI) and static MCI (sMCI) that would or would not progress to AD within 36 months after the baseline. Totally, we also have 205 AD, 231 CN, 165 pMCI, and 147 sMCI subjects in ADNI-1, and 162 AD, 209 CN, 89 pMCI, and 256 sMCI subjects in ADNI-2.",Public,ADNI,,nothing is mentioned,No,nothing is mentioned,No,nothing is mentioned,Yes,"(1)
National Engineering Laboratory for Integrated Aero-Space-Ground-Ocean Big Data Application Technology, School of Computer Science and Engineering, Northwestern Polytechnical University, Xi’an, 710072, Shaanxi, China
(2)
Research and Development Institute of Northwestern Polytechnical University in Shenzhen, Shenzhen, 518057, China
(3)
School of Biomedical and Engineering, ShanghaiTech University, Shanghai, 201210, China

This work was supported in part by the National Natural Science Foundation of China under Grants 61771397, in part by the CAAI-Huawei MindSpore Open Fund under Grants CAAIXSJLJJ-2020-005B, and in part by the China Postdoctoral Science Foundation under Grants BX2021333.",No,nothing is mentioned,No,nothing is mentioned,No,nothing is mentioned,No,nothing is mentioned,
11/10/2022 09.15.48,300,2021,Yes,It was accurately labelled,Meta-modulation Network for Domain Generalization in Multi-site fMRI Classification,we propose a novel framework that adaptively calibrates the site-specific features into site-invariant features via a novel modulation mechanism. ,"In general, it is expected that large amounts of functional magnetic resonance imaging (fMRI) would be helpful to deduce statistically meaningful biomarkers or to build generalized predictive models for brain disease diagnosis. However, the site-variation inherent in rs-fMRI hampers the researchers to use the entire samples collected from multiple sites because it involves the unfavorable heterogeneity in data distribution, thus negatively impact on identifying biomarkers and making a diagnostic decision. To alleviate this challenging multi-site problem, we propose a novel framework that adaptively calibrates the site-specific features into site-invariant features via a novel modulation mechanism.",Neural network,"AUC, Specificity, Accuracy, Sensitivity",No,Nothing is mentioned,Yes,We validated our proposed network over the public Autism Brain Imaging Data Exchange (ABIDE) dataset comprised of data from multiple sites.,"We used 1, 032 samples from a total of 16 sites3, in which 496 subjects are with autism spectrum disorders (ASD) and 536 subjects are with typical developments (TD).",Public,We validated our proposed network over the public Autism Brain Imaging Data Exchange (ABIDE) dataset comprised of data from multiple sites.,No,Nothing is mentioned,No,Nothing is mentioned,No,Nothing is mentioned,Yes,"(1)
Department of Brain and Cognitive Engineering, Korea University, Seoul, Republic of Korea
(2)
Department of Artificial Intelligence, Korea University, Seoul, Republic of Korea

This work was supported by National Research Foundation of Korea (NRF) grant funded by the Korea government (MSIT) (No. 2019R1A2C1006543) and partially by Institute of Information & communications Technology Planning & Evaluation (IITP) grant funded by the Korea government (MSIT) (No. 2019-0-00079, Artificial Intelligence Graduate School Program (Korea University)).",No,Nothing is mentioned,No,Nothing is mentioned,No,Nothing is mentioned,No,Nothing is mentioned,