Tidsstempel,What is the article's index?,Which year is the article from?,Is the article accurately labelled as classification?,"If not accurately labelled as classification, what would you label it as?",Please input the quote from which you infer the answer to the previous question (if possible),What is the aim or task of the article? (input quote),How does the article justify this aim or task? (input quote),Which method is used for classification?,Which performance measures are used? ,Does the article use segmentation as preprocessing?,Please input the quote from which you infer the answer to the previous question (if possible),Does the dataset used in the article have a title?,Please input the quote from which you infer the answer to the previous question (if possible),What is the size of the used dataset? (input quote),What type is the dataset?,Please input the quote from which you infer the answer to the previous question (if possible),Is the survey/method of how the dataset was obtained accessible?,Please input the quote from which you infer the answer to the previous question (if possible),Does the article mention the demographics of the patients/images included in the used dataset?,Please input the quote from which you infer the answer to the previous question (if possible),Does the article mention the intent for collecting the dataset? The intended task for the dataset?,Please input the quote from which you infer the answer to the previous question (if possible),Does the article disclose any affiliations?,Please input the quote from which you infer the answer to the previous question (if possible),"Does the article include anything about respect for persons (informed consent, voluntary participation) participating in the dataset? ",Please input the quote from which you infer the answer to the previous question (if possible),"Does the article have any mention of benefience, minimising risk/maximising benefit of work? ",Please input the quote from which you infer the answer to the previous question (if  possible),"Does the article have any mention of justice (equal treatment, fair selection of subjects)?",Please input the quote from which you infer the answer to the previous question (if  possible),"Does the article mention any respect for law/public interest (transparency in methods/results, accountability for actions)?",Please input the quote from which you infer the answer to the previous question (if  possible),Are there any other comments/interesting aspects?
22/09/2022 13.28.08,4,2012,Yes,It was accurately labelled,we propose and evaluate three approaches to surgical gesture classification from video.,surgical gesture analysis,"Most of the prior work on surgical gesture recognition (see, e.g., [4-6]) uses hidden Markov models (HMMs) to analyze kinematic data stored by the robot (…) Overall, our main conclusion is that methods based on video data perform equally well as methods based n kinematic data for a typical surgical training setup.","""In the first one, we model each video clip from each surgical gesture as the output of a linear dynamical system (LDS) and use metrics in the space of LDSs to classify new video clips. In the second one, we use spatio-temporal features extracted from each video clip to learn a dictionary of spatio-temporal words and use a bag-of-features (BoF) approach to classify new video clips. In the third approach, we use multiple kernel learning to combine the LDS and BoF approaches.""",Accuracy,No,"There is no mention of segmentation, but the article does write: ""We assume that each video is segmented into video surgemes"", so the segmentation has been done",Yes,"""For our tests we used the California dataset [3].""","""The dataset consists of three different tasks: suturing (SU, 39 trials), needle passing (NP, 26 trials) and knot tying (KT, 36 trials). Each task is performed by 8 surgeons with different skill levels.""",Private,"There is no mention of a public dataset, and the article writes ""The authors thank Intuitive Surgical and Carol Reiley for providing the dataset""",No,searching for the dataset yields no results,No,"no mention of demographics, though the article does specify that ""Each task is performed by 8 surgeons with different skill levels""",No,the article contains no mention of intent of data collection,Yes,"This work was funded by NSF grants 0931805 and 0941362, and by the Talentia Fellowships Programme of the Andalusian Regional Ministry of Economy, Innovation and Science",No, the article contains no information about the surgeons in the dataset or the patients they were presumably operating on,No,"the focus of the article is to promote a new method, mode of analysis, and does not mention any risk or benefit other than the usefulness of this new method",No,there is no mention of this,No,there is no mention of this,
22/09/2022 13.43.26,7,2012,Yes,It was accurately labelled,"Second, the classifier learning process does
not rely on pre-labeled training samples, but rather the training samples are extracted
from the test image itself using structural priors on relative cup and disc
positions. Third, we present a classification refinement scheme that utilizes both
structural priors and local context.",We present a superpixel based learning framework based on retinal structure priors for glaucoma diagnosis.,It is critical to detect this degeneration of the optic nerve as early as possible in order to stall its progression,SVM,"we use the same three evaluation criteria as in [1] to measure cup detection accuracy, namely non-overlap ratio (m1), relative absolute area difference (m2) and absolute CDR error (δ),",Yes,"In this work, we utilize the stateof-the-art SLIC (Simple Linear Iterative Clustering) algorithm [12] to segment the fundus disc image into compact and nearly uniform superpixels.",Yes,using a large clinical dataset called ORIGA−light,"For testing we use the ORIGA−light dataset, comprised of 168 glaucoma and 482 normal images.",Public,"Is searchable, available upon request",No,"But the dataset is available upon request, so perhaps this information is also",No,only size is mentioned,No,no mention of intent in article,Yes,This work is funded by Singapore A*STAR SERC Grant (092-148-00731),No,article contains no mention of patients ,No,"no direct mention, simply mentions the method proposed gets a level of ""accuracy is comparable to or higher than the state-of-the-art technique [1], with a speedup factor of tens or hundreds.""",No,no mention of patients,Don't know,"no mention of law/transparency - though they do mention ""The settings in [1] are also adopted in this work to facilitate comparisons"", so based on what that says, maybe",
26/09/2022 09.18.32,9,2012,Yes,It was accurately labelled,"Automatic detection of lung tumors and abnormal lymph
nodes are useful in assisting lung cancer staging. This paper presents a
novel detection method, by first identifying all abnormalities, then differentiating
between lung tumors and abnormal lymph nodes based on their
degree of overlap with the lung field and mediastinum.","our aim of this study is to develop a computerized method to detect
the lung tumors and abnormal lymph nodes from PET-CT thoracic images automatically.","In this work, we propose a new and intuitive idea to the detection problem –
after attempting to detect all abnormalities, if we can identify the actual lung
field (tumors inclusive), then we can differentiate lung tumors and abnormal
lymph nodes based on the degree of overlap between the detected abnormality
and the lung field.","Graph analysis, Regression-based appearance model and graph-based structure labeling are designed to estimate the actual lung field and mediastinum from the pathology-affected thoracic images adaptively.","Accuracy, Precision, Recall",No,"The PET-CT thoracic images are first preprocessed to remove the background
and soft tissues outside of the lung and mediastinum with morphological operations.
All images are then aligned based on the carina of tracheae, and rescaled
to the same size [4]. Next, the abnormalities are detected by classification of
lung field (L), mediastinum (M) or abnormalities (O) (Fig. 1c), based on PET
uptake values and CT densities.",No,"The experiment is performed on 50 sets of 3D PET-CT thoracic
images from patients with non-small cell lung cancer (NSCLC), provided by
the Royal Prince Alfred Hospital, Sydney.","A total of 54 lung tumors and 35
abnormal lymph nodes are annotated as the ground truth. For each data set,
the contour of lung field is also roughly delineated. Five images representing
the typical cases are selected manually as the training set for both structure
labeling and classification between tumors and lymph nodes. The data sets are
then randomly divided into five sets; and within each set, each image is used as
the testing image, with the other nine as the reference images.",Private,"The experiment is performed on 50 sets of 3D PET-CT thoracic
images from patients with non-small cell lung cancer (NSCLC), provided by
the Royal Prince Alfred Hospital, Sydney.",No,"The experiment is performed on 50 sets of 3D PET-CT thoracic
images from patients with non-small cell lung cancer (NSCLC), provided by
the Royal Prince Alfred Hospital, Sydney.",No,Nothing is mentioned in the article,No,Nothing is mentioned in the article,No,Nothing is mentioned in the article,No,Nothing is mentioned in the article,No,"They only mention: Lung cancer is currently the leading cause of cancer deaths; and staging plays
a critical role in defining the prognosis and the best treatment approaches",No,Nothing is mentioned on the choice of subjects,No,"There is a lengthy theory section, but no mention of accessing the code or the dataset",
26/09/2022 09.25.02,10,2012,Yes,It was accurately labelled,"In this paper, we propose a novel domain-transfer learning method
for MCI conversion prediction. Different from most existing methods, we
classify MCI-C and MCI-NC with aid from the domain knowledge learned with
AD and NC subjects as auxiliary domain to further improve the classification
performance.","Different from most existing methods, we
classify MCI-C and MCI-NC with aid from the domain knowledge learned with
AD and NC subjects as auxiliary domain to further improve the classification
performance.","Alzheimer’s disease (AD) is the most common form of dementia in elderly people
worldwide. Early diagnosis of AD is very important for possible delay of the disease.
Mild cognitive impairment (MCI) is a prodromal stage of AD, which can be further
categorized into MCI converters (MCI-C) and MCI non-converters (MCI-NC). The
former will convert into AD in follow-up time, while the latter will not convert. Thus,
accurate diagnosis of MCI converters is of great importance.",SVM,"AUC, Specificity, Accuracy, Sensitivity",Yes,"Then, we use the FSL package to segment
each structural MR image into three different tissue types: gray matter (GM), white
matter (WM), and cerebrospinal fluid (CSF).",Yes,"we evaluate the effectiveness of our proposed DTSVM method on
multimodal data, including MRI, PET and CSF, from the AlzheimerÊs disease
Neuroimaging Initiative (ADNI) database.","the baseline ADNI subjects with all corresponding MRI, PET,
and CSF data are included, which leads to a total of 202 subjects (including 51 AD
patients, 99 MCI patients, and 52 normal controls (NC)). For 99 MCI patients, it
includes 43 MCI converters and 56 MCI non-converters. We use 51 AD and 52 NC
subjects as auxiliary domains, and 99 MCI subjects as target domains.",Public,Googling ADNI leads to a webpage where the dataset is available upon request for research,No,Nothing is mentioned in the article,No,Nothing is mentioned in the article,No,Nothing is mentioned in the article,Yes,"This work was partially supported by NIH grants (EB006733,
EB008374, EB009634, AG041721 and MH088520), NSFC grant (60875030), and
CQKJ (KJ121111).",No,Nothing is mentioned in the article,No,Nothing is mentioned in the article,No,Nothing is mentioned in the article,No,Nothing is mentioned in the article,
26/09/2022 09.33.42,12,2012,No,Other medical imaging task,"It does not use the same performance measures, and aims to predict the outcome of facial deformation post surgery, so not really a diagnosis or a clear classification problem either.  ",,,,,,,,,,,,,,,,,,,,,,,,,,,,
26/09/2022 09.45.32,13,2012,Yes,It was accurately labelled,"We
utilize a fuzzy multi-class modeling using a stochastic expectation maximization
(SEM) algorithm to fit a finite mixture model (FMM) to the
PET image. We then propose a direct estimation formula for TLA and
SUVmean from this multi-class statistical model.","We
utilize a fuzzy multi-class modeling using a stochastic expectation maximization
(SEM) algorithm to fit a finite mixture model (FMM) to the
PET image. We then propose a direct estimation formula for TLA and
SUVmean from this multi-class statistical model.","The aforementioned functional markers computed from the PET image are
corrupted by partial volume effects and acquisition blur. Nonetheless, we recently
proposed a direct statistical estimation method, statistical lesion activity
computation (SLAC), in [6] for computing TLA, in the presence of blur.","Unsupervised learning, The main contributions of this paper include a fuzzy multi-class statistical modeling of the PET data with fuzzy mixing of all ‘hard’ classes involved in the model (in order to handle lesion as well as background heterogeneities) along with a direct estimation formula for TLA and SUVmean from the statistical model parameters.","Accuracy, At least I think it is accuracy, they speak of ground truth and deviating from that I believe",No,Not mentioned in the article,No,"To evaluate the performance, an NCAT phantom [11] with a hot liver lesion was
simulated.","To evaluate the performance, an NCAT phantom [11] with a hot liver lesion was
simulated. Realistic FDG uptake values were assigned to the various organs and
tissues of the NCAT phantom. A non spherical tumor (27.67mL) was inserted in
the liver (see Fig. 1). In the tumor, the activity was set to 18.2kBq/cc. The activity
in the liver, spleen, lungs and body was 6.3kBq/cc, 5.5kBq/cc, 0.9kBq/cc
and 2.5kBq/cc respectively. The voxel size used to generate the phantom was
1mm×1mm×1mm. 30 3min scans of the NCAT phantom were simulated using
a Monte Carlo simulator (PET-SORTEO [10]) which models among others the
spatially variant point spread function (PSF) of the ECAT Exact HR+ scanner.
Attenuation and scatter were also modeled. During reconstruction of both
datasets, the system PSF resolution was recovered by modeling as an isotropic
Gaussian with 5mm FWHM. The projection data were reconstructed using the
maximum likelihood expectation maximization (MLEM) algorithm [9] with ordered
subsets. As in clinical routine, 4 iterations over 16 subsets were performed.
The reconstruction voxel size was set to 2mm× 2mm× 2mm. The images were
post-smoothed with 5mm Gaussian FWHM.",Private,It is simulated data generated for this article of a liver lesion with a tumor inserted,Yes,"To evaluate the performance, an NCAT phantom [11] with a hot liver lesion was
simulated. Realistic FDG uptake values were assigned to the various organs and
tissues of the NCAT phantom. A non spherical tumor (27.67mL) was inserted in
the liver (see Fig. 1). In the tumor, the activity was set to 18.2kBq/cc. The activity
in the liver, spleen, lungs and body was 6.3kBq/cc, 5.5kBq/cc, 0.9kBq/cc
and 2.5kBq/cc respectively. The voxel size used to generate the phantom was
1mm×1mm×1mm. 30 3min scans of the NCAT phantom were simulated using
a Monte Carlo simulator (PET-SORTEO [10]) which models among others the
spatially variant point spread function (PSF) of the ECAT Exact HR+ scanner.
Attenuation and scatter were also modeled. During reconstruction of both
datasets, the system PSF resolution was recovered by modeling as an isotropic
Gaussian with 5mm FWHM. The projection data were reconstructed using the
maximum likelihood expectation maximization (MLEM) algorithm [9] with ordered
subsets. As in clinical routine, 4 iterations over 16 subsets were performed.
The reconstruction voxel size was set to 2mm× 2mm× 2mm. The images were
post-smoothed with 5mm Gaussian FWHM.",No,No patients were included as the data was simulated,Yes,It was created for this article,Yes,"The authors gratefully acknowledge the financial support
by KU Leuven’s Concerted Research Action GOA/11/006, IWT - TBM project
070717 and Research Foundation - Flanders (FWO).",No,Because no persons were involved,No,No persons involved,No,No persons involved,No,No persons involved but a very long perhaps useful theory section if one can recreate it from that?,
26/09/2022 10.18.37,14,2012,Yes,It was accurately labelled,"A novel gland segmentation and classification scheme applied
to an H&E histology image of the prostate tissue is proposed. For
gland segmentation, we associate appropriate nuclei objects with each
lumen object to create a gland segment. We further extract 22 features
to describe the structural information and contextual information for
each segment. These features are used to classify a gland segment into
one of the three classes: artifact, normal gland and cancer gland.","A novel gland segmentation and classification scheme applied
to an H&E histology image of the prostate tissue is proposed.","In detecting prostate cancer on a digitized tissue slide, the pathologist relies
on: (i) structural information; glands in a cancer region (cancer glands) appear
to have structural properties (e.g. nuclei abundance, lumen size) different from
glands in a normal region (normal glands) and (ii) contextual information; cancer
glands typically cluster into groups and are of similar shape and size1, while
shape and size of normal glands vary widely. These two sources of information
can be observed in Fig. 1b. Hence, a reasonable approach to assist a pathologist
in finding cancer regions includes segmenting out glandular regions, examining
their structural and contextual information and finally classifying them.",SVM,Accuracy,Yes,"For
gland segmentation, we associate appropriate nuclei objects with each
lumen object to create a gland segment.",No,"The dataset includes 48 images at 5× magnification (average image
size is 900 × 1,500 pixels), which come from 20 patients. Glands in images of
the same patient still have very large variability in structures. Given the pathologist’s
annotation on each image, we manually label 525 artifacts, 931 normal
glands and 1,375 cancer glands to form the (ground truth) gland dataset.","The dataset includes 48 images at 5× magnification (average image
size is 900 × 1,500 pixels), which come from 20 patients. Glands in images of
the same patient still have very large variability in structures. Given the pathologist’s
annotation on each image, we manually label 525 artifacts, 931 normal
glands and 1,375 cancer glands to form the (ground truth) gland dataset.",Private,The article contains no mention of where the dataset comes from,No,No mention in article,No,No mention in article,No,No mention in article,No,No mention in article,No,No mention in article,No,No mention in article,No,No mention in article,Yes,"The article includes a link to a github repo, containing at least some of the code
The article also includes stats for running time and details about the machine it has been run on",
26/09/2022 10.25.31,8,2021,No,Segmentation,Consistent Segmentation of Longitudinal Brain MR Images with Spatio-Temporal Constrained Networks,,,,,,,,,,,,,,,,,,,,,,,,,,,,
26/09/2022 10.27.16,17,2021,No,Segmentation,Improved Brain Lesion Segmentation with Anatomical Priors from Healthy Subjects,,,,,,,,,,,,,,,,,,,,,,,,,,,,
26/09/2022 10.28.27,18,2021,No,Segmentation,CarveMix: A Simple Data Augmentation Method for Brain Lesion Segmentation,,,,,,,,,,,,,,,,,,,,,,,,,,,,
26/09/2022 10.30.02,25,2021,No,,Partially-Supervised Learning for Vessel Segmentation in Ocular Images,,,,,,,,,,,,,,,,,,,,,,,,,,,,
26/09/2022 10.31.32,30,2021,No,Segmentation,Multi-compound Transformer for Accurate Biomedical Image Segmentation,,,,,,,,,,,,,,,,,,,,,,,,,,,,
27/09/2022 11.14.02,255,2021,Yes,It was accurately labelled,"In the early diagnosis of lung cancer, an important step is classifying malignancy/benignity for each lung nodule.","Recently, the contextual features attract increasing attention, due to the complementary information they provide. Clinically, such contextual features refer to the features of nodule’s surrounding structures, such that (together with nodule’s features) they can expose discriminate patterns for the malignant/benign, such as vascular convergence and fissural attachment. To leverage such contextual features, we propose a Context Attention Network (CA-Net) which extracts both nodule’s and contextual features and then effectively fuses them during malignancy/benignity classification. To accurately identify the contextual features that contain structures distorted/attached by the nodule, we take the nodule’s features as a reference via an attention mechanism. Further, we propose a feature fusion module that can adaptively adjust the weights of nodule’s and contextual features across nodules.","Recently, the contextual features attract increasing attention, due to the complementary information they provide. Clinically, such contextual features refer to the features of nodule’s surrounding structures, such that (together with nodule’s features) they can expose discriminate patterns for the malignant/benign, such as vascular convergence and fissural attachment. To leverage such contextual features, we propose a Context Attention Network (CA-Net) which extracts both nodule’s and contextual features and then effectively fuses them during malignancy/benignity classification",Neural network,"AUC, Accuracy, Log Loss",Yes,"The whole pipeline of our method, namely Context Attention Network (CA-Net), is illustrated in Fig. 2. As shown, it is the sequential of three stages: (i) Nodule Detection that detects all nodules from the CT image;",Yes,DSB2017 dataset,"There are 1397, 198, and 506 patients in the training, validation, and test set, respectively.",Public,"Experimentally, our CA-Net outperforms the 1st place by a noticeable margin on Kaggle DSB2017 dataset.",No,Nothing is mentioned in the article,No,This is the only description in the article: This dataset provides pathologically proven lung cancer label for each patient.,No,Nothing is mentioned in the article,Yes,"This work was supported by MOST-2018AAA0102004, NSFC-61625201, and the Beijing Municipal Science and Technology Planning Project (Grant No. Z201100005620008).",No,Nothing is mentioned in the article,Yes,"Experimentally, our CA-Net outperforms the 1st place by a noticeable margin on Kaggle DSB2017 dataset.",No,Nothing is mentioned in the article,Yes,"To some degree perhaps - though who knows what is actually in this supplementary material?
Also no mention is made of the repo/code for reproducibility... 
Electronic supplementary material
The online version of this chapter (https://​doi.​org/​10.​1007/​978-3-030-87240-3_​3) contains supplementary material, which is available to authorized users.",
27/09/2022 11.21.06,257,2021,Yes,It was accurately labelled,"Learning disease-related representations plays a critical role in image-based cancer diagnosis, due to its trustworthy, interpretable and good generalization power.","Learning disease-related representations plays a critical role in image-based cancer diagnosis, due to its trustworthy, interpretable and good generalization power. A good representation should not only be disentangled from the disease-irrelevant features, but also incorporate the information of lesion’s attributes (e.g., shape, margin) that are often identified first during cancer diagnosis clinically. To learn such a representation, we propose a Disentangle Auto-Encoder with Graph Convolutional Network (DAE-GCN), which adopts a disentangling mechanism with the guidance of a GCN model in the AE-based framework. ","For better representation learning, the disentanglement mechanism has been proved to be an effective way [1, 3, 12], since such a mechanism prompts different independent latent units to encode different independent ground truth generation factors that vary in the data [1]. Based on the above, to capture the disease-related features without mixing other irrelevant information, in this paper we propose a Disentangle Auto-Encoder with Graph Convolutional Network (DAE-GCN), which incorporates a disentangling mechanism into an AE framework, equipped with attribution data during training stage (the attributes are not provided during the test). ","Graph analysis, Supervised learning, Neural network","AUC, Accuracy",No,"Our dataset contains $$\{x_i,A_i,y_i\}_{i \in \{1,...,n\}}$$, in which x, A, y respectively denote the patch-level mass image, attributes (e.g., circumscribed-margin, round-shape, irregular-shape), and the binary disease label. ",Yes," DDSM 
But also uses 3 ""in house"" datasets","We consider both the public dataset DDSM [2] and three in-house datasets: Inhouse1, Inhouse2 and Inhouse3. For each dataset, the region of interests (ROIs) (malignant/benign masses) are cropped based on the annotations of radiologists the same as [9]1. For all datasets, we randomly2 divide the whole set into training, validation and testing as 8:1:1 in patient-wise. ",Don't know,"We consider both the public dataset DDSM [2] and three in-house datasets: Inhouse1, Inhouse2 and Inhouse3.",No,"To evaluate the effectiveness of our DAE-GCN, we verify it on the patch-level mammogram mass benign/malignant classification. We consider both the public dataset DDSM [2] and three in-house datasets: Inhouse1, Inhouse2 and Inhouse3. For each dataset, the region of interests (ROIs) (malignant/benign masses) are cropped based on the annotations of radiologists the same as [9]1. For all datasets, we randomly2 divide the whole set into training, validation and testing as 8:1:1 in patient-wise.",No,Nothing is mentioend,No,Nothing is mentioned,Yes,"This work was supported by MOST-2018AAA0102004, NSFC-61625201 and ZheJiang Province Key Research & Development Program (No. 2020C03073).",No,Nothing is mentioned,Yes,"From the introduction: 
For image-based disease benign/malignant diagnosis, it is crucial to learn the disease-related representation for prediction, due to the necessity of trustworthy (to patients), explainable (to clinicians) and good generalization ability in healthcare.",No,Nothing is mentioned,Yes,"To provide convenience for latter works, we publish our spitted test set of DDSM [2] in supplementary.",
27/09/2022 11.27.05,258,2021,Yes,It was accurately labelled,"Ultrasound (US) imaging is a fundamental modality for detecting and diagnosing breast lesions, while shear-wave elastography (SWE) serves as a crucial complementary counterpart. Although an automated breast lesion classification system is desired, training of such a system is constrained by data scarcity and modality imbalance problems due to the lack of SWE devices in rural hospitals. ","To enhance the diagnosis with only US available, in this work, we propose a knowledge-guided data augmentation framework, which consists of a modal translater and a semantic inverter, achieving cross-modal and semantic data augmentation simultaneously. ","Breast cancer, the most commonly diagnosed cancer, is the fifth leading cause of cancer death all over the world [24].",Neural network,"AUC, Accuracy, Precision, Recall, F1 score",No,Nothing is mentioned,No,"From September 2020 to January 2021, a total of 2,008 images of benign lesions and 1,466 images of malignant lesions from 593 patients were collected as the dataset used in this paper. ","From September 2020 to January 2021, a total of 2,008 images of benign lesions and 1,466 images of malignant lesions from 593 patients were collected as the dataset used in this paper. ",Private,"From September 2020 to January 2021, a total of 2,008 images of benign lesions and 1,466 images of malignant lesions from 593 patients were collected as the dataset used in this paper. ",Yes,"The Super Linear SL-15-4 probe of ultrafast ultrasound device Aixplorer (Super Sonic Imagine, Aix-en-Provence, France) was used for imaging data collection. The maximum stiffness scale of SWE images was selected as 180 Kilopascal (kPa). ",No,Nothing is mentioned,Yes,"From September 2020 to January 2021, a total of 2,008 images of benign lesions and 1,466 images of malignant lesions from 593 patients were collected as the dataset used in this paper. ",Yes,"This work was supported in part by Shanghai Municipal Science and Technology Major Project (2021SHZDZX0102), 111 project (BP0719010), Shanghai Science and Technology Committee (18DZ2270700) and Shanghai Jiao Tong University Science and Technology Innovation Special Fund (ZH2018ZDA17).",No,Nothing is mentioned,No,Nothing is mentioned,No,Nothing is mentioned,Yes,"Electronic supplementary material
The online version of this chapter (https://​doi.​org/​10.​1007/​978-3-030-87240-3_​6) contains supplementary material, which is available to authorized users.",
27/09/2022 11.29.27,259,2021,No,Other medical imaging task,"Transfer learning is an important step to extract meaningful features and overcome the data limitation in the medical Visual Question Answering (VQA) task. However, most of the existing medical VQA methods rely on external data for transfer learning, while the meta-data within the dataset is not fully utilized. In this paper, we present a new multiple meta-model quantifying method that effectively learns meta-annotation and leverages meaningful features to the medical VQA task. Our proposed method is designed to increase meta-data by auto-annotation, deal with noisy labels, and output meta-models which provide robust features for medical VQA tasks. Extensively experimental results on two public medical VQA datasets show that our approach achieves superior accuracy in comparison with other state-of-the-art methods, while does not require external data to train meta-models.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
27/09/2022 11.37.14,262,2021,Yes,It was accurately labelled,"In this paper, we propose a coherent cooperative learning framework based on transfer learning for unsupervised cross-domain classification.","In this paper, we propose a coherent cooperative learning framework based on transfer learning for unsupervised cross-domain classification.","In the practical application of medical image analysis, due to the different data distributions of source domain and target domain and the lack of the labels of target domain, domain adaptation for unsupervised cross-domain classification attracts widespread attention. However, current methods take knowledge transfer model and classification model as two separate training stages, which inadequately considers and utilizes the intrinsic information interaction between module","Unsupervised learning, Transfer learning, Neural network","Accuracy, Precision, Recall, F1 score",No,Nothing is mentioned,Yes,"We use three databases in the experiments, and their information is shown in Table 1. The Chest X-Ray1 is divided into training dataset and testing dataset [12]. Single lesion2 and Multiple lesions3 are the training datasets of two open lesion recognition competitions.","No quote, but there is Table 1 which includes the number of images of each used dataset",Public,"The Chest X-Ray1 is divided into training dataset and testing dataset [12]. Single lesion2 and Multiple lesions3 are the training datasets of two open lesion recognition competitions. (and I think the first one is also accessible, there is a link in the footnote)",No,Nothing is mentioned,No,Nothing is mentioned,No,Nothing is mentioned,No,"This work was supported in part by 2030 National Key Research and Development Program of China (2018AAA0100500), the National Nature Science Foundation of China (no. 61773166), Projects of International Cooperation of Shanghai Municipal Science and Technology Committee (14DZ2260800), the Fundamental Research Funds for the Central Universities, and the ECNU Academic Innovation Promotion Program for Excellent Doctoral Students (YBNLTS2021-040).",No,Nothing is mentioned,No,Nothing is mentioned,No,Nothing is mentioned,Yes,"Electronic supplementary material
The online version of this chapter (https://​doi.​org/​10.​1007/​978-3-030-87240-3_​10) contains supplementary material, which is available to authorized users.",
28/09/2022 09.54.15,15,2012,No,I don't know,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Don't know what this is, not classification I think...."
28/09/2022 10.03.14,16,2012,Yes,It was accurately labelled,"With the advent of advanced imaging techniques, genotyping,
and methods to assess clinical and biological progression, there is
a growing need for a unified framework that could exploit information
available from multiple sources to aid diagnosis and the identification
of early signs of Alzheimer’s disease (AD).","We propose a modeling
strategy using supervised feature extraction to optimally combine highdimensional
imaging modalities with several other low-dimensional disease
risk factors. The motivation is to discover new imaging biomarkers
and use them in conjunction with other known biomarkers for prognosis
of individuals at high risk of developing AD. Our framework also has the
ability to assess the relative importance of imaging modalities for predicting
AD conversion.","Mild cognitive impairment (MCI) is an intermediate stage between healthy aging
and dementia. Patients diagnosed with MCI are at high risk of developing
Alzheimer’s disease (AD), but not everyone with MCI will convert. Accurate
prognosis for MCI patients is an important prerequisite for providing the optimal
treatment and management of the disease.","SVM, Prediction of Conversion to AD: Distinguishing the probable convertors from the population of MCI is a binary classification problem. While there are several ways to look at this problem, we present here a formulation of the classifier supervised by the AD group and healthy control group (NL). In other words, the classifier is trained on the AD and NL but is used as a “recommender” for the test MCI subject. Based on the classification score obtained on the MCI subject, the prediction of the classifier is interpreted. We denote the test MCI subject as “AD-like” when the classifier recommends AD and treated as predicted MCI-C otherwise termed as “Stable-MCI” or predicted MCI-NC. The classifier accuracy is assessed by comparing the predicted MCI-C or MCI-NC status with the conversion status from the follow-up study for that test MCI subject. The proposed methodology is evaluated using the LDA, its quadratic variant–Quadratic Discriminant Analysis (QDA), and SVM as binary classifiers.","AUC, Specificity, Accuracy, Sensitivity",Yes,"Tissue-wise intensity normalization
for white matter, gray matter, and cerebrospinal fluid was performed using the expectation maximization based segmentation followed by the piecewise polynomial
histogram matching algorithm",Yes,"All the baseline and screening T1 weighted, bias-fieldcorrected
and N3 scaled structuralMagnetic Resonance Images were downloaded
from the Alzheimer’s Disease Neuroimaging Initiative (ADNI) database.","The baseline subjects that had all the clinical, APOE genotyping, FDG-PET
imaging and MRI imaging data from the ADNI database comprised of a total
of 242 individuals.",Public,ADNI is available upon request,No,Nothing is mentioned,No,Nothing is mentioned,No,Nothing is mentioned,Yes,"Data collection and sharing for this project was funded by
the Alzheimer’s Disease Neuroimaging Initiative (ADNI) (NIH Grant U01
AG024904).The research in this paper was supported byNIHgrant 5R01EB007688,
the University of California, San Francisco (NIH grantP41 RR023953),NSF grant
CNS-0751152), and NSF CAREER Grant 1054057.",No,Nothing is mentioned,No,Nothing is mentioned,No,Nothing is mentioned,No,Nothing is mentioned,
28/09/2022 10.14.36,17,2012,No,Other medical imaging task,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Detection not classification
28/09/2022 10.21.37,19,2012,Yes,It was accurately labelled,"One important contribution of the method is
the provision of an interpretability layer, which is able to explain a particular
classification by visually mapping the most important visual patterns associated
with such classification.","A method for automatic analysis and interpretation of histopathology
images is presented. The method uses a representation of the image data
set based on bag of features histograms built from visual dictionary of Haarbased
patches and a novel visual latent semantic strategy for characterizing the
visual content of a set of images.","This paper presents a new method, ViSAI, for automatic analysis and interpretation of
histopathological images.","The method comprises three main stages: learning of an image representation based on bag of features (BOF), characterization of the rich visual variety of a histopathological image collection using visual latent topic analysis, and connection of visual patterns with the semantics of the problem using a probabilistic classification model.","Specificity, Accuracy, Sensitivity",No,Nothing is mentioned,No,"The dataset comprises 10 labeled histopathological cases from St. Jude Children’s Research
Hospital, which 5 are anaplastic and 5 are non-anaplastic","Each slide is a whole
virtual slide of 80000×80000 pixels with one or more cancerous regions with a large
tumoral variability, manually annotated by a neuro-pathologist. For every slide, 750
individual images of 200×200 pixels non-overlapping where extracted uniformly at
random from these cancerous regions, resulting in a database of 7500 different images:
half of them anaplastic.",Private,"The dataset comprises 10 labeled histopathological cases from St. Jude Children’s Research
Hospital, which 5 are anaplastic and 5 are non-anaplastic",No,Nothing is mentioned,No,Nothing is mentioned,No,Nothing is mentioned,No,Nothing is mentioned,No,Nothing is mentioned,No,Nothing is mentioned,No,Nothing is mentioned,No,Nothing is mentioned,
28/09/2022 11.32.22,20,2012,No,I don't know,,,,,,,,,,,,,,,,,,,,,,,,,,,,,No clue what this one is about :D
28/09/2022 11.40.00,25,2012,Yes,It was accurately labelled,"Classification of Ambiguous Nerve Fiber
Orientations in 3D Polarized Light Imaging","3D Polarized Light Imaging (3D-PLI) has been shown to
measure the orientation of nerve fibers in post mortem human brains at
ultra high resolution. The 3D orientation in each voxel is obtained as a
pair of angles, the direction angle and the inclination angle with unknown
sign. The sign ambiguity is a major problem for the correct interpretation
of fiber orientation. Measurements from a tiltable specimen stage, that
are highly sensitive to noise, extract information, which allows drawing
conclusions about the true inclination sign. In order to reduce noise, we
propose a global classification of the inclination sign, which combines
measurements with spatial coherence constraints.","Fiber tracts are composed of axons, which connect nerve cells between each
other, and thus transmit information between brain areas. The exact courses
of fiber tracts are still far from being fully understood.","Graph analysis, The problem is formulated as a second order Markov random field and solved efficiently with graph cuts.","Sensitivity, RMSD",No,Nothing is mentioned (but this article is insanely convoluted!),No,"We evaluate our approach on synthetic and human brain
data.","Human Brain Data. Regions in histological sections of three post mortem
brains without pathological findings were selected to demonstrate the different
behavior of all approaches (Fig. 4(b)–(d)).
Synthetic Data. A synthetic data set consisting of a direction image ˜ ϕ and an
inclination image ˜α was created. The structure consists of rounded and crossing
fiber tracts (Fig. 4(a))",Private,The synthetic data they construct themselves and no mention is made of the human brain data,Don't know,"Not sure if someone who understands this could recreate the synthetic data, the human data no",No,Nothing is mentioned,Yes,At least the synthetic data is created for this article,No,Nothing is mentioned,No,Nothing is mentioned,No,Nothing is mentioned,No,Nothing is mentioned,No,Nothing is mentioned,
28/09/2022 11.41.48,28,2012,No,Other medical imaging task,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
28/09/2022 11.44.17,31,2012,No,Other medical imaging task,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"One I understand the basics of - trying to sample from MRI's to get better data faster, but not directly anything to do with classification I would say"
29/09/2022 08.59.47,266,2021,Yes,It was accurately labelled,"Universal Lesion Detection (ULD) in computed tomography (CT) [1–14], which aims to localize different types of lesions instead of identifying lesion types [15–26], plays an essential role in computer-aided diagnosis (CAD","In this paper we propose a BM-based conditional training for two-stage ULD, which can (i) reduce positive vs. negative anchor imbalance via a BM-based conditioning (BMC) mechanism for anchor sampling instead of traditional IoU-based rule; and (ii) adaptively compute size-adaptive BM (ABM) M. de Bruijne et al. (eds.)Medical Image Computing and Computer Assisted Intervention – MICCAI 2021Image Processing, Computer Vision, Pattern Recognition, and Graphics12905
https://doi.org/10.1007/978-3-030-87240-3_14
Conditional Training with Bounding Map for Universal Lesion Detection
Han Li1, 2  , Long Chen2, 3  , Hu Han2  , Ying Chi4   and S. Kevin Zhou1, 2  
(1)
Medical Imaging, Robotics, Analytic Computing Laboratory/Engineering (MIRACLE), School of Biomedical Engineering & Suzhou Institute for Advanced Research, University of Science and Technology of China, Suzhou, China
(2)
Key Laboratory of Intelligent Information Processing of Chinese Academy of Sciences (CAS), Institute of Computing Technology, CAS, Beijing, China
(3)
School of Electronic, Electrical and Communication Engineering, University of the Chinese Academy of Science, Beijing, China
(4)
Healthcare Intelligence, AIC, DAMO Academy, Alibaba Group, Hangzhou, China
 
 
Han Li
Email: han.li@miracle.ict.ac.cn
 
Long Chen
Email: long.chen@miracle.ict.ac.cn
 
Hu Han (Corresponding author)
Email: hanhu@ict.ac.cn
 
Ying Chi
Email: xinyi.cy@alibaba-inc.com
Abstract
Universal Lesion Detection (ULD) in computed tomography plays an essential role in computer-aided diagnosis. Promising ULD results have been reported by coarse-to-fine two-stage detection approaches, but such two-stage ULD methods still suffer from issues like imbalance of positive v.s. negative anchors during object proposal and insufficient supervision problem during localization regression and classification of the region of interest (RoI) proposals. While leveraging pseudo segmentation masks such as bounding map (BM) can reduce the above issues to some degree, it is still an open problem to effectively handle the diverse lesion shapes and sizes in ULD. In this paper we propose a BM-based conditional training for two-stage ULD, which can (i) reduce positive vs. negative anchor imbalance via a BM-based conditioning (BMC) mechanism for anchor sampling instead of traditional IoU-based rule; and (ii) adaptively compute size-adaptive BM (ABM) from lesion bounding-box, which is used for improving lesion localization accuracy via ABM-supervised segmentation.",we propose a novel training mechanism for ULD to effectively reduce positive vs. negative anchor imbalance via a BM-based conditioning (BMC) mechanism in stage-1 and improve lesion localization accuracy by leveraging a size-adaptive BM (ABM) for supervising the segmentation branch in stage-2. ,"Different from the traditional IoU-based positive and negative anchors selection mechanism, we use two independent anchor classification and regression tasks by directly predicting a per-pixel objectness map and selecting positive anchors for regression based on BMs [11]. Specifically as shown in Fig. 1, we use the  $$BM_{xy}$$ [11] as objectness GT map and select anchors whose value is greater than a threshold B in $$BM_{xy}$$ to the region proposal network (RPN) for pixel-wise objectness map regression. We further randomly mask out some background pixels in $$BM_{xy}$$ during objectness training to keep the number of background pixels no more than two times of the foreground pixel number. In addition, we extend BM into size-adaptive BMs (ABMs) to handle diverse lesions, in which the small lesions will be enhanced to compensate its limited pixel number while the big lesions are weakened. We use an ABM-supervised segmentation branch in stage-2 to improve the lesion localization accuracy.",Sensitivity,Yes,"Sect. 2.2 introduces the BMC mechanism, and Sect. 2.3 explains the newly introduced ABM-supervised segmentation branch.",Yes,DeepLesion dataset,"The dataset contains 32,735 lesions on 32,120 axial slices from 10,594 CT studies of 4,427 unique patients. Most existing datasets typically focus on one type of lesion, while DeepLesion contains a variety of lesions with large diameters ranges (from 0.21 to 342.5 mm). The 12-bit intensity CT is rescaled to [0,255] with different window ranges settings used in different frameworks. Also, every CT slice is resized and interpolated according to the detection frameworks’ setting. We follow the official split, i.e., $$70\%$$ for training, $$15\%$$ for validation and $$15\%$$ for testing.",Public,Searching for it shows it can be found by anyone,Don't know,Nothing is mentioned,No,Nothing is mentioned,No,Nothing is mentioned,Yes,"This research was supported in part by the Natural Science Foundation of China (grant 61732004), Youth Innovation Promotion Association CAS (grant 2018135) and Alibaba Group through Alibaba Innovative Research Program.",No,Nothing is mentioned,No,Nothing is mentioned,No,Nothing is mentioned,Yes,"There is a doi in the electronic supplementary material, but still only available behind a paywall and am unsure how much more material is actually provided","I would say this is perhaps more classification adjacent, ULD seems to be about localizing different types of lesions, and is used for computer-aided diagnosis, but not as a stand alone part.. "
29/09/2022 09.20.10,266,2021,Yes,It was accurately labelled,"Unsupervised anomaly detection (UAD) learns one-class classifiers exclusively with normal (i.e., healthy) images to detect any abnormal (i.e., unhealthy) samples that do not conform to the expected normal patterns","we propose a novel self-supervised representation learning method, called Constrained Contrastive Distribution learning for anomaly detection (CCD), which learns fine-grained feature representations by simultaneously predicting the distribution of augmented data and image contexts using contrastive learning with pretext constraints. ","UAD has two main advantages over its fully supervised counterpart. Firstly, it is able to directly leverage large datasets available from health screening programs that contain mostly normal image samples, avoiding the costly manual labelling of abnormal samples and the subsequent issues involved in training with extremely class-imbalanced data. Further, UAD approaches can potentially detect and localise any type of lesions that deviate from the normal patterns. One significant challenge faced by UAD methods is how to learn effective low-dimensional image representations to detect and localise subtle abnormalities, generally consisting of small lesions. ","we propose Constrained Contrastive Distribution learning (CCD), a new self-supervised representation learning designed specifically to learn normality information from exclusively normal training images.",AUC,No,Nothing is mentioned,Yes,"They use three different datasets: Hyper-Kvasir, LAG, and Liu et al's colonoscopy dataset",Different sizes,Public,"But mixed, some public, some private",No,None of the used datasets are described in great detail,No,Nothing is mentioned,No,Nothing is mentioned,No,Nothing is mentioned,No,Nothing is mentioned,No,Nothing is mentioned,No,Nothing is mentioned,Yes,"Their code is freely available on github, link in abstract",
29/09/2022 09.53.59,267,2021,Yes,It was accurately labelled,"In this paper, we propose a selective attention regularization module (SAttenReg) to mimic the diagnosis process of pathologists. Specifically, to explicitly encourage the model to focus on clinically interpretable features (e.g., nuclei and fat droplets), SAttenReg learns the attention map with the regularization of clinically interpretable features. Furthermore, with the different contributions of histological features, the model can selectively focus on different histological features based on the distribution of nuclei in each instance. Experiments conducted on the in-house Liver-NAS and public Biopsy4Grading biopsy image datasets show that our method achieves superior classification performance with promising localization results.",we propose a selective attention regularization module (SAttenReg) to mimic the diagnosis process of pathologists.,"Nonalcoholic fatty liver disease (NAFLD) is the most common cause of liver disease worldwide [21, 22]. It is estimated that the prevalence of NAFLD is between 25% and 45%, which has become an important public health concern [4, 20]. ",Neural network,"Specificity, F1 score, Sensitivity",No,Nothing is mentioned,Yes,Biopsy4grading and Liver-NAS,"Biopsy4Grading [7] is a public liver section dataset collected from animals studies. Each liver tiles (299 $$\times $$ 299 pixels) were assigned to discrete pathologist-like sub-scores for quantifying NAS-related components of ballooning degeneration (0–2), lobular inflammation (0–3), steatosis (0–3) and fibrosis (0–4), corresponding to the Kleiner score system [11]. Liver-NAS is a private dataset of liver biopsy images collecting from 9 patients. Image tiles were generated from whole slide images ($$\sim 106259\times 306939$$ pixels) with an area of $$224\times 224$$ pixels, which can guarantee the pathologist to sufficiently identify the relevant histological features within the tile.",Private,"Both, one is public, one is private",No,Nothing is mentioned,No,Nothing is mentioned,No,Nothing is mentioned,Yes,"This work was supported by the Health and Medical Research Fund Project under Grant 07180216. We acknowledge insightful discussion with Anthony W.H. CHAN. We also thank Vincent WS WONG, Grace LH WONG, and Howard H.W. LEUNG from the Chinese University of Hong Kong for help with data preparation.",No,Nothing is mentioned,No,Nothing is mentioned,No,Nothing is mentioned,No,Nothing is mentioned,
29/09/2022 10.01.00,268,2021,Yes,It was accurately labelled,Categorical Relation-Preserving Contrastive Knowledge Distillation for Medical Image Classification,"we propose a novel Categorical Relation-preserving Contrastive Knowledge Distillation (CRCKD) algorithm, which takes the commonly used mean-teacher model as the supervisor. ","The amount of medical images for training deep classification models is typically very scarce, making these deep models prone to overfit the training data. Studies showed that knowledge distillation (KD), especially the mean-teacher framework which is more robust to perturbations, can help mitigate the over-fitting effect. ","deep learning, knowledge distillation","Accuracy, F1 score,  average precision (AP), balanced multi-class accuracy (BMA),",No,Nothing is mentioned,Yes,"HAM10000 [23, 24] and APTOS datasets [25].","The HAM10000 consists of 10015 dermoscopy images labeled by 7 types of skin lesions. In APTOS, there are 3662 fundus images for grading diabetic retinopathy into five categories. ",Don't know,"Dataset: We evaluated our proposed CRCKD framework on the HAM10000 [23, 24] and APTOS datasets [25]. The HAM10000 consists of 10015 dermoscopy images labeled by 7 types of skin lesions. In APTOS, there are 3662 fundus images for grading diabetic retinopathy into five categories. These two datasets both suffer from severe class imbalance. A detailed description of these two datasets is provided in the supplementary material.",No,Nothing is mentioned,No,Nothing is mentioned,No,Nothing is mentioned,Yes,"The work described in this paper was supported by National Key R&D program of China with Grant No. 2019YFB1312400, Hong Kong RGC CRF grant C4063-18G, and Hong Kong RGC GRF grant #14211420.",No,Nothing is mentioned,No,Nothing is mentioned,No,Nothing is mentioned,Yes,"Also has supplementary electronic material, but there is a mention of what the supplementary material contains in the text, more info about the datasets, so some of the above questions may have different answers if this was available",
29/09/2022 10.07.02,269,2021,Yes,It was accurately labelled,we propose a tensor-based multi-index representation learning (TMRL) framework for fMRI-based MDD detection,", we propose a tensor-based multi-index representation learning (TMRL) framework for fMRI-based MDD detection","Major depression disorder (MDD) is one of the most prevalent disabling disorder, characterized by depressed mood, loss of interest or pleasure in nearly all activities. This mental illness has a high mortality rate due to the suicidal behavior of MDD patients, while the high cost of treatment troubles patients, their family members, and society [1, 2]. Even though many efforts have been made in clinical neuroscience and psychiatric research, the unknown etiology and pathological mechanism still prevent us from fully understanding the disease.",tensor-based multi-index representation learning (TMRL) framework for MDD detection with rs-fMRI,"Specificity, Accuracy, F1 score, Sensitivity",No,"Each fMRI scan was basically pre-processed by using the Data Processing Assistant for Resting-State fMRI (DPARSF). In this pipeline, we first discard the first 10 time points, followed by slice timing correction, head motion correction, regression of nuisance co-variants of head motion parameters, white matter, and cerebrospinal fluid. Images are then normalized with an EPI template in the MNI space, resampling to $$3 \times 3\times 3\,\text {mm}^{3}$$ resolution, and spatial smoothing using a $$6\,\text {mm}$$ full-width at half-maximum (FWHM) Gaussian kernel. ",Yes,The public rs-fMRI dataset,The public rs-fMRI dataset consists of 533 subjects1,Public,The public rs-fMRI dataset consists of 533 subjects1,No,Nothing is mentioned,Yes,"Article contains a table covering the gender, age, education year, first period, on medication and illness time of subjects included!",No,Nothing is mentioned,Yes,This work was finished when D. Yao was visiting the University of North Carolina at Chapel Hill. D. Yao and M. Liu was partly supported by NIH grant (No. AG041721). Z. Zhang was partly supported by the National Key Research and Development Program of China (No. 2016YFD0700100).,No,Nothing is mentioned,No,Nothing is mentioned,No,Nothing is mentioned,Yes,The table showing the demographics and electronic supplementary material,
30/09/2022 10.58.09,33,2012,No,I don't know,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Unsure about this one, doesn't have the performance measures I would expect, but also don't understand what they are really doing and how.."
30/09/2022 11.06.10,36,2012,Yes,It was accurately labelled,"There is an increasing demand for automated detection and analysis of
dermoscopy structures and malignancy clues such as streaks in dermoscopy images,
for computer-aided early diagnosis of deadly melanoma. This paper presents
a novel approach for streak detection and visualization on dermoscopic images.
We tackle the detection of streaks by means of ridge and valley estimation. Orientation
estimation and correction is applied to detect low contrast and fuzzy streaks
lines, and candidate streaks are used to classify dermoscopy images into streaks
Absent or Present with the AUC of 90.5% on 300 dermoscopy images.","This paper presents
a novel approach for streak detection and visualization on dermoscopic images.","Melanoma is the most deadly form of skin cancer, yet treatable via excision if detected
early. There is, therefore, a demand to develop computer-aided diagnostic systems to facilitate
the early detection of melanoma.",SimpleLogistic classifier implemented in Weka ( a logistic regression model),"AUC, Accuracy, Precision, Recall, F1 score",Yes,First the lesion is segmented using Wighton et al.’s method,No,"we evaluated our proposed approach on streak detection
on a set of 300 dermoscopy images, including 105 absent and 195 present. 250
images are chosen randomly from two atlases of dermoscopy [10,1], and 50 images
are taken from experts’ archives with permission.","we evaluated our proposed approach on streak detection
on a set of 300 dermoscopy images, including 105 absent and 195 present. 250
images are chosen randomly from two atlases of dermoscopy [10,1], and 50 images
are taken from experts’ archives with permission.",Private,"we evaluated our proposed approach on streak detection
on a set of 300 dermoscopy images, including 105 absent and 195 present. 250
images are chosen randomly from two atlases of dermoscopy [10,1], and 50 images
are taken from experts’ archives with permission. - So I suppose that means mixed, the atlases may be public?",No,Nothing is mentioned,No,Nothing is mentioned,No,Nothing is mentioned,Yes,"This work was funded by the Canadian NSERC, CIHR-Skin Research
Training Center and a grant from the Canadian Health Research Project (CHRP).",No,Nothing is mentioned,No,Nothing is mentioned,No,Nothing is mentioned,No,Nothing is mentioned,
30/09/2022 11.12.41,37,2012,Yes,It was accurately labelled,"Our experimental results show that the proposed method
can effectively identify the location of the foveola, facilitating diagnosis
around this important landmark.","We develop an automated method to determine the foveola
location in macular 3D-OCT images in either healthy or pathological
conditions.","The foveola is an important anatomical landmark for retinal image analysis [1]. It
is located in the center of the macula, responsible for sharp central vision. Several
clinically-relevant indices are measured with respect to the foveola location, such
as the retina’s average thickness, or drusen size within concentric circles around
the foveola [1, 2]. In addition, many macular diseases are best observed around
the foveola, such as macular hole, and age-related macular degeneration [3].
Therefore, the localization of the foveola in retinal images is an important first
step for diagnosis and longitudinal data analysis.",SVM,"mean, median, standard deviation",No,nothing is mentioned,No,"We collected a large sample of 3D SD-OCT macular scans (200x200x1024 or
512x128x1024 protocol, 6x6x2 mm; Cirrus HD-OCT; Carl Zeiss Meditec). Each
scan is then normalized to be 200x200x200 in x, y, z. For each scan, two ophthalmologists
labeled the (x, y) location of the foveola independently. We then
included a total of 170 scans from 170 eyes/126 subjects in which all scans have
good expert labeling agreement (distance ≤ 8 pixels)","We collected a large sample of 3D SD-OCT macular scans (200x200x1024 or
512x128x1024 protocol, 6x6x2 mm; Cirrus HD-OCT; Carl Zeiss Meditec). Each
scan is then normalized to be 200x200x200 in x, y, z. For each scan, two ophthalmologists
labeled the (x, y) location of the foveola independently. We then
included a total of 170 scans from 170 eyes/126 subjects in which all scans have
good expert labeling agreement (distance ≤ 8 pixels)",Private,"We collected a large sample of 3D SD-OCT macular scans (200x200x1024 or
512x128x1024 protocol, 6x6x2 mm; Cirrus HD-OCT; Carl Zeiss Meditec). Each
scan is then normalized to be 200x200x200 in x, y, z. For each scan, two ophthalmologists
labeled the (x, y) location of the foveola independently. We then
included a total of 170 scans from 170 eyes/126 subjects in which all scans have
good expert labeling agreement (distance ≤ 8 pixels)",Don't know,"We collected a large sample of 3D SD-OCT macular scans (200x200x1024 or
512x128x1024 protocol, 6x6x2 mm; Cirrus HD-OCT; Carl Zeiss Meditec). Each
scan is then normalized to be 200x200x200 in x, y, z. For each scan, two ophthalmologists
labeled the (x, y) location of the foveola independently. We then
included a total of 170 scans from 170 eyes/126 subjects in which all scans have
good expert labeling agreement (distance ≤ 8 pixels)",No,Nothing is mentioned,Yes,For the purpose of this article,Yes,"This research is supported in part by National Institutes of
Health contracts R01-EY013178 and P30-EY008098, The Eye and Ear Foundation
(Pittsburgh, PA), unrestricted grants from Research to Prevent Blindness,
Inc. (New York, NY), and grants from Intel Labs Pittsburgh (Pittsburgh, PA).",No,Nothing is mentioned,No,Nothing is mentioned,No,Nothing is mentioned,Yes,"There is psuedocode included for their algorithm, so partial transparency?","This one is perhaps also unclear if it is classification or not, the performance measures especially seem to indicate perhaps not, more localisation than classification, though they do do classification"
30/09/2022 11.17.42,38,2012,Yes,It was accurately labelled,"In the context of a blind source separation
of the underlying colour, we arrive at intrinsic melanin and hemoglobin
images, whose properties are then used in supervised learning to achieve excellent
malignant vs. benign skin lesion classification.","In this paper we propose a new log-chromaticity 2-D colour space,
an extension of previous approaches, which succeeds in removing confounding
factors from dermoscopic images: (i) the effects of the particular camera characteristics
for the camera system used in forming RGB images; (ii) the colour
of the light used in the dermoscope; (iii) shading induced by imaging non-flat
skin surfaces; (iv) and light intensity, removing the effect of light-intensity falloff
toward the edges of the dermoscopic image. In the context of a blind source separation
of the underlying colour, we arrive at intrinsic melanin and hemoglobin
images, whose properties are then used in supervised learning to achieve excellent
malignant vs. benign skin lesion classification.","The three most common malignant skin cancers are basal cell carcinoma (BCC), squamous
cell carcinoma (SCC), and melanoma, among which melanoma is the most deadly
with a high increasing rate in most parts of the world. Melanoma is often treatable if
detected in the early stage, particularly before the metastasis phase. Therefore, there is
an increasing demand for computer-aided diagnostic systems to catch early melanomas.
Colour has played a crucial role in the diagnosis of skin lesions by experts in most
clinical methods (see e.g. [1]). For instance, the presence of multiple colours with an
irregular distribution can signal malignancy.
Few studies have investigated the use of colour features representing biological properties
of skin lesions.",Logistic classifier,"AUC, Precision, Recall, F1 score",Yes,"For automatic segmentation of lesions, we found that
using the geometric-mean μ is as good as or better than the state of the art [12] for these
dermoscopic images, in amuch simpler algorithm.",No,"We applied a Logistic classifier to a set of 500 images, with two classes consisting of
malignant (melanoma and BCC) vs. all benign lesions","We applied a Logistic classifier to a set of 500 images, with two classes consisting of
malignant (melanoma and BCC) vs. all benign lesions",Private,"(This is the ONLY description of the dataset...) We applied a Logistic classifier to a set of 500 images, with two classes consisting of
malignant (melanoma and BCC) vs. all benign lesions",No,Nothing is mentioned,No,Nothing is mentioned,No,Nothing is mentioned,No,Nothing is mentioned,No,Nothing is mentioned,No,Nothing is mentioned,No,Nothing is mentioned,No,Nothing is mentioned,This article probably has the shortest description of a dataset I've seen so far!
30/09/2022 11.23.46,40,2012,Yes,It was accurately labelled,"We applied a linear Support Vector Machine (SVM) to classify candidate patch
sequences.","we present an image analysis method to
detect apoptosis in time-lapse phase-contrast microscopy, which is nondestructive
imaging.","There have been little-to-no reports of apoptosis detection in phase-contrast
microscopy. To the best of our knowledge, cell death event detection has only
been implicitly performed as a byproduct of cell tracking; i.e., if the trajectory of
a cell terminates during cell tracking, the cell is considered dead. However, this
simple heuristic often yields poor results because many cell traject",SVM,"Precision, Recall",No,Nothing is mentioned,No,"After C2C12 myoblastic stem cells were cultured for one day, Mitomycin C was
added to induce apoptosis. Afterward, three populations were imaged every 5
minutes over 45 hours, resulting in three sets of 540 image frames. As shown in
Fig. 4, most of cells were dead at the last frame. We manually annotated apoptosis
by marking the center of each apoptotic cell after it shrinks and becomes
bright, obtaining 1154 cases in total. The image sequences and ground truths
are available on the first author’s web page (www.cs.cmu.edu/∼seungilh).","After C2C12 myoblastic stem cells were cultured for one day, Mitomycin C was
added to induce apoptosis. Afterward, three populations were imaged every 5
minutes over 45 hours, resulting in three sets of 540 image frames. As shown in
Fig. 4, most of cells were dead at the last frame. We manually annotated apoptosis
by marking the center of each apoptotic cell after it shrinks and becomes
bright, obtaining 1154 cases in total. The image sequences and ground truths
are available on the first author’s web page (www.cs.cmu.edu/∼seungilh).",Public,"The image sequences and ground truths
are available on the first author’s web page (www.cs.cmu.edu/∼seungilh).",Yes,"After C2C12 myoblastic stem cells were cultured for one day, Mitomycin C was
added to induce apoptosis. Afterward, three populations were imaged every 5
minutes over 45 hours, resulting in three sets of 540 image frames. As shown in
Fig. 4, most of cells were dead at the last frame. We manually annotated apoptosis
by marking the center of each apoptotic cell after it shrinks and becomes
bright, obtaining 1154 cases in total. The image sequences and ground truths
are available on the first author’s web page (www.cs.cmu.edu/∼seungilh).",No,"Not relevant as such, uses stem cells (though no mention is made of which and whose stem cells are used of course)",Yes,For the purpose of this article,No,Nothing is mentioned,No,Nothing is mentioned,No,Nothing is mentioned,No,Nothing is mentioned,Yes,Pseudo code included,
03/10/2022 09.06.44,270,2021,Yes,It was accurately labelled,computer-aided mild cognitive impairment (MCI) conversion prediction,we propose a region ensemble model using a divide and conquer strategy to capture the disease’s finer representation,"Despite many recent advances, computer-aided mild cognitive impairment (MCI) conversion prediction is still a very challenging task due to: 1) the abnormal areas are subtle compared to the size of the whole brain, 2) the features’ dimension is much larger than the number of samples. ",Neural network,"AUC, Specificity, Accuracy, Sensitivity",Yes,"Since our method needs voxel-level annotation to extract brain regions, we use the dataset in [13] and the method in [19] to train a segmentation model which segments the whole brain into 134 regions.",Yes,We perform experiments on the public Alzheimer’s Disease Neuroimaging Initiative (ADNI) dataset [18],"Following [9–12], in all experiments, we treat ADNI-1 as the training set and leave ADNI-2 for testing to make an easier comparison. The training and testing set contains 226 sMCI vs. 167 pMCI and 239 sMCI vs. 38 pMCI, respectively. We also collect 199 AD and 229 NC samples in ADNI-1 as the additional samples to optimize the proposed relation regularized loss.",Public,ADNI is available ,No,Nothing is mentioned,No,Nothing is mentioned,No,Nothing is mentioned,Yes,"This work has been supported by the National Key Research and Development Program Grant 2018AAA0100400, the National Natural Science Foundation of China (NSFC) grants 61773376, 61836014, 61721004 and 31870984.",No,Nothing is mentioned,No,Nothing is mentioned,No,Nothing is mentioned,No,Nothing is mentioned,
03/10/2022 09.13.12,271,2021,Yes,It was accurately labelled," Since normal human airways share an anatomical structure, we design a graph prototype whose structure follows the normal airway anatomy. Then, we learn the prototype and a graph neural network from a weakly-supervised airway dataset, i.e., only the holistic label is available, indicating if the airway has anomaly or not, but which bronchus node has the anomaly is unknown. During inference, the graph neural network predicts the anomaly score at both the holistic level and node-level of an airway. "," Since normal human airways share an anatomical structure, we design a graph prototype whose structure follows the normal airway anatomy. Then, we learn the prototype and a graph neural network from a weakly-supervised airway dataset, i.e., only the holistic label is available, indicating if the airway has anomaly or not, but which bronchus node has the anomaly is unknown. During inference, the graph neural network predicts the anomaly score at both the holistic level and node-level of an airway. ",Detecting the airway anomaly can be an essential part to aid the lung disease diagnosis. ,"Graph analysis, Neural network","Specificity, Sensitivity",No,"But the data has to be segmented before using their model: Given the segmented and classified airway results shared by [7] (Fig. 2(b–c)), we encode the anatomical structure of the airways, as well as their image properties and graph properties into feature vectors. ",Yes,"We collected datasets from 3 resources: The Lung Image Database Consortium (LIDC) [8], The Lung Tissue Research Consortium (LTRC) [9], and The National Lung Screening Trial (NLST)","We collected datasets from 3 resources: The Lung Image Database Consortium (LIDC) [8], The Lung Tissue Research Consortium (LTRC) [9], and The National Lung Screening Trial (NLST) [10], leading to 62 normal samples and 23 anomaly samples in total. ",Public,"Looking at the references and googling, all 3 seem to be public",No,Nothing is mentioned,No,Nothing is mentioned,No,Nothing is mentioned,No,Nothing is mentioned,No,Nothing is mentioned,No,Nothing is mentioned,No,Nothing is mentioned,Yes,The code is publicly available on Github,
03/10/2022 09.17.03,272,2021,No,Other medical imaging task,"In the experiments, we use three widely used metrics [20] to evaluate the performance of different retrieval methods. These evaluation metrics are: average cumulative gain (ACG), normalized discounted cumulative gain (NDCG), and weighted mean average precision (mAP$$_w$$).",,,,,,,,,,,,,,,,,,,,,,,,,,,,
03/10/2022 09.18.24,273,2021,No,Other medical imaging task,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
03/10/2022 09.19.11,275,2021,No,Segmentation,ASC-Net: Adversarial-Based Selective Network for Unsupervised Anomaly Segmentation,,,,,,,,,,,,,,,,,,,,,,,,,,,,
03/10/2022 09.33.27,41,2012,Yes,It was accurately labelled,"We test our method on a
collection of 42 lymphocyte sequences and present results on i) discrimination of
normal and abnormal cellular morphology, ii) local statistical differences between
abnormal and normal shape sequences, and iii) classification of shape sequences
based on the dynamic cellular shape changes from one time point to another.","In this paper we propose a dynamic framework for quantitative analysis of
lymphocyte morphological changes in 2D+t image sequences","Morphological analysis of cells features prominently in a wide range of applications
including digital pathology and is essential for improving our understanding
of the basic physiological processes of organisms.",Learning Vector Quantization (LVQ) was then used to classify these two categories with 10-fold cross-validation,"Specificity, Accuracy, Sensitivity",No,"But mentions the data is segmented prior to use: We represent the segmented cell boundary by 2D
closed, continuously parameterized curve [5–7] c ⊂ R2 given by c(s) : [0, 2π) →
R2.",No,"Our data consists of 42 lymphocyte image sequences (20∼30 seconds) of mice
undergoing back skin transplantation (age: 6-8 weeks, weight 20-22 g) observed
with phase contrast microscopy (Olympus BX51, 0.3 μ resolution, 16 × 1000
magnification). The first group consisted of 21 healthy Balb/C mice as hosts
and 21 healthy Balb/C mice as donors, whereas the second group consisted of
21 healthy Balb/C mice as hosts and 21 healthy C57BL/6 mice as donors. The
lymphocytes were obtained from the blood samples of the 42 hosts collected
from the tail 7 days after the skin transplant.","Our data consists of 42 lymphocyte image sequences (20∼30 seconds) of mice
undergoing back skin transplantation (age: 6-8 weeks, weight 20-22 g) observed
with phase contrast microscopy (Olympus BX51, 0.3 μ resolution, 16 × 1000
magnification). The first group consisted of 21 healthy Balb/C mice as hosts
and 21 healthy Balb/C mice as donors, whereas the second group consisted of
21 healthy Balb/C mice as hosts and 21 healthy C57BL/6 mice as donors. The
lymphocytes were obtained from the blood samples of the 42 hosts collected
from the tail 7 days after the skin transplant.",Private,"Our data consists of 42 lymphocyte image sequences (20∼30 seconds) of mice
undergoing back skin transplantation (age: 6-8 weeks, weight 20-22 g) observed
with phase contrast microscopy (Olympus BX51, 0.3 μ resolution, 16 × 1000
magnification). The first group consisted of 21 healthy Balb/C mice as hosts
and 21 healthy Balb/C mice as donors, whereas the second group consisted of
21 healthy Balb/C mice as hosts and 21 healthy C57BL/6 mice as donors. The
lymphocytes were obtained from the blood samples of the 42 hosts collected
from the tail 7 days after the skin transplant.",No,"Our data consists of 42 lymphocyte image sequences (20∼30 seconds) of mice
undergoing back skin transplantation (age: 6-8 weeks, weight 20-22 g) observed
with phase contrast microscopy (Olympus BX51, 0.3 μ resolution, 16 × 1000
magnification). The first group consisted of 21 healthy Balb/C mice as hosts
and 21 healthy Balb/C mice as donors, whereas the second group consisted of
21 healthy Balb/C mice as hosts and 21 healthy C57BL/6 mice as donors. The
lymphocytes were obtained from the blood samples of the 42 hosts collected
from the tail 7 days after the skin transplant.",No,"Also not relevant, tested on mice",Yes,For the article,Yes,"This work is sponsored by the National Natural Science Foundation of China
(60971133) and the China Scholarship Council. anxing@bit.edu.cn",No,"Not relevant, mice testing",No,Nothing is mentioned,No,"Not relevant, mice testing",No,Nothing mentioned,
03/10/2022 09.37.26,42,2012,Yes,It was accurately labelled,"In this paper we propose a learning-based method that is general enough
to perform well across different microscopy modalities. Rather than invoking
computationally-intensive segmentation frameworks [1,9], or classifying all image
patches in a sliding-window manner [15], it uses a highly-efficient MSER region
detector [8] to find a broad number of candidate regions to be scored with a
learning-based measure. The non-overlaping subset of those regions with high
similarity to the class of interest can then be selected via dynamic programming,
while the learning can be done within the structured output framework [12].","In this paper we propose a learning-based method that is general enough
to perform well across different microscopy modalities. Rather than invoking
computationally-intensive segmentation frameworks [1,9], or classifying all image
patches in a sliding-window manner [15], it uses a highly-efficient MSER region
detector [8] to find a broad number of candidate regions to be scored with a
learning-based measure. The non-overlaping subset of those regions with high
similarity to the class of interest can then be selected via dynamic programming,
while the learning can be done within the structured output framework [12].","Automatic cell detection is a subject of interest in a wide range of cell-based
studies, as it is the basis of many automatic methods for cell counting, segmentation
and tracking. The broad diversity of cell lines and microscopy imaging
techniques require that cell detection algorithms adapt well to different scenarios.
The difficulty of the problem also increases when the cell density of the
sample is high, as in this case the cell size can vary and cell clumping is usual.
Moreover, in some applications different cell types or other similar structures
can be present in the same image, and in this case the algorithm is required to
detect only the cells of interest, posing a barrier hard to overcome with classical
image processing techniques.",SVM,"Precision, Recall",Yes,"Although the algorithm produces a set of regions, our
aim is to optimize the detection accuracy (and not the segmentation) w.r.t. the
ground truth provided in the form of dots.",No,"Three data sets for cell detection have been used to validate the method
(Figure 1). Firstly, the ICPR 2010 Histopathology Images contest [4], which
consists of 20 images of stained breast cancer tissue. It is required to detect
lymphocyte nuclei, while discriminating them from breast cancer nuclei having
very similar appearance. The second data set comes from [1] and contains 12
fluorescence microscopy images of human embryonic kidney (HEK) cells, where
the detection task is challenging due to the significant intensity variation between
cells across the image, fading boundaries, and frequent cell clumping. The third
data set contains 22 phase-contrast images of cervical cancer cell colonies of the
HeLa cell line, which presents a high variability in cell shapes and sizes.
Three variations of our method are evaluated: (I) direct classification","Three data sets for cell detection have been used to validate the method
(Figure 1). Firstly, the ICPR 2010 Histopathology Images contest [4], which
consists of 20 images of stained breast cancer tissue. It is required to detect
lymphocyte nuclei, while discriminating them from breast cancer nuclei having
very similar appearance. The second data set comes from [1] and contains 12
fluorescence microscopy images of human embryonic kidney (HEK) cells, where
the detection task is challenging due to the significant intensity variation between
cells across the image, fading boundaries, and frequent cell clumping. The third
data set contains 22 phase-contrast images of cervical cancer cell colonies of the
HeLa cell line, which presents a high variability in cell shapes and sizes.
",Don't know,Mixed I think,No,"Three data sets for cell detection have been used to validate the method
(Figure 1). Firstly, the ICPR 2010 Histopathology Images contest [4], which
consists of 20 images of stained breast cancer tissue. It is required to detect
lymphocyte nuclei, while discriminating them from breast cancer nuclei having
very similar appearance. The second data set comes from [1] and contains 12
fluorescence microscopy images of human embryonic kidney (HEK) cells, where
the detection task is challenging due to the significant intensity variation between
cells across the image, fading boundaries, and frequent cell clumping. The third
data set contains 22 phase-contrast images of cervical cancer cell colonies of the
HeLa cell line, which presents a high variability in cell shapes and sizes.
Three variations of our method are evaluated: (I) direct classification",No,Nothing is mentioned,No,Nothing is mentioned,Yes,"We are grateful to Dr. N. Rajpoot, Dr. E. Bernadis, Dr.
B. Vojnovic and Dr. G. Flaccavento for providing cell data sets. Financial support
was provided by the RCUK Centre for Doctoral Training in Healthcare
Innovation (EP/G036861/1) and ERC grant VisRec no. 228180.",No,Nothing is mentioned,No,Nothing is mentioned,No,Nothing is mentioned,No,Nothing is mentioned,
03/10/2022 09.39.15,51,2012,No,Other medical imaging task,"However, our target applications for this model are registration and reconstruction.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
03/10/2022 09.40.04,52,2012,No,Other medical imaging task,"Towards Intra-operative PET for Head
and Neck Cancer: Lymph Node Localization
Using High-Energy Probes",,,,,,,,,,,,,,,,,,,,,,,,,,,,
03/10/2022 09.45.04,53,2012,Yes,It was accurately labelled,"Our method features a novel completely
data-driven approach to breast shape prediction that does not necessitate
prior knowledge about biomechanical properties and parameters of the
breast tissue.","We therefore propose a method for 3D breast decompression
and associated lesion mapping from 3D DBT data.","According to theWorld Cancer Report 2008 (globocan.iarc.fr, 2012/01/23) breast
cancer is the most frequent cancer diagnosis in women among all specifiable
kinds of cancer. Early detection is assumed to significantly improve outcomes.",3D Shape Prediction by Multiple Multi-variate Random Forest Regression,Accuracy,Yes,"For this we first segment the breast
tissue area by thresholding and region growing,",No,"Nipple detection has been trained and evaluated on 122 annotated training
data sets, i.e., DBT scans.","Nipple detection has been trained and evaluated on 122 annotated training
data sets, i.e., DBT scans.",Private,"Nipple detection has been trained and evaluated on 122 annotated training
data sets, i.e., DBT scans.",No,Nothing is mentioned,No,Nothing is mentioned,Yes,I believe it was collected for this article,No,Nothing is mentioned,No,Nothing is mentioned,No,Nothing is mentioned,No,Nothing is mentioned,No,Nothing is mentioned,